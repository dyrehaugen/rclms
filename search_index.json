[["index.html", "Climate System 1 Climate Change", " Climate System Dyrehaugen Web Notebook 2023-12-07 1 Climate Change The issue of Climate Change is treated across several web notebooks: Climate System (github) (geek) (loc) Climate Models (github) (geek) (loc) Climate Impacts (github) (geek) (loc) Climate Actions (github) (geek) (loc) You are now visiting the Climate System Web Notebook. Climate is someone else’s Weather Climate Crisis and Economic Development are one and the same problem The neoliberal solution to climate change is to hope that somehow it will become profitable to save the planet. This will not work. "],["attribution.html", "2 Attribution 2.1 Attribution Studies Timeline 2.2 Map of Attribution Studies 2.3 Bottom Trawling CO2 release 2.4 Company Attribution 2.5 Military", " 2 Attribution For too long, weather’s randomness has kept events such as these from being blamed squarely on climate change. Reporters in the late 1990s and early 2000s would ask climate scientists about climate change’s role in a weather-related disaster. All we could say was that we’d expect to see more of these events. Now, we can specify increased chances for specific events. This extends to forecasts: we can identify the places that are more likely to see wildfires, mudslides and fish die-offs. Such calculations dent both climate denial and a false sense of security. They take away the argument that ‘extreme weather happens anyway, so we don’t need to worry about it’. Extreme weather happens — and these metrics pinpoint what is becoming more likely, by how much and why. Betts (2021) Nature Ametsoc (2021) Explaining Extreme Weather (pdf) 2.1 Attribution Studies Timeline ClimateChangeNews AR5 concluded that human influence on the climate system is “clear.” Today scientists say climate change is, without doubt, caused by us. A 2021 study concluded that humans have caused all of the warming observed since the preindustrial period. Since the last IPCC report, there has been an explosion of attribution studies finding that specific heatwaves, droughts, tropical cyclones and other extreme events were more likely or intense because of climate change. Recent studies have shown that extreme events such as the Siberian heat wave in 2020 would never have happened without humans pumping greenhouse gases into the air. Since AR5, attribution science has become more “impact-oriented”, Sjoukje Philip, a climate scientist from the World Weather Attribution (WWA) group, told Climate Home News. That means more studies focusing on the societal impacts of extreme weather events. The increase in attribution studies is due to more precise climate models and peer-reviewed methods which allow scientists to rapidly and accurately analyse extreme events. Scientists are now able to carry out attribution studies within a few days of an event occurring. Half of all attribution studies focus on heatwaves. Heatwaves are relatively easy to attribute because they are “very certain and the first response to climate change” and cover a large area, which makes it easier for climate models to pick up. Most of the rest look at extremes of rainfall leading to drought or floods. Only a handful have looked at hurricanes, which are hard to model due to their complexity and limited historical data. They reached relatively weak conclusions about the scale of human influence. That could change as new high-resolution models are being developed. The majority of attribution studies focus on events in Europe and North America. This is because these regions have the most reliable climate data available. Timeline of climate attribution studies 2004: First heatwave attribution study The study found that climate change had at least doubled the likelihood of the European heatwave in 2003, which killed more than 70,000 people. 2011: First flooding attribution study The first study to attribute greenhouse gas emissions’ contribution to flood risk in England and Wales. The scientists concluded that emissions increased the risk of floods occurring in England and Wales in autumn 2000 by more than 20% and in two out of three cases by more than 90%. 2014: Likelihood of European heatwaves analysis The study found that summer heatwaves in Europe over the past 10-15 years were 10 times more likely due to climate change 2016: Mortality study of European heatwave The first study to directly link deaths during the 2003 European heatwave to climate change. The scientists concluded that 506 of the 735 summer fatalities in Paris in 2003, and 64 of the 315 in London were a result of climate change. 2017: Bangladesh flooding study World Weather Attribution analysis directly linked severe flooding in Bangladesh in 2017 to climate change. 2018: Cape Town water crisis analysis The 2017 drought which led to Cape Town’s water crisis was made three times more likely by climate change, according to analysis by World Weather Attribution scientists. 2018: Extreme heat across Asia Extreme heat across Asia in 2016 would have been impossible without climate change, scientists concluded in 2018. 2020: Siberian heatwave impossible without climate change The prolonged Siberian heatwave in 2020 would have been almost impossible without climate change, according to rapid attribution analysis by the World Weather Attribution group. 2021: Australian bushfire season 30% more likely Australia’s devastating bushfire season in 2019-202 was made significantly more likely because of climate change, according to World Weather Attribution scientists. The analysis showed that climate change led to weather conditions that increased the fire risk by at least 30%. ClimateChangeNews 2.2 Map of Attribution Studies Known as “extreme event attribution”, the field has gained momentum, not only in the science world, but also in the media and public imagination. These studies have the power to link the seemingly abstract concept of climate change with personal and tangible experiences of the weather. Scientists have published more than 300 peer-reviewed studies looking at weather extremes around the world, from wildfires in Alaska (pdf) and hurricanes in the Caribbean to flooding in France and heatwaves in China. The result is mounting evidence that human activity is raising the risk of some types of extreme weather, especially those linked to heat. To track how the evidence on this fast-moving topic is stacking up, Carbon Brief has mapped – to the best of our knowledge – every extreme-weather attribution study published to date. The map above shows 355 extreme weather events and trends across the globe for which scientists have carried out attribution studies. Carbon BriefMap 2.3 Bottom Trawling CO2 release Time Magzine: How Industrial Fishing Creates More CO2 Emissions Than Air Travel Bottom trawling is responsible for one gigaton of carbon emissions a year—a higher annual total than (pre-pandemic) aviation emissions. Not only does the practice contribute to climate change, it is extremely damaging to ocean biodiversity—the “equivalent of ploughing an old-growth forest into the ground, over and over and over again until there is nothing left” Bottom trawling is also one of the least cost effective methods of fishing. Most locations have been trawled so many times, there is little left worth catching. Without government subsidies, no one would be making a penny. Refuting a long-held view that ocean protection harms fisheries, the study found that well placed marine protected areas (MPAs) that ban fishing would actually boost the production of marine life by functioning as fish nurseries and biodiversity generators capable of seeding stocks elsewhere. Sala Marine sediments are the largest pool of organic carbon on the planet and a crucial reservoir for long-term storage29. If left undisturbed, organic carbon stored in marine sediments can remain there for millen-nia30. However, disturbance of these carbon stores can re-mineralize sed-imentary carbon to CO2, which is likely to increase ocean acidification, reduce the buffering capacityof the ocean and potentially add to the build-up of atmospheric CO2 Using satellite-inferred information on fishing activity by industrial trawlers and dredgers between 2016 and 2019, aggregated at a reso-lution of 1km2, we estimate that 4.9million km2 or 1.3% of the global ocean is trawled each year. This disturbance to the seafloor results in an estimated 1.47Pg of aqueous CO2 emissions, owing to increased carbon metabolism in the sediment in the first year after trawling. If trawling continues in subsequent years, emissions decline as sediment carbon stocks become exhausted. However, after 9 years of continuous trawling, emissions stabilize at around 40% of the first year’s emissions, or around 0.58Pg CO2 (Supplementary Fig.35). If the intensity and footprint of trawling remains constant, we estimate that sediment carbon emissions will continue at approximately 0.58Pg CO2 for up to around 400 years of trawling, after which all of the sediments in the top metre are depleted. Although 1.47Pg CO2 represents only 0.02% of total marine sedimentary carbon, it is equivalent to 15–20% of the atmospheric CO2 absorbed by the ocean each year32,33, and is compara-ble to estimates of carbon loss in terrestrial soils caused by farming34. Although an unknown fraction of the aqueous CO2 is emitted to the atmosphere, the increase in CO2 in the water column and sediment pore waters can have far-reaching and complex effects on marine carbon cycling, primary productivity and biodiversity. Time Magzine BBC Sala (2021) Protecting the global ocean for biodiversity, food and climate - Nature Share 2.4 Company Attribution A 2017 report by the Carbon Disclosure Project showed that 100 companies have been responsible for 71 per cent of global emissions since 1988. In 2019, a similar study from the Climate Accountability Institute found that just 20 companies were responsible for 35 per cent of all energy-related carbon dioxide and methane worldwide since 1965. Sultana 2.5 Military Noor Militaries have generated about 430m metric tonnes of CO2 emissions since 2015 Paris accords. The US and UK militaries owe at least $111bn in reparations to communities most harmed by their planet-heating pollution, a first-of-its-kind study calculates. The research employs a “social cost of carbon” framework – a way to estimate the cost, in dollars, of the climate damage done by each additional tonne of carbon in the atmosphere. “The environmental costs of maintaining the global military reach of the US and UK armed forces are astonishing,” said Patrick Bigger, research director of the Climate and Community Project and co-author of the report. According to the report, which was published by the UK-based thinktank Common Wealth and the US-based Climate and Community Project, the two militaries have generated at least 430m metric tonnes of carbon dioxide equivalent since the 2015 United Nations Paris climate agreement. That’s more than the total greenhouse gas emissions produced in the UK last year. To offer minimal compensation for damage caused by those emissions, the US military should offer $106bn in international climate financing, while the UK military should offer $5bn, the researchers write, employing an equation drawn up by a Columbia University researcher in 2021. Those figures, though eye-popping, are “extremely conservative”, the authors say. “We wanted to get a sense of the minimum scale of climate finance that both of these countries owe due to the effects of their military operations,” said Khem Rogaly, a researcher at Common Wealth and study co-author. “But it really is the minimum.” One reason: they are based on “opaque” and “incomplete” data from the US and UK governments, which don’t include most emissions from the institutions’ supply chains. The figures omit data from 2017 and 2018, when the UK military failed to report its emissions estimates, and from 2022, which the US has not yet released. They also fail to account for certain climate impacts of military activity such as the unique climate-warming properties of jet fuel, among other issues. The UK and the US have made some plans to clean up their militaries’ emissions imprints. The environmental impact wreaked by the US and UK militaries extends far beyond warming from greenhouse gas emissions, the researchers say. The social cost of carbon doesn’t account for health impacts to communities near military activity – from Bikini Atoll in the Marshall Islands, where nuclear testing in the 40s and 50s led to severe environmental damage; to Vieques, Puerto Rico, where decades of US navy chemical pollution significantly increased the risk of cardiovascular and respiratory disease for locals; to Iraq, where troops’ use of depleted uranium led to widespread health issues including birth defects during the Gulf war and the 2003 invasion. “These two militaries have about 900 bases overseas,” said Rogaly. “The effects of having all these military installations across the world is going to be extremely severe when you’re supplying them with fossil fuels, clearing land, building installations for military activity, contaminating with toxic waste.” Basav Sen, climate policy project director at the Institute for Policy Studies thinktank, who reviewed the report, said the research is “crucial”. “We can’t account for our emissions without accounting for the military-industrial complex,” he said. Militaries are among the world’s biggest contributors to the climate crisis, accounting for 5.5% of all global greenhouse gas emissions. “Greening” militaries while maintaining existing operations is not a good solution. Only a reparative program that extends from base closures and reduced operations to environmental remediation, climate finance and just transition plans for military workers is up to the task. Noor (2023) US and UK militaries owe combined $111bn in climate reparations "],["carbon-budget.html", "3 Carbon Budget 3.1 Net-zero 3.2 Revelle factor", " 3 Carbon Budget The temperature response for a 1.5°C scenario has a huge uncertainty &amp; this propagates to the uncertainty in the carbon budget. To say “the remaining carbon budget for 1.5°C is 440 GtCO₂” [add favorite number] is highly misleading Taking a narrow 67–33% range, the value is 230–670 GtCO₂, but full range (left) could be −1000 - 2000 GtCO₂… (yes, could be negative or huge) (Glen Peters) Memo Matthews: The remaining carbon budget quantifies the future CO 2 emissions to limit global warming below a desired level. Carbon budgets are subject to uncertainty in the Transient Climate Response to Cumulative CO 2 Emissions (TCRE), as well as to non-CO 2 climate influences. We estimate a median TCRE of 0.44 °C and 5–95% range of 0.32–0.62 °C per 1000 GtCO 2 emitted. Considering only geophysical uncertainties, our median estimate of the 1.5 °C remaining carbon budget is 440 GtCO 2 from 2020 onwards, with a range of 230–670 GtCO 2 , (for a 67–33% chance of not exceeding the target). Additional socioeconomic uncertainty related to human decisions regarding future non-CO 2 emissions scenarios can further shift the median 1.5 °C remaining carbon budget by ±170 GtCO 2 . Remaining carbon budgets (RCBs) represent the future cumulative CO 2 emissions that would be consistent with keeping global warming to a specified level. Despite being conceptually simple, RCBs have been defined and estimated in various ways and with many different underlying assumptions, resulting in a wide range of “best estimates” across different studies 2 . Moreover, most of these estimates of remaining budgets account for only a subset of the relevant uncertain processes and often omit the contribution of key uncertain processes (such as permafrost thaw or future scenario uncertainty, among others) Median TCRE estimate is 0.44 °C per 1000 GtCO2 , with a 5–95% range of 0.32–0.62 °C per 1000 GtCO2 A stronger constraint on the left-hand side of the distribution (low TCRE values, with sharply increasing probability above 0.25 °C/ 1000 GtCO 2 ), while the right-hand side of this distribution has a wider tail. This right-skewed distribution shape of our observationally-constrained TCRE estimate is physically related to the possibility of a large negative aerosol forcing Median RCB for 1.5 °C is 440 GtCO2 from 2020 onwards, representing a 50% chance of stabilising warming at or below 1.5 °C. The corresponding budget for a 67% chance of remaining below the target is 230 GtCO2 from the year 2020 onwards. Matthews(2021) Carbon Budget Uncertainties (pdf) 3.1 Net-zero Disaster looms if big finance is allowed to game the carbon offsetting markets to achieve ‘net zero’ emissions. Net zero increasingly involves highly questionable carbon accounting. As a result, the new politics swirling around net zero targets is rapidly becoming a confusing and dangerous mix of pragmatism, self-delusion and weapons-grade greenwash. The science of net zero is simple: every sector of every country in the world needs to be, on average, zero emissions. We know how to do this for electricity, cars, buildings and even a lot of heavy industry. But in certain areas, including air travel and some agricultural emissions, there is no prospect of getting to zero emissions in the near future. For these residual emissions, greenhouse gasses will need to be sucked out of the atmosphere at the same rate as they are added, so that, on average, there are net zero emissions. The science of net zero is simple: every sector of every country in the world needs to be, on average, zero emissions. We know how to do this for electricity, cars, buildings and even a lot of heavy industry. But in certain areas, including air travel and some agricultural emissions, there is no prospect of getting to zero emissions in the near future. For these residual emissions, greenhouse gasses will need to be sucked out of the atmosphere at the same rate as they are added, so that, on average, there are net zero emissions. Making this work requires carbon removal, also known as “negative emissions”. This can be low-tech, like restoring forests, as this takes carbon out of the atmosphere and stores it in trees. Or it can be hi-tech, like using chemicals to strip carbon dioxide from the atmosphere and then pumping it deep underground into safe geological storage. In theory this is all fine, as pragmatically some carbon removal is needed to balance hard-to-reduce emissions: but negative emissions and offsetting alone are not a route to net zero. In practice, by believing in the promise of these methods, we are too often deceiving ourselves, in three major ways. The first is an unrealistic overreliance on carbon removal to preserve the status quo. Critically, there is far too little land to plant enough trees to counter today’s emissions, and large-scale hi-tech methods do not yet exist. The second deception is in offsetting against notional emissions trajectories instead of removing carbon from the atmosphere.Offsetting needs to be used to remove carbon dioxide from the atmosphere to counter difficult-to-remove emissions, and not just be an enabler of business-as-nearly-usual. The third deception comes from not getting what you think you’re paying for in the self-regulated global carbon market. The commercial carbon offset concept relies on “additionality” – that money paid then reduces emissions or captures carbon that would not otherwise have happened. The offsets market is awash with old legacy carbon credits where that assumption is violated. If such deceptions remain, disaster looms. Big finance, led by Carney, is planning to massively expand carbon markets. Conceivably, new carbon-based financial products could boom, with little impact on emissions. Just like the sub-prime crisis, few will understand what they bought, and another globe-spanning crash could sweep the world, compounding economic and climate crises causing mass suffering, as we realise again that the Earth owes us nothing. Nature doesn’t do bailouts. Lewis (Guardian) 3.2 Revelle factor Wikipedia The Revelle factor (buffer factor) is the ratio of instantaneous change in carbon dioxide (CO 2) to the change in total dissolved inorganic carbon (DIC), and is a measure of the resistance to atmospheric CO2 being absorbed by the ocean surface layer.[1] The buffer factor is used to examine the distribution of CO2 between the atmosphere and the ocean, and measures the amount of CO2 that can be dissolved in the mixed surface layer. It is named after the oceanographer Roger Revelle. The Revelle factor describes the ocean’s ability to uptake atmospheric CO2, and is typically referenced in global carbon budget analysis and anthropogenic climate change studies. In order to enter the ocean, carbon dioxide gas has to partition into one of the components of carbonic acid: carbonate ion, bicarbonate ion, or protonated carbonic acid, and the product of these many chemical dissociation constants factors into a “back-pressure” that limits how fast the carbon dioxide can enter the surface ocean. The capacity of the ocean waters to take up surplus (anthropogenic) CO2 is inversely proportional to the value of the Revelle factor. Hence, in modern-day oceans, it is possible to see the concentrations of anthropogenic CO2 by measuring the Revelle factor; the lower the Revelle factor, the greater the amount of anthropogenic CO2.[4] Low Revelle factors are typically found in the warmer tropical to subtropical waters, whereas higher Revelle factors are found in the colder high latitude waters of the North Atlantic. The North Pacific has higher Revelle factors, and has lower anthropogenic CO 2. This is due to the fact that the alkalinity values in the North Pacific are as much as 100μmol/kg lower than those in the North Atlantic. The Revelle effect describes how only a small fraction of pCO2 is present in ocean water when much larger amounts are added to the atmosphere. Depending on the alkalinity of the water, DIC is either present as CO3, HCO3, or CO2. When the pH is high (basic) the Revelle factor is greatest, causing much of the DIC to exist as HCO3 or CO3, and not CO2. So, the greater the buffering effect (low Revelle Factor) the more DIC occurs as CO3 or HCO3, effectively lowering the pCO2 levels in both the atmosphere and ocean. Wikipedia Revelle Factor "],["climate-sensitivity.html", "4 Climate Sensitivity 4.1 Climate Feedbacks 4.2 Global Warming Pipeline 4.3 ECS - Equilibrium Climate Sensitivity 4.4 Remote Sensing of Tipping Points 4.5 Exxon’s 1980s Scenario", " 4 Climate Sensitivity Hansen Phasedown of emissions cannot restore Earth’s energy balance within less than several decades, which is too slow to prevent grievous escalation of climate impacts and probably too slow to avoid locking in loss of the West Antarctic ice sheet and sea level rise of several meters. Hansen (2023) PipelinePaper230705 (pdf) Hansen - published pipeline paper abstract Improved knowledge of glacial-to-interglacial global temperature change yields Charney (fast-feedback) equilibrium climate sensi- tivity 1.2 ± 0.3 C (2\\(\\sigma\\)) per W/m2, which is 4.8C ± 1.2C for doubled CO2. Consistent analysis of temperature over the full Cenozoic era—including ‘slow’ feedbacks by ice sheets and trace gases—supports this sensitivity and implies that CO2 was 300–350 ppm in the Pliocene and about 450 ppm at transition to a nearly ice-free planet, exposing unrealistic lethargy of ice sheet models. Equilibrium global warming for today’s GHG amount is 10C, which is reduced to 8C by today’s human-made aerosols. Equilibrium warming is not ‘committed’ warming; rapid phaseout of GHG emissions would prevent most equilibrium warming from occurring. However, de- cline of aerosol emissions since 2010 should increase the 1970–2010 global warming rate of 0.18C per decade to a post-2010 rate of at least 0.27C per decade. Thus, under the present geopolitical approach to GHG emissions, global warming will exceed 1.5C in the 2020s and 2C before 2050. Impacts on people and nature will accelerate as global warming increases hydrologic (weather) extremes. The enormity of consequences demands a return to Holocene-level global temperature. Required actions include: (1) a global increas- ing price on GHG emissions accompanied by development of abundant, affordable, dispatchable clean energy, (2) East-West coopera- tion in a way that accommodates developing world needs, and (3) intervention with Earth’s radiation imbalance to phase down today’s massive human-made ‘geo-transformation’ of Earth’s climate. Current political crises present an opportunity for reset, espe- cially if young people can grasp their situation Hansen (2023) Global Warming in the pipeline (pdf) Guardian on Hansen Pipeline Paper The Earth’s climate is more sensitive to human-caused changes than scientists have realized until now, meaning that a “dangerous” burst of heating will be unleashed that will push the world to be 1.5C hotter than it was, on average, in pre-industrial times within the 2020s and 2C hotter by 2050. There is a huge amount of global heating “in the pipeline”. Such acceleration is dangerous in a climate system that is already far out of equilibrium. Michael Mann, a climate scientist at the University of Pennsylvania, said that Hansen and his co-authors are “very much out of the mainstream” in identifying an acceleration in surface heating that has “continued at a remarkably constant rate for the past few decades”. Mann said that cuts to shipping emissions have only a tiny effect on the climate system and that calls for solar geoengineering are misguided and a “very slippery slope”. Bärbel Hönisch, a paleoclimatologist at Columbia University, said she had “some reservations” about the certainties expressed in Hansen’s research about the state of the Earth’s climate millions of years ago, which helps predict the consequences of warming today. “I’d be a little more reserved, but they may well be correct – it’s a nicely written paper,” she said. “It raises a lot of questions that will trigger a lot of research that will bring our understanding forward.” Some other researchers are less skeptical of Hansen’s dire warning of supercharged global heating, highlighting his previous prescient warnings about the climate crisis that have largely played out due to decades of inaction to stem the use of fossil fuels. “I think [Hansen’s] contention that the IPCC has underestimated climate sensitivity somewhat will prove to be correct,” said Rob Jackson, a Stanford University scientist and chair of the Global Carbon Project. “It’s hard to know what’s unlikely any more in terms of warming. No fossil fuel has declined in use yet globally, not even coal. “I think Hansen’s pessimism is warranted. He stood up 35 years ago and sounded the alarm – and the world mostly ignored him, and all of us.” Milman (2023) Global heating is accelerating, warns scientist who sounded climate alarm in the 80s Axios on Hansen The paper, published Thursday in the peer-reviewed journal Oxford Open Climate Change, is a synthesis of new and previous discoveries across multiple fields. It is peppered with policy prescriptions, unusual for a scientific paper. Hansen has long straddled the line between scientist and activist. In the new paper, he recommends pursuing a range of policy options, from putting a price on carbon to geoengineering. In this study, he calls on climate scientists to embrace the responsibilities medical professionals have to their patients. He argues they have been too reticent and conservative to lay out the full ramifications of warming. The paper finds that global warming has been accelerating since 2010 and that this will soon become clear in the data. The quickening pace of warming is not well-handled by computer models. Hansen and his coauthors argue that immediate and deep cuts in greenhouse gas emissions alone won’t be sufficient to forestall dangerous levels of climate change. The paper opens the door to endorsing geoengineering, referred to as “climate restoration” in the paper, for a short period of time. This involves deliberately trying to counter warming’s effects by modifying the climate in other ways. Michael Mann, a climate researcher at the University of Pennsylvania, told Axios via email that he doesn’t believe the authors “have made the case for any of the major claims…or that climate models are getting this wrong.” He noted that ocean heat content, a key indicator of the planet’s heat budget, “shows a very steady, rather than accelerating, increase.” The fact that he puts the solutions right there in the abstract is actually exactly what needs to be done psychologically in the way that we communicate about climate change. [Freedman (2023) New study warns climate is warming even faster than some think] (https://www.axios.com/2023/11/02/climate-change-warming-james-hansen) 4.1 Climate Feedbacks Abstract Heinze Earth system models (ESMs) are key tools for providing climate projections under different sce- narios of human-induced forcing. ESMs include a large number of additional processes and feedbacks such as biogeochemical cycles that traditional physical climate models do not consider. Yet, some processes such as cloud dynamics and ecosystem functional response still have fairly high uncertainties. In this article, we present an overview of climate feedbacks for Earth system components currently included in state-of-the-art ESMs and discuss the challenges to evaluate and quantify them. Uncertainties in feedback quantification arise from the in- terdependencies of biogeochemical matter fluxes and physical properties, the spatial and temporal heterogeneity of processes, and the lack of long-term continuous observational data to constrain them. We present an outlook for promising approaches that can help to quantify and to constrain the large number of feedbacks in ESMs in the future. The target group for this article includes generalists with a background in natural sciences and an interest in climate change as well as experts working in interdisciplinary climate research (researchers, lecturers, and students). This study updates and significantly expands upon the last comprehensive overview of climate feedbacks in ESMs, which was produced 15 years ago (NRC, 2003). Heinze (2019) Climate Feedbacks (pdf) 4.2 Global Warming Pipeline Hansen ECS is the climate sensitivity defined by the Charney study, with ice sheets and GHGs fixed. Earth system sensitivity (ESS) is the complete climate sensitivity in which the climate system – including GHGs and ice sheets, which we refer to (somewhat misleadingly) as slow feedbacks – responds to the imposed forcing. During the past 800,000 years, CO 2 provided ~80% of GHG climate forcing, i.e., the total GHG forcing is 25% larger than the CO 2 forcing. The climate sensitivity in which non-CO 2 GHG feedbacks are allowed to change increases from ~4°C to ~5°C. When all feedbacks, including ice sheets, are allowed to respond to the climate forcing, the equilibrium response is approximately doubled, i.e., ESS is ~ 10°C. Charney defined an equilibrium climate sensitivity (ECS): the eventual global temperature change caused by doubled CO 2 in the idealized case in which ice sheets, vegetation and long- lived GHGs are fixed (except for the specified CO 2 doubling). All other quantities are allowed to change. The ones deemed most significant – clouds, aerosols, water vapor, snow cover and sea ice – change rapidly in response to climate change. Thus, the Charney ECS is also called the “fast feedback” climate sensitivity. Feedbacks can interact in many ways, so their changes are usually calculated in global climate models (GCMs) that can simulate such interactions. Charney implicitly assumed that change of the ice sheets on Greenland and Antarctica – which we will categorize as a “slow feedback” – was not important on the time scale of most public interest. ECS defined by Charney is a useful concept that helps us understand how human-made and natural climate forcings affect climate. We must also consider an Earth system sensitivity, 16 ESS, in which all feedbacks are allowed to respond to a climate forcing. ECS and ESS both depend on the initial climate state 17,18 and direction (warming or cooling) of climate change, but at the present climate state – with ice sheets on Antarctica and Greenland – climate should be about as sensitive in the warmer direction as in the cooler direction. Paleoclimate data indicate that ESS substantially exceeds ECS, i.e., when feedbacks that Charney kept fixed are allowed to change, climate sensitivity increases. As Earth warms, ice sheets shrink and the atmosphere contains more CO 2 , CH 4 and N 2 O, at least on glacial-interglacial time scales. e-folding how long it would take for the atmospheric CO2 levels to drop to 1/e (37%) of the atmospheric CO2 level after the addition of a pulse of CO2.* (see MODTRAN Section) The e-folding time – the time for surface temperature to reach 63% of its equilibrium response – was about a century. The physics is straightforward. If the delay were a result of a fixed source of thermal inertia, say the ocean’s well-mixed upper layer, response time would increase linearly with ECS because most climate feedbacks come into play in response to temperature change driven by the forcing, not in direct response to the forcing. Thus, a model with ECS of 4°C takes twice as long to reach full response as a model with ECS of 2°C, if the mixed layer provides the only heat capacity. However, while the mixed layer is warming, there is exchange of water with the deeper ocean, which slows the mixed layer warming. The longer response time with high ECS allows more of the ocean to come into play. If mixing into the deeper ocean is approximated as diffusive, surface temperature response time is proportional to the square of climate sensitivity. If ECS is 4°C, more warming is in the pipeline than widely assumed. Hansen (2022) Global Warming in the Pipeline (pdf) Hansen (2022) Earth’s Energy Imbalance and Climate Response Time Hansen Earth’s climate is characterized – ominously – by amplifying feedbacks and delayed response. Feedbacks and delayed response have been recognized for at least 40 years, but they are difficult to quantify. Feedbacks determine climate sensitivity to applied forcing. Delayed response makes human-made climate forcing a threat to today’s public and future generations because of the practical difficulty of reversing the forcing once consequences become apparent to the public. Thus, there is a premium on knowledge of climate sensitivity and response time, and the implications must be delivered to the public as soon as possible. The 1979 Charney study 4 considered an idealized climate sensitivity in which ice sheets and non-CO2 GHGs are fixed. The Charney group estimated that the equilibrium response to 2×CO2 , a forcing of 4 W/m2 , was 3°C, thus an ECS of 0.75°C per W/m2 , with one standard deviation uncertainty σ = 0.375°C. Charney’s estimate stood as the canonical ECS for more than 40 years. The current IPCC report concludes that 3°C for 2×CO 2 is their best estimate for ECS. We compare recent glacial and interglacial climates to infer ECS with a precision not possible with climate models alone. Uncertainty about Last Glacial Maximum (LGM) temperature has been resolved independently to find peak LGM cooling 7.0 ± 1°C (2σ, 95% confidence) at 21-18 kyBP. We show that, accounting for polar amplification, these analyses are consistent with the 5.8 ± 0.6°C LGM cooling of land areas between 45°S and 35°N using the temperature- dependent solubility of dissolved noble gases in ancient groundwater. The forcing that maintained the 7°C LGM cooling was the sum of 2.25 ± 0.45 W/m 2 (2σ) from GHGs and 3.5 ± 1.0 W/m 2 (2σ) from the LGM surface albedo, thus 5.75 ± 1.1 W/m 2 (2σ). ECS implied by the LGM is thus 1.22 ± 0.29°C (2σ) per W/m 2 , which, at this final step, we round to 1.2 ± 0.3°C per W/m 2 . For transparency, we have combined uncertainties via simple RMS (root-mean-square). ECS as low as 3°C for 2×CO 2 is excluded at the 3σ level, i.e., with 99.7% confidence. More sophisticated mathematical analysis, which has merits but introduces opportunity for prior bias and obfuscation, is not essential; error assessment ultimately involves expert judgement. Instead, focus is needed on the largest source of error: LGM surface albedo change, which is uncertain because of the effect of cloud shielding on the efficacy of the forcing. As cloud modeling is advancing rapidly, the topic is ripe for collaboration of CMIP 58 (Coupled Model Intercomparison Project) with PMIP 59 (Paleoclimate Modelling Intercomparison Project). Simulations should include at the same time change of surface albedo and topography of ice sheets, vegetation change, and exposure of continental shelves due to lower sea level. Knowledge of climate sensitivity can be advanced further via analysis of the wide climate range in the Cenozoic era. Climate response time We expected climate response time – the time for climate to approach a new equilibrium after imposition of a forcing – to become faster as mixing of heat in ocean models improved. 79 That expectation was not met when we compared two generations of the GISS GCM. The GISS (2020) GCM is demonstrably improved 34,35 in its ocean simulation over the GISS (2014) GCM as a result of higher vertical and horizontal resolution, more realistic parameterization of sub-grid scale motions, and correction of errors in the ocean computer program. Yet the time required for the model to achieve 63% of its equilibrium response remains about 100 years. There are two reasons for this, one that is obvious and one that is more interesting and informative. The Charney report recognized that clouds were a main cause of a wide range in ECS estimates. Today, clouds still cast uncertainty on climate predictions. Fast EEI response – faster than global temperature response – has a practical effect: observed EEI understates the reduction of climate forcing required to stabilize climate. Although the magnitude of this effect is uncertain, it makes the task of restoring a hospitable climate and saving coastal cities more challenging. On the other hand, long climate response time implies the potential for educated policies to affect the climate outcome before the most undesirable consequences occur. With climate in a state of disequilibrium, how much time do we have before we pass the point of no return, the point where major climate impacts are locked in, beyond our ability to control? That’s a complex matter; it requires understanding of “slow” feedbacks, especially ice sheets. It also depends on how far climate is out of equilibrium. Thus, we first consider the full Earth system sensitivity. Earth system sensitivity (ESS) The Cenozoic era – the past 66 million years – provides an opportunity to study Earth system sensitivity via a consistent analysis for climate ranging from hothouse conditions with Earth 15°C warmer and sea level 60 m higher than preindustrial climate to glacial conditions with Earth 7°C cooler and sea level 120 m lower than preindustrial. This whole-Cenozoic approach defines the CO2 history more accurately than CO2 proxy measurements. The Cenozoic provides a perspective on present greenhouse gas (GHG) levels. The dashed line in Fig. marks the “we are here” level of GHG climate forcing, which is more than half of the forcing that maintained EECO global temperature of +15°C relative to the Holocene. Today’s GHG forcing of 4.6 W/m 2 is relative to mid-Holocene CO 2 of 260 ppm; we present evidence in Section 4.3 that 260 ppm is the natural Holocene CO 2 level. GHG forcing today already is well above the level needed to deglaciate Antarctica, if the forcing is left in place long enough. We are not predicting deglaciation of Antarctica on a time scale that today’s people would care about – rather we are drawing attention to how far today’s climate is out of equilibrium with today’s GHG level. The extent that the climate is out of equilibrium with atmospheric composition is one measure of how strongly humanity is pushing the climate system. Hope of approximately stabilizing climate requires removing the disequilibrium by reducing human-made climate forcing. The danger is that – if deglaciation is allowed to get well underway – it will become difficult if not impossible to prevent large sea level rise. **Aerosols* (resumed see under Athmosphere) Earth’s energy imbalance EEI is hard to measure, a small difference between two large quantities (Earth absorbs and emits about 240 W/m 2 averaged over the entire planetary surface), but change of EEI can be well-measured from space. Absolute calibration is from the change of heat in the heat reservoirs, mainly the global ocean, over a period of at least a decade, as required to reduce error due to the finite number of places that the ocean is sampled. 87 EEI varies year-to- year, largely because global cloud amount varies with weather and ocean dynamics, but averaged over several years EEI helps inform us about what is needed to stabilize climate. EEI has doubled since the first decade of this century. This increase is one basis for our prediction of post-2010 acceleration of the global warming rate. The EEI increase may be partly due to restrictions on maritime aerosol precursor emissions imposed in 2015 and 2020, but the growth rate of GHG climate forcing also increased in 2015 and since has remained at the higher level The reduction of climate forcing required to reduce EEI to zero is greater than EEI. The added burden is a result of ultrafast cloud feedback. Cloud feedbacks are only beginning to be simulated well, but climate sensitivity near 1.2°C per W/m2 implies that the net cloud feedback is large, with clouds accounting for as much as half of equilibrium climate sensitivity. Global warming and sea level rise in the pipeline Cenozoic CO2 and climate histories reveal where climate is headed, if present human-made climate forcings remain in place. GHG climate forcing is now 4.6 W/m2 relative to the mid- Holocene (7kyBP) or 4.1 W/m2 relative to 1750. We argue that 4.6 W/m2 is the human-made forcing, but there is little point to debate whether it should be 4.6 W/m2 or 4.1 W/m2 because the GHG forcing is increasing 0.5 W/m2 per decade. One merit of consistent analysis for the full Cenozoic era is revelation that the human-made climate forcing exceeds the forcing at transition from a largely ice-free planet to glaciated Antarctica, even with inclusion of a large, negative, aerosol climate forcing. Equilibrium global warming for today’s GHG level is 10°C for our central estimate ECS = 1.2°C ± 0.3°C per W/m2 , including amplifications from disappearing ice sheets and non-CO2 GHGs. Aerosols reduce equilibrium warming to about 8°C. Equilibrium sea level change is + 60 m (about 200 feet). Hansen (2023) PipelinePaper230705 (pdf) 4.2.1 Equilibrium Warming Hansen Some people on Twitter interpreted the statement: “Equilibrium global warming including slow feedbacks for today’s human-made greenhouse gas (GHG) climate forcing (4.1 W/m2) is 10°C, reduced to 8°C by today’s aerosols” in our draft paper “Global Warming in the Pipeline” as indicating that the world is committed to warming of 10°C. The word “committed” or “commit” does not appear in our paper. If it had, it would have been in a statement such as “the world needs to commit to global cooling of about 1°C for the sake of young people and future generations.” Equilibrium warming is a useful concept employed for more than a century, e.g., in the studies by Arrhenius in the 1890s and Charney in the 1970s. Equilibrium response is the global temperature change after the climate system restores energy balance following imposition of a climate forcing. One merit of our analysis of Cenozoic (past 66 million years) climate is that it reveals that the present human-made GHG (greenhouse gas) forcing is already greater than the GHG forcing at the transition from a nearly unglaciated Antarctica to a glaciated continent. Yes, if we leave atmospheric composition as it is today, sea level will eventually rise about 60 m (200 feet). Of course, none of us would be there to see it. However, it’s not the new equilibrium at +200 feet that’s of most concern, it’s the chaos that ensues once ice sheet collapse begins in earnest. That chaos was the topic of our paper[1] “Ice Melt, Sea Level Rise and Superstorms,” which was blackballed by IPCC (Intergovernmental Panel on Climate Change). In that paper, we conclude that continuation of GHG emissions along the path that the world is on will lead to shutdown of the overturning (North Atlantic and Southern Ocean) circulations this century and sea level rise of several meters on a time scale of 50-150 years. As yet, little has changed to get us off that path. Climate Hocus-Pocus Physics is a description of the real world. So, climate science should be focused on data. That’s the way science is supposed to work. However, IPCC is focused on models. Not just global climate models (GCMs), but models that feed the models, e.g., Integrated Assessment Models (IAMs) that provide scenarios for future GHG levels. These models are useful and even necessary for analysis of the complex climate system, but sometimes the models contain hocus-pocus. As we mention in our current paper, they can assume, in effect, that “a miracle will occur.” So, the models need to be continually checked against the real world. Fig: Annual growth of climate forcing by GHGs including the part of O3 forcing not included in the CH4 forcing. MPTG and OTG are Montreal Protocol and Other Trace Gases. Figure compares the real-world growth rate of GHG forcing with the RCP2.6 scenario, which is used in IPCC’s AR5 report as a scenario that would limit global warming to about 2°C. Figure 28 shows that an enormous gap has opened between the real world and RCP2.6. The “miracle” in RCP2.6 is largely an assumption of negative emissions via power plants that burn biofuels, capturing and sequestering the CO2. Also beware of nations promising “net zero” emissions without defining what they mean. As discussed in our paper, the present policy approach is not working and it is not likely to work. For example, the cost to close the gap in Figure via carbon capture and storage is estimated as $3.4-7.0 trillion per year – that’s the annual, growing cost. That miracle is not likely to happen. It’s disappointing that scientists who once contributed to research progress, but now enjoy twittering, do not correct a nonscientist’s assumption that equilibrium warming = committed warming but instead allow the misconception to persist and then use it to insist that we are “wrong” in our assessment. Claim that current scientific literature points to eventual global warming being kept “well below 2°C” as being consistent with real world trends and policies is egregious, an uncritical acceptance of models and the assumptions that went into them. Hansen (2023) Equilibrium Warming = Committed Warming? Hausfather Media reports frequently claim that the world is facing “committed warming” in the future as a result of past emissions, meaning higher temperatures are “locked in”, “in the pipeline” or “inevitable”, regardless of the choices society takes today. The best available evidence shows that, on the contrary, warming is likely to more or less stop once carbon dioxide (CO2) emissions reach zero, meaning humans have the power to choose their climate future. The world would be around 0.4C warmer if CO2 and aerosol emissions go to zero, compared to zero CO2 emissions alone. Hausfather (2021) Explainer: Will global warming ‘stop’ as soon as net-zero emissions are reached? (NB - See critical comments in this link) 4.3 ECS - Equilibrium Climate Sensitivity ECS Climate sensitivity is defined as the equilibrium change in global and annual mean surface air temperature, \\(\\Delta T\\), due to an increment in downward radiative flux, \\(\\Delta R_{f}\\) , that would result from sustained doubling of atmospheric \\(CO_2\\) over its preindustrial value (2 x \\(CO_2\\) ). Studies based, on observations, energy balance models, temperature reconstructions, and global climate models (GCMs) have found that the probability density distribution of \\(\\Delta T\\) is peaked in the range 2.0°C ≤ \\(\\Delta T\\) ≤ 4.5°C, with a long tail of small but finite probabilities of very large temperature increases. An important parameter in climate science is the equilibrium or long-run response in the global mean surface temperature to a doubling of atmospheric carbon dioxide. In the climate science community, this is called the equilibrium climate sensitivity ECS. With reference to climate models, this is calculated as the increase in average surface temperature with a doubled CO2 concentration relative to a path with the pre-industrial CO2 concentration. This parameter also plays a key role in the geophysical components in the IAMs. Given the importance of the ECS in climate science, there is an extensive literature estimating probability density functions. These pdfs are generally based on climate models, the instrumental records over the last century or so, paleoclimatic data such as estimated temperature and radiative forcings over ice-age intervals, and the results of volcanic eruptions. Much of the literature estimates a probability density function using a single line of evidence, but a few papers synthesize different studies or different kinds of evidence. The IPCC Fifth Assessment report (AR5) reviewed the literature quantifying uncertainty in the ECS and highlighted five recent papers using multiple lines of evidence (IPCC, 2014). Each paper used a Bayesian approach to update a prior distribution based on previous evidence (the prior evidence usually drawn from instrumental records or a climate model) to calculate the posterior probability density function. Gilligham (2015) Modelling Uncertainty (pdf) 4.3.1 Roe and Baker Distribution Abstract Uncertainties in projections of future climate change have not lessened substantially in past decades. Both models and observations yield broad probability distributions for long-term increases in global mean temperature expected from the doubling of atmospheric carbon dioxide, with small but finite probabilities of very large increases. We show that the shape of these probability distributions is an inevitable and general consequence of the nature of the climate system, and we derive a simple analytic form for the shape that fits recent published distributions very well. We show that the breadth of the distribution and, in particular, the probability of large temperature increases are relatively insensitive to decreases in uncertainties associated with the underlying climate processes. Memo Roe and Baker What determines the distribution shape of ECS and in particular, the high \\(\\Delta T\\) tail? To what extent we can decrease the distribution width? Climate consists of a set of highly coupled, tightly interacting physical processes. Understanding these physical processes is a massive task that will always be subject to uncertainty. How do the uncertainties in the physical processes translate into an uncertainty in climate sensitivity? Explanations for the range of predictions of DT, summarized in (14), have focused on (i) uncertainties in our understanding of the individual physical processes (in particular, those associated with clouds), (ii) complex interactions among the individual processes, and (iii) the chaotic, turbulent nature of the climate system, which may give rise to thresholds, bifurcations, and other discontinuities, and which remains poorly understood on a theoretical level. We show here that the explanation is far more fundamental than any of these. We use the framework of feedback analysis to examine the relationship between the uncertainties in the individual physical processes and the ensuing shape of the probability distribution of \\(\\Delta T\\). Because we are considering an equilibrium temperature rise, we consider only time-independent processes. Roe and Baker (2007) Climate Sensitivity (pdf) Memo Hannart RB addressed these questions using rather simple theoretical considerations and reached the conclusion that reducing uncertainties on climate feedbacks and underlying climate processes will not yield a large reduction in the envelope of climate sensitivity. In this letter, we revisit the premises of this conclusion. We show that it results from a mathematical artifact caused by a peculiar definition of uncertainty used by these authors. Reducing inter-model spread on feedbacks does in fact induce a reduction of uncertainty on climate sensitivity, almost proportionally. Therefore, following Roe and Baker assumptions, climate sensitivity is actually not so unpredictable. The main originality of RB07 approach consists in analyzing explicitly the way uncertainties on \\(f\\), due to a limited understanding of their underlying physical processes, prop- agates into uncertainties on \\(\\Delta T\\): assuming \\(f\\) is a random variable with mean \\(f\\) and standard deviation \\(\\sigma_f\\) , RB07 uses this simple probabilistic model to highlight several fundamental properties of uncertainty propagation from feedbacks to climate sensitivity. The most prominent conclusion of this analysis is that reducing uncertainties on \\(f\\) does not yield a large reduction in the uncertainty of \\(\\Delta T\\), and thus that improvements in the understanding of physical processes will not yield large reductions in the envelope of future climate projections. We show that this conclusion is a mathematical artifact with no connection whatsoever to climate. RB07 uses the feedback analysis framework. Denoting \\(\\Delta T_0\\) the Planck temperature response to the radiative perturbation and \\(f\\) the feedback gain (RB07 refers to it as feedback factor), they obtain: \\[\\Delta T = \\frac{\\Delta T_0}{1 - f}\\] RB07 then assumes uncertainty on Planck response to be negligible so that the entire spread on \\(\\Delta T\\) results from the uncertainty on the global feedback gain \\(f\\). To model this uncertainty, RB07 assumes that \\(f\\) follows a Gaussian distribution with mean \\(\\overline{f}\\) , standard deviation \\(\\sigma_f\\) and implicit truncation for \\(f\\) &gt; 1. Then, they derive an exact expression of the distribution of \\(\\Delta T\\). This simple probabilistic climatic model is used by RB07 to analyze the way uncertainties on \\(f\\), due to a limited understanding of underlying physical processes, propagates into uncertainties on \\(\\Delta T\\). Their analysis highlights two fundamental properties: Amplification: The term in \\(\\frac{1}{1-f}\\) amplifies uncertainty on feedbacks, all the more intensely as \\(f\\) is close to (though lower than) one. Small uncertainties on feedbacks are thus converted in large uncertainties on the rise of temperature. Insensitivity: reducing uncertainty on \\(f\\) has little effect in reducing uncertainty on \\(\\Delta T\\), also stated as the breadth of the distribution of \\(\\Delta T\\) is relatively insensitive to decreases in \\(\\sigma_f\\). We are puzzled by the second property, that is, the claimed insensitivity of uncertainty on \\(\\Delta T\\) to uncertainty on feedbacks. The reason why one may find this second assertion puzzling, is that it intuitively seems to contradict the first. While the probability \\(P(\\Delta T \\in [4.5°C, 8°C])\\) may be of interest practically, this metric is irrelevant to describe the breadth of the distribution of climate sensitivity which was RB07 explicit intent. To address this question, any measure of distribution spread chosen amongst those classically used in Descriptive Statistics is more appropriate. (Hugo Mathjax don’t render correctly here:?? OK in rpad !! OK in mathjaxtest!!) With such measures when the spread of feedback parameter \\(S_f\\) decreases, the resulting spread of climate sensitivity \\(S_{\\Delta T}\\) values also decreases. Further the decrease is approximately linear for \\(S_f\\) small and tends to be steeper for larger values of \\(S_{f}\\) . Hannart on RB (pdf) Tol: RB-fitting Github Memo Jules and James Roe and Baker have attempted to justify the pdfs that have been generated as not only reasonable, but inevitable on theoretical grounds RB’s basic point is that if “feedback” \\(f\\) is considered to be Gaussian, then sensitivity = \\(\\lambda_0/(1-f)\\) is going to be skewed, which seems fair enough. Where I part company with them is when they claim that this gives rise to some fundamental and substantial difficulty in generating more precise estimates of climate sensitivity, and also that it explains the apparent lack of progress in improving on the long-standing 1979 Charney report estimate of 1.5-4.5C at only the “likely” level. Stoat’s complaints also seem pertinent: \\(f\\) cannot really be a true Gaussian, unless one is willing to seriously consider large negative sensitivity, and even though a Gaussian is a widespread and often reasonable distribution, it is hard to find any theoretical or practical basis for a Gaussian abruptly truncated at 1. I can think of several alternative theories as to why the uncertainty in the IPCC estimate has not reduced. The probabilistic methods generally used to generate these long-tailed pdfs are essentially pathological in their use of a uniform prior (under the erroneous belief that this represents “ignorance”), together with only looking at one small subset of the pertinent data at a time, and therefore do not give results that can credibly represent the opinions of informed scientists. There may also be the sociological effect of this range as some sort of anchoring device, which people are reluctant to change despite its rather shaky origins. Ramping up uncertainty (at least at the high end) is a handy lever for those who argue for strong mitigation, and it would also be naive to ignore the fact that scientists working in this area benefit from its prominence. Jules and James: Comment on RB Memo Gillingham Note that the US government used a version of the Roe and Baker distribution calibrated to three constraints from the IPCC for its uncertainty estimates (IAWG, 2010). Specifically, the IAWG Report modified the original Roe and Baker distribution to assume that the median value is 3.0°C, the probability of being between 2 and 4.5°C is two-thirds, and there is no mass below zero or above 10°C. The modified Roe and Baker distribution has a higher mean ECS than any of the models (3.5°C) and a much higher dispersion (1.6°C as compared to 0.84°C from Olsen et al. 2012). Gilligham (2015) Modelling Uncertainty (pdf) 4.3.2 GCM based Approach Gavin (2019) RealClimate (Part 1) Gavin (2020) RealClimate (Part 2) 4.3.3 GCM free Approach Memo GCM free approach The atmosphere is a complex system involving turbulent processes operating over a wide range of scales starting from millimeters at the Kolmogorov dissipation scale up to the size of the Earth, spanning over 10 orders of magni- tudes in space. The dynamics are sensitive to initial conditions and there are deterministic predictability limits that are roughly equal to the eddy turn-over time (lifetime) of structures. For planetary scale structures in the atmosphere, the overall deterministic prediction limit of about 10 days corresponds to the scaling transition timescale τ w from the weather regime to the macroweather regime. The atmospheric components of GCMs exhibit the same weather-macroweather scaling transition as the atmosphere and similar predictability limits. Beyond this horizon, the internal variability has to be interpreted stochastically so that a single GCM run is only one realization of the random process; at these timescales, weather models effectively become stochastic macroweather generators. For projec- tions over multi-decadal timescales and beyond, multi-model ensembles (MME) that include several models are used. The mean of the MME is taken to obtain the deterministic forced component of temperature variability and average out the internal variability (Collins et al. 2013). Emergent properties of the Earth’s climate, i.e. proper- ties which are not specified a priori, are then inferred from GCM simulations. The equilibrium climate sensitivity (ECS) is such a property; it refers to the expected temperature change after an infinitely long time following a doubling in carbon dioxide ( CO 2 ) atmospheric concentration. Another is the transient climate response (TCR), which is defined as the change in temperature after a gradual doubling of CO 2 atmospheric concentration over 70 years at a rate of 1% per year. However, it is not clear whether such emer- gent properties from computational models can be taken as genuine features of the natural world. The difficulty is that each GCM has its own climate (“structural uncertainty”) and this leads to very large discrepancies in ECS and TCR between GCMs; this underscores the need for qualitatively different approaches which can narrow down the properties of the real climate directly from observations. The ecological consequences of global warming could be dire; therefore, better constraining climate sensitivity is of utmost importance in order to meet the urgency of adjusting economical and environmental policies. Multidecadal climate projections rely almost exclusively on deterministic global climate models (GCMs) in spite of the fact that there are still very large structural uncertainties between Coupled Model Intercomparison Project phase 5 (CMIP5) GCMs, i.e. each has its own climate, rather than the real world climate. Climate skeptics have argued that IPCC projections are untrustworthy precisely because they are entirely GCM based. While this conclusion is unwarranted, it underscores the need for independent and qualitatively different approaches. It is therefore significant that the alternative GCM-free approach we present here yields comparable results albeit with smaller uncertainty. According to our projections made to 2100, to avert a 1.5 K warming, future emissions will be required to undergo drastic cuts similar to RCP 2.6, for which we found a 46% probability to remain under the said limit; it is virtually cer- tain that RCP 4.5 and RCP 8.5-like futures would overshoot. Even a 2.0 K warming limit would surely be surpassed by 2100 under RCP 8.5 and probably also under RCP 4.5, with only a 6% chance of remaining under the limit. The safest option remains RCP 2.6 which we project to remain under 2.0 K with very high confidence. The question remains whether it is at all realistic given that it relies strongly on the massive deployment of speculative negative emission technologies. On the other hand, our model has obvious limitations since it assumes a linear stationary relationship between forcing and temperature, neglecting nonlinear interac- tions which could arise as the system evolves, as it cur- rently warms. In particular, so-called tipping points could be reached in the coming century which would lead to a breakdown of the linear model proposed. Such potential behaviours are of critical value for improving future projections, but they have not yet been observed with high confidence even in GCMs. This underlines the need to exploit paleoclimate archives to achieve a better understanding of low-frequency natural variability, namely the transition scale from the macroweather regime to the climate regime. In this study, we have assumed the increased variability in the climate regime to be strictly a result of forcing, but internal modes of variability could also have a significant contribution for longer timescales. Climate News Network Climate Sensitivity article (Climate Dynamics) (pdf) 4.3.4 State dependence of CO2 forcing Future CO2 emissions will cause more 25% warming than CO2 emissions today The effect of increasing the concentration of atmospheric carbon dioxide (CO2) on global average surface air temperature might be expected to be constant. However, H. He et al. found that this is not the case. Doubling the atmospheric CO2 concentration increases the impact of any given increase in CO2 by about 25%, owing to changes induced in the climatological base state. The more anthropogenic CO2 emissions raise the atmospheric CO2 concentration, the more serious the consequences will be. He Abstract When evaluating the effect of carbon dioxide (CO2) changes on Earth’s climate, it is widely assumed that instantaneous radiative forcing from a doubling of a given CO2 concentration (IRF2×CO2) is constant and that variances in climate sensitivity arise from differences in radiative feedbacks or dependence of these feedbacks on the climatological base state. Here, we show that the IRF2×CO2 is not constant, but rather depends on the climatological base state, increasing by about 25% for every doubling of CO2, and has increased by about 10% since the preindustrial era primarily due to the cooling within the upper stratosphere, implying a proportionate increase in climate sensitivity. This base-state dependence also explains about half of the intermodel spread in IRF2×CO2, a problem that has persisted among climate models for nearly three decades. He (2023) State dependence of CO2 forcing and its implications for climate sensitivity 4.4 Remote Sensing of Tipping Points Many aspects of the climate are sensitive to small disrupting changes that could trigger an abrupt change in the system into a new stable state. Even at relatively low levels of global warming, systems that exhibit these instabilities could accelerate global warming through climate feedbacks or cause other cascading impacts. These ‘tipping elements’, or ‘large-scale discontinuities in the climate system’, as UNFCCC IPCC reports refer to them, have been assigned successively greater risk with each IPCC report since 2001. Proximity to a tipping point may be indicated in remote sensing data by characteristic statistical changes. Early warning indicators can be developed using an increasing trend in the lag-1 autocorrelation when it is correlated with an increase in variance. Niklas Boers of the Potsdam Institute for Climate Impact Research highlighted recent work using these characteristic statistical changes to identify the reduction in a system’s resilience, and has developed early warning indicators for Arctic sea-ice extent, Greenland ice sheet, Atlantic Meridional Overturning Circulation, the Amazon rainforest and the South American Monsoon system. The technique has also been applied to aquatic ecosystems and marine anoxic events. Automatic detection of extreme events and abrupt shifts in climate datasets using edge detection algorithms. futureearth 4.5 Exxon’s 1980s Scenario Exxon’s research warned of the risks of climate change from human-cause greenhouse gas emissions 40 years ago. Then came the ‘sea change’ at the energy company. After deepening the company’s understanding of an environmental problem it suspected could harm its business, Exxon put its muscle behind efforts to manufacture doubt about the reality of global warming. They deliberately created doubt when their internal research confirmed how serious a threat it was. Lavelle (2019) Former Exxon Scientists Tell Congress of Oil Giant’s Climate Research Before Exxon Turned to Denial "],["co2-vs-temperature-causality.html", "5 CO2 vs Temperature: Causality 5.1 Temperature lags CO2 during deglaciation 5.2 Hen-Or-Egg Causality 5.3 The 1940s CO2 Plateau 5.4 Origins of CO2 increase", " 5 CO2 vs Temperature: Causality 5.1 Temperature lags CO2 during deglaciation Shakun Abstract The covariation of carbon dioxide (CO 2 ) concentration and temperature in Antarctic ice-core records suggests a close link between CO 2 and climate during the Pleistocene ice ages. The role and relative importance of CO 2 in producing these climate changes remains unclear, however, in part because the ice-core deuterium record reflects local rather than global temperature. Here we construct a record of global surface temperature from 80 proxy records and show that temperature is correlated with and generally lags CO 2 during the last (that is, the most recent) deglaciation. Differences between the respective temperature changes of the Northern Hemisphere and Southern Hemisphere parallel variations in the strength of the Atlantic meridional overturning circulation recorded in marine sediments. These observations, together with transient global climate model simulations, support the conclusion that an antiphased hemispheric temperature response to ocean circulation changes superimposed on globally in-phase warming driven by increasing CO 2 concentrations is an explanation for much of the temperature change at the end of the most recent ice age. Shakun Memo Understanding the causes of the Pleistocene ice ages has been a significant question in climate dynamics since they were discovered in the mid-nineteenth century. The identification of orbital frequencies in the marine \\({}^{18}O/{}^{16}O\\) record, a proxy for global ice volume, in the 1970s demonstrated that glacial cycles are ultimately paced by astronomical forcing. Initial measurements of air bubbles in Antarctic ice cores in the 1980s revealed that greenhouse gas concentrations also increased and decreased over the last glacial cycle, suggesting they too may be part of the explanation. The ice-core record now extends back 800,000 yr and shows that local Antarctic temperature was strongly correlated with and seems to have slightly led changes in \\(CO_2\\) concentration. The implication of this relationship for understanding the role of \\(CO_2\\) in glacial cycles, however, remains unclear. For instance, proxy data have variously been interpreted to suggest that \\(CO_2\\) was the primary driver of the ice ages, a more modest feedback on warming or, perhaps, largely a consequence rather than cause of past climate change. Similarly, although climate models generally require greenhouse gases to explain globalization of the ice-age signal, they predict a wide range (one-third to two-thirds) in the contribution of greenhouse gases to ice-age cooling, with additional contributions from ice albedo and other effects Global temperature reconstructions and transient model simulations spanning the past century and millennium have been essential to the attribution of recent climate change, and a similar strategy would probably improve our understanding of glacial cycle dynamics. Here we use a network of proxy temperature records that provide broad spatial coverage to show that global temperature closely tracked the increase in \\(CO_2\\) concentration over the last deglaciation, and that variations in the Atlantic meridional overturning circulation (AMOC) caused a seesawing of heat between the hemispheres, supporting an early hypothesis that identified potentially important roles for these mechanisms. These findings, supported by transient simulations with a coupled ocean–atmosphere general circulation model, can explain the lag of \\(CO_2\\) behind Antarctic temperature in the ice-core record and are consistent with an important role for \\(CO_2\\) in driving global climate change over glacial cycles. The onset of deglaciation, which features about 0.3 \\({}^\\circ C\\) of global warming before the initial increase in \\(CO_2\\) ,17.5 kyr ago. \\(CO_2\\) was not the cause of initial warming. The overall correlation and phasing of global temperature and the overall correlation and phasing of global \\(CO_2\\) are consistent with \\(CO_2\\) being an important driver of global warming during the deglaciation, with the centennial- scale lag of temperature behind \\(CO_2\\) being consistent with the thermal inertia of the climate system owing to ocean heat uptake and ice melting Although other mechanisms contributed to climate change during the ice ages, climate models suggest that their impacts were regional and thus cannot explain the global extent of temperature changes documented by our stacked record alone. The lead of Antarctic temperature over global temperature indicates spatial variability in the pattern of deglacial warming. Southern Hemisphere temperature probably leads \\(CO_2\\) , consistent with the Antarctic ice-core results, Northern Hemisphere temperature lags \\(CO_2\\). Seesawing of heat between the hemispheres explains the contrast between the lead of Antarctic temperature over \\(CO_2\\) and the lag of global (and Northern Hemisphere) temperature behind \\(CO_2\\). Our global temperature stack and transient modelling point to \\(CO_2\\) as a key mechanism of global warming during the last deglaciation. Furthermore, our results support an interhemispheric seesawing of heat related to AMOC variability and suggest that these internal heat redistributions explain the lead of Antarctic temperature over \\(CO_2\\) while global temperature was in phase with or slightly lagged \\(CO_2\\). Lastly, the global proxy database suggests that parts of the northern mid to high latitudes were the first to warm after the LGM, which could have initiated the reduction in the AMOC that may have ultimately caused the increase in \\(CO_2\\) concentration. Shakun (2012) Global Warming Preceded by Increasing Carbon Dioxide Concentrations during the Last Deglaciation (pdf) Review in Skeptical Scientist 5.2 Hen-Or-Egg Causality Koutsoyiannis Abstract It is common knowledge that increasing \\(CO_2\\) concentration plays a major role in enhancement of the greenhouse effect and contributes to global warming. The purpose of this study is to complement the conventional and established theory, that increased \\(CO_2\\) concentration due to human emissions causes an increase in temperature, by considering the reverse causality. Since increased temperature causes an increase in \\(CO_2\\) concentration, the relationship of atmospheric \\(CO_2\\) and temperature may qualify as belonging to the category of “hen-or-egg” problems, where it is not always clear which of two interrelated events is the cause and which the effect. We examine the relationship of global temperature and atmospheric carbon dioxide concentration in monthly time steps, covering the time interval 1980–2019 during which reliable instrumental measurements are available. While both causality directions exist, the results of our study support the hypothesis that the dominant direction is T → \\(CO_2\\) . Changes in \\(CO_2\\) follow changes in T by about six months on a monthly scale, or about one year on an annual scale. We attempt to interpret this mechanism by involving biochemical reactions as at higher temperatures, soil respiration and, hence, \\(CO_2\\) emissions, are increasing. Koutsoyiannis Memo We develop a stochastic framework, introducing useful notions of time irreversibility and system causality while we discuss the logical and technical complications in identifying causality, which prompt us to seek just necessary, rather than sufficient, causality conditions. In the Results section, we examine the relationship of these two quantities using the modern data, available at the monthly time step. We juxtapose time series of global temperature and atmospheric CO2 concentration from several sources, covering the common time interval 1980–2019. In our methodology, it is the timing rather than the magnitude of changes that is important, being the determinant of causality. While logical, physically based arguments support the “hen-or-egg” hypothesis, indicating that both causality directions exist, interpretation of cross-correlations of time series of global temperature and atmospheric CO2 suggests that the dominant direction is T → CO2, i.e., the change in temperature leads and the change in CO2 concentration follows. We attempt to interpret this latter mechanism by noting the positive feedback loop—higher temperatures increase soil respiration and, hence, CO2 emissions. While we occasionally use the Granger statistical test, this is not central in our approach. Rather, we place the emphasis on time directionality in the relationship, which we try to identify in the simplest possible manner, i.e., by finding the lag, positive or negative, which maximizes the cross-correlation between the two processes. Another difference of our study, from most of the earlier ones, is our focus on changes, rather than current states, in the processes we investigate. This puts the technique of process differencing in central place in our analyses. This technique is quite natural and also powerful for studying time directionality. We note that differencing has also been used in a study by Humlum et al., which has several similarities with our study, even though it is not posed in a formal causality context, as well as in the study by Kodra et al. However, differencing has been criticized for potentially eliminating long-run effects and, hence, providing information only on short-run effects Data Our investigation of the relationship of temperature with concentration of carbon dioxide in the atmosphere is based on two time series of the former process and four of the latter. Specifically, the temperature data are of two origins, satellite and ground-based. The satellite dataset, developed at the University of Alabama in Huntsville (UAH), infers the temperature, T, of three broad levels of the atmosphere from satellite measurements of the oxygen radiance in the microwave band using advanced (passive) microwave sounding units on NOAA and NASA satellites [47,48]. The data are publicly available on the monthly scale in the forms of time series of “anomalies” (defined as differences from long-term means) for several parts of earth as well as in maps. Here, we use only the global average on monthly scale for the lowest level, referred to as the lower troposphere. The ground-based data series we use is the CRUTEM.4.6.0.0 global T2m land temperature [49]. This originates from a gridded dataset of historical near-surface air temperature anomalies over land. Data are available for each month from January 1850 to the present. The dataset is a collaborative product of the Met Office Hadley Centre and the Climatic Research Unit at the University of East Anglia. We note that both sources of information, UAH and CRUTEM, provide time series over the globe, land, and oceans; here, we deliberately use one source for the globe and one for the land. The two temperature series used in the study are depicted in Figure. They are consistent with each other (and correlated, r = 0.8), though the CRUTEM4 series shows a larger increasing trend than the UAH series. The differences can be explained by three reasons: (a) the UAH series includes both land and sea, while the chosen CRUTEM4 series is for land only, in which the increasing trend is substantially higher than in sea; (b) the UAH series refers to some high altitude in the troposphere (see details in Koutsoyiannis [50]), while the CRUTEM4 series refers to the ground level; and (c) the ground-based CRUTEM4 series might be affected by urbanization (many ground stations are located in urban areas). In any case, the difference in the increasing trends is irrelevant for the current study, as the timing, rather than the magnitude, of changs is the determinant of causality. Methods Stochastic Framework A recent study [30] investigated time irreversibility in hydrometeorological processes and developed a theoretical framework in stochastic terms. It also studied necessary conditions for causality, which is tightly linked to time irreversibility. A process that is not time-reversible is called time-asymmetric, time-irreversible, or time-directional. Time asymmetry of a process can be studied more conveniently (or even exclusively in a scalar process) through the differenced process. To study irreversibility in vector processes, we can use second-order moments and, in particular, cross-covariances among the different components of the vector. Time (ir)reversibility could then be characterized by studying the properties of symmetry or asymmetry of \\(r_{x̃ ỹ}( ν, η )\\) as a function of the time lag η. Time asymmetry is closely related to causality, which presupposes irreversibility. “No causal process (i.e., such that of two consecutive phases, one is always the cause of the other) can be reversible” In probabilistic definitions of causality, time asymmetry is determinant. Suppes [61] defines causation thus: “An event \\(B_{t&#39;}\\) [occurring at time t’ ] is a prima facie cause of the event \\(A_t\\) [occurring at time t] if and only if (i) t 0 &lt; t, ( ii ) P{\\(B_{t&#39;}\\) } &gt; 0, (iii) P(\\(A_t | B_{t&#39;}\\) ) &gt; P(\\(A_t\\) )”. In addition, Granger’s [62] first axiom in defining causality reads, “The past and present may cause the future, but the future cannot”. Consequently, in simple causal systems, in which the process component \\(x_τ\\) is the cause of \\(y_τ\\) (like in the clear case of rainfall and runoff, respectively), it is reasonable to expect \\(r_{x̃ỹ}[ ν, η ] ≥ 0\\) for any η ≥ 0, while \\(r_{x̃ỹ}[ ν, η ] = 0\\) for any η = 0. However, in “hen-or-egg” causal systems, this will not be the case, and we reasonably expect \\(r_{x̃ỹ}[ ν, η ] != 0\\) for any η. Yet, we can define a dominant direction of causality based on the time lag \\(η_1\\) maximizing cross-correlation. Formally, \\(η_1\\) is defined for a specified ν as \\(η_1 : = argmax |r_{x̃ỹ} ( ν, η )|\\) (over η) We can thus distinguish the following three cases: • If \\(η_1 = 0\\), then there is no dominant direction. • If \\(η_1 &gt; 0\\), then the dominant direction is \\(x_τ → y_τ\\) . • If \\(η_1 &lt; 0\\), then the dominant direction is \\(y-τ_ → x_τ\\) . It must be stressed that the above conditions are considered as necessary and not sufficient conditions for a causative relationship between the processes x τ and y . Following Koutsoyiannis [30] τ (where additional necessary conditions are discussed), we avoid seeking sufficient conditions, a task that would be too difficult or impossible due to its deep philosophical complications as well as the logical and technical ones. In essence, the “Granger causality test” studies the improvement of prediction of a process \\(y_τ\\) by considering the influence of a “causing” process \\(x_τ\\) The rejection of the null hypothesis is commonly interpreted in the literature with a statement that \\(x_τ\\) “Granger-causes” \\(y_τ\\). This is clearly a misstatement and, in fact, the entire test is based on correlation matrices. Thus, it again reflects correlation rather than causation. The rejection of the null hypothesis signifies improvement of prediction and this does not mean causation. Cohen [66] suggested replacing the term “Granger causality” with “Granger prediction” after correctly pointing out this: Results from Granger causality analyses neither establish nor require causality. Granger causality results do not reveal causal interactions, although they can provide evidence in support of a hypothesis about causal interactions. Some have thought they can approach genuine causes and get rid of the caution “correlation is not causation” by replacing the correlation with other statistics in the mathematical description of causality. For example, Liang [44] uses the concept of information (or entropy) flow (or transfer) between two processes; this method has been called “Liang causality” in the already cited work he co-authors [43]. The usefulness of such endeavours is not questioned, yet their vanity to determine genuine causality is easy to infer: using any quantity related to entropy (equivalently, information), is virtually identical to using correlation. The information flow turns out to be the correlation coefficient multiplied by a constant. In other words, the big philosophical problem of causality cannot be resolved by technical tricks. Thus, using any quantity related to entropy (equivalently, information), is virtually identical to using correlation. We assert that both causality directions exist, and we are looking for the dominant one under the current climate conditions (those manifest in the datasets we use) instead of trying to make assertions of an exclusive causality direction. Conclusion In brief, all above confirm the results of our methodology that the dominant direction of causalityis T → CO2. Physical Interpretation The omnipresence of positive lags on both monthly and annual time scales and the confirmation by Granger tests reduce the likelihood that our results are statistical artefacts. Still, our results require physical interpretation which we seek in the natural process of soil respiration. Soil respiration, R s , defined to be the flux of microbially and plant-respired CO 2 , clearly increases with temperature. It is known to have increased in the recent years [74,75]. Observational data of R s (e.g., [76,77]; see also [78]) show that the process intensity increases with temperature. Rate of chemical reactions, metabolic rate, as well as microorganism activity, generally increase with temperature. This has been known for more than 70 years (Pomeroy and Bowlus [79]) and is routinely used in engineering design. The Figure 6.1 of the latest report of the IPCC [75] provides a quantification of the mass balance of the carbon cycle in the atmosphere that is representative of recent years. The soil respiration, assumed to be the sum of respiration (plants) and decay (microbes), is 113.7 Gt C/year (IPCC gives a value of 118.7 including fire, which along with biomass burning, is estimated to be 5 Gt C/year by Green and Byrne [80]). We can expect that sea respiration would also have increased. Moreover, outgassing from the oceans must also have increased as the solubility of CO 2 in water decreases with increasing temperature [14,81]. In addition, photosynthesis must have increased, as in the 21st century the Earth has been greening, mostly due to CO 2 fertilization effects [82] and human land-use management [83]. Specifically, satellite data show a net increase in leaf area of 2.3% per decade [83]. The sums of carbon outflows from the atmosphere (terrestrial and maritime photosynthesis as well as maritime absorption) amount to 203 Gt C/year. The carbon inflows to the atmosphere amount to 207.4 Gt C/year and include natural terrestrial processes (respiration, decay, fire, freshwater outgassing as well as volcanism and weathering), natural maritime processes (respiration) as well as anthropogenic processes. The latter comprise human CO 2 emissions related to fossil fuels and cement production as well as land-use change, and amount to 7.7 and 1.1 Gt C/year, respectively. The change in carbon fluxes due to natural processes is likely to exceed the change due to anthropogenic CO 2 emissions, even though the latter are generally regarded as responsible for the imbalance of carbon in the atmosphere. The results of the study support the hypothesis that both causality directions exist, with T → CO 2 being the dominant, despite the fact that CO 2 → T prevails in public, as well as in scientific, perception. Indeed, our results show that changes in CO 2 follow changes in T by about six months on a monthly scale, or about one year on an annual scale. The opposite causality direction opens a nurturing interpretation question. We attempted to interpret this mechanism by noting that the increase in soil respiration, reflecting the fact that the intensity of biochemical process increases with temperature, leads to increasing natural CO 2 emission. Thus, the synchrony of rising temperature and CO 2 creates a positive feedback loop. Koutsoyiannis (2020) Atmospheric Temperature and CO2 : Hen-Or-Egg Causality? (pdf) *Reviewer comments to Koutsoyannis (Connolly)** On your proposed mechanism for T→CO2 In Section 6, you briefly postulate some of the mechanisms by which increasing T could cause increasing CO2. I agree with you that increasing global temperatures should lead to increasing atmospheric CO2 from increased soil respiration. Indeed, in a recent paper - ÓhAiseadha et al. (2020), we briefly pointed out that this leads to the surprising fact that the net night-time soil warming caused by wind farms is probably leading to an increase in biological CO2 emissions which may well be counteracting some (or all) of the reduction in anthropogenic CO2 emissions the wind farms are hoped to cause. You might find some of the references we cite in Section 4.2.4 of ÓhAiseadha et al. (2020) relevant for your arguments. However, I would suggest that there are other mechanisms by which global temperatures could alter atmospheric CO2 concentrations – and broadly they typically are of the same sign, i.e., more warming leading to increased atmospheric CO2 concentrations. For instance, I would also note that the solubility of CO2 in water decreases with increasing temperature. So, it is plausible that increasing temperature could also cause increasing CO2 through outgassing from the oceans. This is something we are considering for a manuscript that we are working on. However, we are still evaluating this hypothesis, as we are realising there are several unresolved issues associated with the transfer of CO2 across the surface ocean/air boundary. Nonetheless, the transfer of CO2 back and forth between the surface oceans and the atmosphere is an important component of the annual CO2 fluxes. Therefore, changes in average SST may also be contributing to changes in atmospheric CO2. Also, we still haven’t published this formally, but our current best explanation for the high seasonal variability of the Barrow (and other Arctic CO2 monitoring stations, e.g., Alert, Canada) is that it is probably related to the seasonality of sea ice. That is, when the oceans are covered by sea ice, no gaseous exchange can occur, but once the sea ice melts in the Arctic summer, CO2 can be exchanged. And because the sea surface temperature is relatively cold, the CO2 solubility is relatively high, i.e., CO2 enters the oceans. If this hypothesis is correct, then it suggests that changes in average sea ice cover from changing global temperatures might also alter atmospheric CO2. These proposed mechanisms are less well grounded in the literature than the soil respiration mechanism. However, I suggest that you should at least consider the possibility of other mechanisms. Connolly 5.2.1 Causal Structure by Information Flow Analysis Stips Abstract We use a newly developed technique that is based on the information flow concept to investigate the causal structure between the global radiative forcing and the annual global mean surface temperature anomalies (GMTA) since 1850. Our study unambiguously shows one-way causality between the total Greenhouse Gases and GMTA. Specifically, it is confirmed that the former, especially \\(CO_2\\) , are the main causal drivers of the recent warming. A significant but smaller information flow comes from aerosol direct and indirect forcing, and on short time periods, volcanic forcings. In contrast the causality contribution from natural forcings (solar irradiance and volcanic forcing) to the long term trend is not significant. The spatial explicit analysis reveals that the anthropogenic forcing fingerprint is significantly regionally varying in both hemispheres. On paleoclimate time scales, however, the cause-effect direction is reversed: temperature changes cause subsequent \\(CO_2\\) / \\(CH_4\\) changes. Stips Memo In this study, we use a recently developed mathematical method, which is capable of quantitatively evaluating the drive and feedback causal relation between time series, to address the importance of the different forcing components on climate in a quantitative but model independent way. This new method is based on the information flow (IF) concept. The whole new formalism is derived from first principles, rather than as an empirically defined ansatz, with the property of causality guaranteed in proven theorems. This is in contrast to other causality analyses, say that based on Granger causality or convergent cross mapping (CCM). The resulting formula is concise in form, involving only the common statistics, namely sample covariances. It also allows an explicit discrimination between correlation and causality: causation implies correlation, but not vice versa Causality is measured as the time rate of information flowing from one time series to another. A nonzero IF, or information transfer as it may appear in the literature, from an event to another logically tells the strength of the causality from the former to the latter, and a vanishing causality must entail a zero flow. Transfer entropy and Granger causality, the two most extensively studied formalisms of IF and causality analysis respectively, turn out to be equivalent up to a factor of 2. In causality analysis, a principle (actually the only quantitatively stated fact) that must be verified is that, when the evolution of a dynamical event (say A) is independent of another (say B), then the causality from B to A is nil. It has long been found that Granger causality and transfer entropy fail to verify this principle in many applications, giving rise to spurious causalities. Results We use this technique to analyse the recently measured global mean surface air temperature anomalies (GMTA) and various reconstructed external forcings covering the period from 1850 to 2005 (156 years). To introduce the method we calculate the information flow (IF) in nat (natural unit of information) per unit time [nat/ut] from the 156 years annual time series of global \\(CO_2\\) concentration to GMTA as 0.348 ± 0.112 nat/ut and − 0.006 ± 0.003 nat/ut in the reverse direction. Obviously, the former is significantly different from zero, while the latter, in comparison to the former, is negligible. This result unambiguously shows a one-way causality in the sense that the recent \\(CO_2\\) increase is causing the temperature increase, but not the other way around. Conclusions Using the IF concept we were able to confirm the inherent one-way causality between human activities and global warming, as during the last 150 years the increasing anthropogenic radiative forcing is driving the increasing global temperature, a result that cannot be inferred from traditional time delayed correlation or ordinary least square regression analysis. Natural forcing (solar forcing and volcanic activities) contributes only marginally to the global temperature dynamics during the last 150 years. Human influence, especially via \\(CO_2\\) radiative forcing, has been detected to be significant since about the 1960s. This provides an independent statistical confirmation of the results from process based modelling studies. On very long time scales (800,000 years) the IF is only significant in the direction from air temperature to \\(CO_2\\) . This supports the idea that the feedback of GHGs to temperature changes seems to be much slower than the fast response of temperature to changes in GHGs. The spatial explicit analysis strongly indicates that the increasing anthropogenic forcing is causing very differing effects regionally with some regions in the southern hemisphere showing large IF values. Regions of significant IF do coincide with regions having stronger than average recent warming trends. Stips (2016) On the causal structure between CO2 and global temperature (pdf) (See also rsts/Causation: Liang) 5.3 The 1940s CO2 Plateau Bastos Abstract The high-resolution CO 2 record from Law Dome ice core reveals that atmospheric CO 2 concentration stalled during the 1940s (so-called CO 2 plateau). Since the fossil- fuel emissions did not decrease during the period, this stalling implies the persistence of a strong sink, perhaps sus- tained for as long as a decade or more. Double-deconvolution analyses have attributed this sink to the ocean, conceivably as a response to the very strong El Niño event in 1940– 1942. However, this explanation is questionable, as recent ocean CO 2 data indicate that the range of variability in the ocean sink has been rather modest in recent decades, and El Niño events have generally led to higher growth rates of atmospheric CO 2 due to the offsetting terrestrial response. Here, we use the most up-to-date information on the differ- ent terms of the carbon budget: fossil-fuel emissions, four estimates of land-use change (LUC) emissions, ocean uptake from two different reconstructions, and the terrestrial sink modelled by the TRENDY project to identify the most likely causes of the 1940s plateau. We find that they greatly over- estimate atmospheric CO 2 growth rate during the plateau pe- riod, as well as in the 1960s, in spite of giving a plausible explanation for most of the 20th century carbon budget, es- pecially from 1970 onwards. The mismatch between recon- structions and observations during the CO 2 plateau epoch of 1940–1950 ranges between 0.9 and 2.0 Pg C yr −1 , depend- ing on the LUC dataset considered. This mismatch may be explained by (i) decadal variability in the ocean carbon sink not accounted for in the reconstructions we used, (ii) a further terrestrial sink currently missing in the estimates by land- surface models, or (iii) LUC processes not included in the current datasets. Ocean carbon models from CMIP5 indi- cate that natural variability in the ocean carbon sink could explain an additional 0.5 Pg C yr −1 uptake, but it is unlikely to be higher. The impact of the 1940–1942 El Niño on the observed stabilization of atmospheric CO 2 cannot be con- firmed nor discarded, as TRENDY models do not repro- duce the expected concurrent strong decrease in terrestrial uptake. Nevertheless, this would further increase the mis- match between observed and modelled CO 2 growth rate dur- ing the CO 2 plateau epoch. Tests performed using the OS- CAR (v2.2) model indicate that changes in land use not cor- rectly accounted for during the period (coinciding with dras- tic socioeconomic changes during the Second World War) could contribute to the additional sink required. Thus, the previously proposed ocean hypothesis for the 1940s plateau cannot be confirmed by independent data. Further efforts are required to reduce uncertainty in the different terms of the carbon budget during the first half of the 20th century and to better understand the long-term variability of the ocean and terrestrial CO 2 sinks. Bastos Memo Figure: Atmospheric CO 2 concentration in the Law Dome ice core and firn record from Rubino et al. (2013) and respective un- certainties (markers and whiskers) as well as the spline fit applied to the data following Enting et al. (2006), which attenuates by 50 % variations of ca. 23 years. The period corresponding to the plateau is highlighted between vertical grey lines. The blue markers cor- respond to samples from Law Dome and red markers from South Pole; different symbols indicate the different ice cores (big mark- ers) and firn samples (dots). Persistent El Niño sequences in 1895–1898 and 1911–1916 as well as the 1940s coincided with small decreases in the CO 2 growth rate. The very strong El Niño event that lasted from 1940 until 1942 (Brönnimann et al., 2004) may have been responsible for reduced upwelling of carbon-rich waters in the Eastern Pacific, causing an abnormal increase of the global ocean sink. However, this hypothesis remains controversial and, moreover, in spite of the high quality of the Law Dome δ 13 C record, the scatter and uncertainty in the data are relatively high and they affect how well it is possible to partition the biospheric and oceanic fluxes. Errors in the δ 13 C data may lead to spurious and highly correlated terres- trial and oceanic fluxes. Rafelski et al. (2009), using a single deconvolution of the CO 2 record and a simple land-surface model, pointed to an increased terrestrial sink during the 1940s. This sink was re- lated to change in temperature. Single deconvolutions do not use the δ 13 C information and assume time-invariant ocean re- sponse. When terrestrial uptake is used to explain the 1940s plateau they produce a peak in δ 13 C that appears to be incon- sistent with the ice-core δ 13 C measurements, although the differences are not large compared to the measurement un- certainties. Even if the unusually long 1940–1942 El Niño did induce strong oceanic uptake, it is not clear that it should have led to a decrease in CO 2 growth rate, as El Niño periods in recent decades have usually been associ- ated with a net increase in atmospheric CO 2 growth rate. The occurrence of El Niño leads to reduced outgassing of CO 2 in the tropical Pacific due to the slow-down of vertical upwelling of carbon and nutrient-rich subsurface waters, driven by weaker trade winds. However, the magnitude of the El Niño/Southern Oscillation (ENSO) impact on oceanic uptake differs significantly between studies, with approaches based on \\(δ^{13}\\)C analysis pointing to anomalies of 1.5–2.5 Pg C yr −1 (Keeling et al., 1995; Joos et al., 1999; Trudinger et al., 2002a), while atmospheric CO 2 -based meth- ods point to anomalies of only 0.1–0.5 Pg C yr −1. Furthermore, the enhancement of the global ocean sink during an El Niño event is usually offset by a much larger terrestrial CO 2 release due to the response of land ecosystems to widespread drought conditions in the tropics and increased fire emissions. Here, we evaluate whether it is possible to reproduce the stabilization in atmospheric CO 2 during the 1940s using model-based records of sources and sinks for the 20th cen- tury and identify possible mechanisms to explain the plateau. We first compare the atmospheric CO 2 growth rate recon- structed using these datasets with the ice-core record to test their ability to capture the plateau. Additionally, we evalu- ate whether the ocean response to the 1940–1942 El Niño may explain the atmospheric CO 2 stabilization. Finally, we analyse the response of the land sink to this event using land-surface process models and, given that land-use data are highly uncertain, test the possible contribution of LUC to ex- plain the additional sink required to match observations. Bastos Conclusion Although the oceans are likely to have contributed, they cannot by themselves provide the complete explanation of the 1940s plateau. A strong terres- trial sink is also required to match the observed stalling in atmospheric CO 2 during the period. In the case of the terrestrial sink, other processes currently not included in the models or in the LUC reconstructions may have contributed to the plateau. The ef- fects of fire occurrence, changes in nutrient availability and the devastating socioeconomic consequences of the Second World War are examples of processes currently not well rep- resented in the models. Bastos (2016) Re-evaluating the 1940s CO2 plateau (pdf) 5.4 Origins of CO2 increase Engelbeen In climate skeptics circles, there is rather much confusion about historical/present CO2 measurements. This is in part based on the fact that rather accurate historical direct measurements of CO2 in the atmosphere by chemical methods show much higher values in certain periods of time (especially around 1942), than the around 280 ppmv which is measured in Antarctic ice cores. 280 +/- 10 ppmv is assumed to be the pre-industrial amount of CO2 in the atmosphere during the current interglacial (the Holocene) by the scientific community. This is quite important, as if there were (much) higher levels of CO2 in the recent past, that may indicate that current CO2 levels are not from the use of fossil fuels, but a natural fluctuation and hence its influence on temperature is subject to (huge) natural fluctuations too and the current warmer climate is not caused by the use of fossil fuels. To be sure about my skepticism: I like to see and examine the arguments of both sides of the fence, and I make up my own mind, based on these arguments. I am pretty sure that current climate models underestimate the role of the sun and other natural variations like ocean oscillations on climate and overestimate the role of greenhouse gases and aerosols. But I am as sure that the increase of CO2 in the atmosphere since the start of the industrial revolution is mainly from the use of fossil fuels. Mass Balance The amount of CO2 emitted by humans nowadays is about 9 GtC/yr (CO2 counted as carbon). The increase in the atmosphere is about 5 GtC/yr. In any year of the past over 50 years, the emissions are larger than the increase in the atmosphere. That means that the total mass balance of all natural variables (temperature, ocean pH, vegetation) which influence CO2 levels, is always towards more sink than source over any year. The natural seasonal exchange between vegetation and oceans at one side and the atmosphere at the other side is estimated at about 150 GtC/yr. But that is not of interest for what the change is over a year, as most of the natural releases are absorbed within the same year. The difference after a year is not more than +/- 2 GtC, mainly caused by temperature changes (El Niño, Pinatubo eruption). Thus the natural variations over a year are smaller than the emissions. No matter how high the natural seasonal turnover might be, in all years over the previous near 50 years, the natural CO2 sinks were larger than the natural CO2 sources… Thus it is near impossible that natural sources were responsible for (a substantial part of) the increase of CO2 in the past 50 years. Isotopes Vegetation growth in general uses by preference 12C, thus if you measure δ13C in vegetation, you will see that it has quite low δ13C values. As almost all fossil fuels were formed from vegetation (or methanogenic bacteria, with similar preferences), these have low δ13C values too. Most other carbon sources (oceans, carbonate rock wearing, volcanic out gassing,…) have higher δ13C values. The δ13C levels as well as in the atmosphere as in the upper oceans start to decrease from 1850 on, that is at the start of the industrial revolution. In the 400 years before, there is only a small variation, probably caused by the temperature drop in the Little Ice Age. Longer term measurements of the δ13C ratio in CO2 from ice cores show that over the whole Holocene, the variations were not more than +/- 0.2 per mil. Even the change from a glacial to an interglacial period did not give more than 0.2 per mil δ13C change. Again this is a good indication of the influence of fossil fuel burning… The 14C/12C ratio: 14C is a carbon isotope that is made in the atmosphere by the impact of cosmic rays. It is an unstable (radioactive) isotope and breaks down with a half-life time of about 6,000 years. 14C is used for radiocarbon dating of not too old fossils (maximum 60,000 years). The amount of 14C in the atmosphere is variable (depends of the sun’s activity), but despite that, it allows to have a reasonable dating method. Until humans started to burn fossil fuels… The amounts of 14C in the atmosphere and in vegetation is more or less in equilibrium (as is the case for 13C: a slight depletion, due to 12C preference of the biological processes). But about halve of it returns to the atmosphere within a year, by the decay of leaves. Other parts need more time, but a lot is going back into the atmosphere within a few decades. For the oceans, the lag between 14C going into the oceans (at the North Atlantic sink place of the great conveyor belt) and its release around the equator is 500-1500 years, which gives a slight depletion of 14C, together with some very old carbonate going into solution which is completely 14C depleted. In pre-industrial times, there was an equilibrium between cosmogenic 14C production and oceanic depletion. Fossil fuels at the moment of formation (either wood for coal or plankton for oil) incorporated some 14C, but as these are millions of years old, there is no measurable 14C anymore left. Just as is the case for 13C, the amount of CO2 released from fossil fuel burning diluted the 14C content of the atmosphere. This caused problems for carbon dating from about 1890 on. Therefore a correction table is used to correct samples of after 1890. In the 1950’s another human intervention caused trouble for carbon dating: nuclear bomb testing induced a lot of radiation, which nearly doubled the atmospheric 14C content. Since then, the amount is fast reducing, as the oceans replace it with “normal” 14C levels. The half life time is about 14 years. Again, this adds to the evidence that fossil fuel burning is the main cause of the increase of CO2 in the atmosphere… The ocean’s pH and pCO2: If oceanic CO2 (from the deep oceans to the surface and further into the atmosphere) was released, this should increase the 13C/12C ratio of both the upper oceans and the atmosphere, while we see the reverse. Moreover, the release of more CO2 from the upper oceans due to a lower pH would reduce the total amount of carbon (DIC: dissolved inorganic carbon, that is CO2 + bicarbonate + carbonate) in the ocean’s surface layer. But we see the reverse trend: DIC is increasing over time [10]. Thus the increase of atmospheric CO2 is going into the oceans, not reverse. There are huge differences in oceanic pCO2 at different latitudes due to changes in temperature and DIC. This gives a permanent release of CO2 in the tropics (pCO2 of maximum 750 µatm in the upper oceans vs. about 400 µatm for the atmosphere) and a permanent sink of CO2 in the polar oceans, especially in the North-East Atlantic (minimum 150 µatm vs. 400 µatm). The oceans at mid-latitudes are seasonal emitters/absorbers of CO2, depending of the water temperature and sea life (plankton). The average yearly global difference of pCO2(atmosphere) - pCO2(oceans) is about 7 ppmv. That means that in average more CO2 is going from the atmosphere into the oceans than reverse [4]. Moreover, different surveys over time revealed that ocean parts which were net sources of CO2 gradually changed into net absorbers. Although the ocean pCO2 data are scattered in time and covered area, the trends are clear that the average (increasing) flow of CO2 is from the atmosphere into the oceans and not reverse. Engelbeen Conclusion From the available evidence it is quite clear that human emissions are the main cause of the increase of CO2 in the atmosphere. There is a small influence of temperature on this increase, as warmer oceans emit some CO2 (but warmer land absorbs more CO2 in vegetation!). The influence of temperature is limited: based on the variability of the CO2 increase around the trend, the short-term (seasons to 2-3 years) ratio is 4-5 ppmv/ºC (based on the seasonal and opposite temperature related 1992 Pinatubo and 1998 El Niño events). The very long term influence of temperature on CO2 levels (Vostok ice core) is about 8 ppmv/ºC. Thus at maximum, the influence of temperature on the current increase since the LIA is 0.8 ºC x 8 ppmv/ºC = 6.4 ppmv of the over 100 ppmv increase since the start of the industrial revolution. There are only two fast main sources of CO2 to the atmosphere, besides the burning of fossil fuels: oceans and vegetation. Vegetation is not a source of CO2, as the oxygen deficiency (see chapter 1.5) showed. Neither are the oceans, as the δ13C trend (see chapter 1.3) and the pCO2/pH trends (see chapter 1.6) shows. This is more than sufficient to be sure that human emissions are the cause of most of the increase of CO2 in the atmosphere over the past 1.6 century. Thus we may conclude: All observed evidence from measurements all over the earth show with overwhelming evidence that humans are causing the bulk of the recent increase of CO2 into the atmosphere. But… That humans are the cause of the recent increase of CO2 doesn’t tell anything about the influence of increased CO2 on temperature! 5.4.1 Anthropogenic CO2 ** Exchange Rates (turnover) vs Absorption Rates (sink capacity)** From several discussions, I know that it is quite difficult to understand the two different mechanisms which govern the fate of human CO2 in the atmosphere: the fate of individual molecules, governed by exchange rates (“turnover”) and the fate of an increase in total CO2, governed by absorption rates (sink capacity). Every year about 150 GtC of CO2 (somewhat less than 20% of the total CO2 content) is exchanged between the atmosphere and the oceans/vegetation. That means that every single CO2 molecule from human or natural origin has a 20% chance per year to be incorporated in vegetation or dissolved into the oceans. This makes that the half life time (the “residence” time) of human CO2 in the atmosphere is only about 5 years. Thus if humans emit 8 GtC in a given year, next year some 6.5 GtC is still of human origin, the rest was exchanged with CO2 from the oceans and vegetation. The second year, this still is 5.3 GtC, then 4.3 GtC, etc… This is not completely accurate, as some of the “human” CO2 comes back next year(s), especially from vegetation, as much of vegetation is one-year old leaves, which rotting returns a high part of CO2 incorporated in previous years. This is less the case for the oceans, where more of the absorbed CO2 disappears into the deep oceans, where it isn’t directly traceable anymore. There are techniques to follow human CO2 even there, where they use other recent human-made gases like CFC’s and the extra 14CO2 spike from the atomic bomb tests 1945-1960 to track the past emissions. Anyway the “half life”, that is the time period in which half of the human induced individual CO2 molecules disappears, is around 5 years. Over longer periods, humans continue to emit (currently about 9 GtC/year) CO2. The accumulation over the last years thus is 9 + 7.2 + 5.8 + 4.6 + 3.7 +… or about 40 GtC from the emissions over the past 30 years. That is only 5% of the current atmosphere… Some conclude from this that humans are only responsible for 5% of the CO2 increase and thus, as far as that influences temperature, also only for 5% of the temperature increase. But that is a wrong assumption… The previous paragraphs are about how much human induced CO2 still is in the atmosphere. That is about the origin and fate of individual CO2 molecules, which atmospheric lifetime is governed by the seasonal turnover (back and forth flows) of about 150 GtC in/out the atmosphere from/to oceans and vegetation, and has nothing to do with the fate of the extra amount of CO2 (as mass) that humans emit, neither with the increase of total amount of CO2 in the atmosphere as result of that. The latter is governed by the net amounts which year by year are incorporated into oceans and vegetation. That is only 1-7 GtC/year (variable due to temperature variability) or in average 50-55% of the emissions. The half life time of this extra CO2 (as mass) is much longer than the half life time of an individual CO2 molecule: around 40 years [14]. Thus if we should stop all CO2 emissions today, then the increase of 100 ppmv since the start of the industrial revolution would be reduced to 50 ppmv after some 40 years, further to 25 ppmv after 80 years and 12.5 ppmv after 120 years… Bern Model / Revell factor The IPCC comes with much longer half life times, according to the Bern model. This is a combination of relative fast (upper oceans), slower (deep oceans and more permanent storage in the biosphere) and very slow (rock weathering) sinks for the extra CO2. They assume that the first, relative fast, sinks of CO2 will reduce in capacity over the years. That is only true for the ocean surface layer, which follows the atmosphere quite rapidly (1-3 years), but is saturated at 10% of the change in the atmosphere, due to the buffer/Revelle factor. Some media talk about hundreds to thousands of years that the extra CO2 will reside in the atmosphere. That is true for the last part of the curve, as the smaller amounts of CO2 are getting slower and slower into the sinks. But the bulk (87.5 %) of the extra CO2 will disappear within 120 years as there is no sign of a slowdown of the sink capacity of the deep oceans and vegetation. Engelbeen (YYYY) ORIGIN OF THE RECENT CO2 INCREASE IN THE ATMOSPHERE Engelbeeb (YYYY) ABOUT SPURIOUS CORRELATIONS AND CAUSATION OF THE CO2 INCREASE Stokes: Airborne Fraction (AF) The CO2 did start to rise while our emissions were small. I remarked that this is likely due to land clearance, which transfers C from the plant biomass to air. The airborne fraction (AF) - the fraction of emission that stays in the air. I find that the added CO2 rises very linearly with total anthropogenic addition, and the AF is 44%, with very little sign of change. For the Mauna Loa period (1959-), the mass of C in the air plotted against all anthro addition (fossil + land use). It is very linear, and the regression slope is 0.439. Airborne fraction is described in AR4 Ch 7. It is often described in terms of AF of emissions, rather than total anthro. The AF is of course larger, at 55%, and is quite close to what Scripps quotes. Nick Stokes (Moyhu Blog 2014) CO2 accumulation accounted for by emission and land use Sealevel In paleoclimate reconstructions from ice cores, CO2 level changes generally lag temperature changes by hundreds of years, which is consistent with the fact that higher CO2 levels not only cause higher temperatures, but are also caused by higher ocean temperatures, and ocean temperature is slow to respond to air temperature changes. Note that the rate at which the ocean absorbs CO2 from the air is proportional to CO2’s partial pressure in the air. That’s intuitively obvious when you remember that the concentration of CO2 in the air determines the rate at which CO2 molecules collide with and are absorbed by the surface of the ocean, and falling raindrops. So the measly 3% per °C, by which CO2 solubility in water decreases as the water warms, is dwarfed by the 48% by which solubility increased as atmospheric CO2 concentration rose by 48% (from 280 ppmv to 414 ppmv), and as atmospheric CO2 level continues to rise, the rate at which the oceans remove CO2 from the air will continue to accelerate. Sealevel.info "],["co2-isotopes.html", "6 CO2 Isotopes 6.1 Suess Effect 6.2 Isotopic discrimination of land photosynthesis 6.3 Isotopic signature of Anthropocene", " 6 CO2 Isotopes NOAA Carbon-14 (or \\({}^{14}C\\)) is also known as radiocarbon, because it is the only carbon isotope that is radioactive. It is perhaps most famous for its use in radiocarbon dating of archeological artifacts ranging from mummies to cave drawings, and it plays a crucial role in studying fossil fuel carbon dioxide emissions as well. Fossil fuels are, well, fossils, and are millions of years old. Because of this, all of the radiocarbon initially present has decayed away, leaving no \\({}^{14}C\\) in this ancient organic matter. All other atmospheric carbon dioxide comes from young sources–namely land-use changes (for example, cutting down a forest in order to create a farm) and exchange with the ocean and terrestrial biosphere. This makes \\({}^{14}C\\) an ideal tracer of carbon dioxide coming from the combustion of fossil fuels. Scientists can use \\({}^{14}C\\) measurements to determine how much \\({}^{14}C\\)O2 has been diluted with \\({}^{14}C\\)-free CO2 in air samples, and from this can calculate what proportion of the carbon dioxide in the sample comes from fossil fuels. Unlike \\({}^{14}C\\), the amount of \\({}^{13}C\\) or \\({}^{12}C\\) in an artifact does not change over time since both \\({}^{13}C\\) and \\({}^{12}C\\) are stable isotopes. In other words, they do not decay. Because they are stable isotopes, a \\({}^{13}C\\) atom will always remain a \\({}^{13}C\\) atom, and the same is true for \\({}^{12}C\\). Recall that there is much, much more \\({}^{12}C\\) than \\({}^{13}C\\) in the world –almost 99% of all carbon atoms are \\({}^{12}C\\). Even so, different carbon pools have different ratios of \\({}^{13}C\\) and \\({}^{12}C\\) – called isotopic fingerprints. The differences are small - one carbon pool may have 98.8% \\({}^{12}C\\) while another may have 99.2% \\({}^{12}C\\) - but modern machines, called isotope ratio mass spectrometers, can detect these differences quite easily. Pools with relatively more \\({}^{13}C\\) (less \\({}^{12}C\\)) are called “heavy” and those with less \\({}^{13}C\\) are called “light”. Let’s look at the four main carbon pools with which climate scientists are concerned: the atmosphere, the terrestrial biosphere (land plants, animals, and soils), fossil fuels, and the ocean. The atmosphere has a certain ratio of \\({}^{13}C\\) to \\({}^{12}C\\). This ratio is affected by the isotopic fingerprint of the source of new carbon dioxide to the atmosphere. Some sources of carbon dioxide are “heavy” while others are “light”. The ratio in the atmosphere is also affected by the isotopic fingerprint of carbon dioxide sinks. Do these sinks take in a lot of \\({}^{13}C\\) or very little relative to the amount of \\({}^{12}C\\) they take up from the atmosphere? 6.1 Suess Effect So, we know that the ratio of carbon isotopes in atmospheric carbon dioxide samples is from a mixture of sources, and we also know the unique isotopic fingerprint of each of those sources. Using these two pieces of information, scientists can figure out why trends in Δ14C and δ13C occur. Globally, as atmospheric carbon dioxide levels continue to increase, both Δ14C and δ13C are decreasing over time. This is called the Suess Effect – named after Dr. Suess who first discovered this phenomenon. The steady downward trend in Δ14C of background air shows that the additional carbon dioxide added to the atmosphere must have a lower Δ14C value than what is already in the atmosphere. Well, we know that fossil fuels have a Δ14C signal of -1000‰, but that all other sources have a signal that is very close to that of ambient air (approximately + 45‰ in 2010, actually). Therefore, when CO2 from fossil fuels enter the atmosphere, the Δ14C value in the atmosphere goes down. We can precisely calculate how much the Δ14C value in the atmosphere goes down when fossil fuel CO2 is added. It turns out to be about a 3‰ decrease in Δ14C for every 1 ppm of fossil fuel CO2 added to the atmosphere. Ocean When CO2 is released from the ocean to the atmosphere, it tends to have a Δ14C value slightly lower than the atmosphere, because some of the 14C in it has had time to decay. Over the oceans, and especially in the Southern Hemisphere (which is mostly ocean!) this is the most important effect on Δ14C. Respiration However, over the land, there is another effect that we think about – carbon released from plants and soils. Carbon dioxide taken up from the atmosphere by plants is eventually released back to the atmosphere by respiration, but only after a few years (typically 10-20 years). This means that a very small amount of the 14C has decayed away, and the Δ14C value of the CO2 from respiration (when organisms use energy and release carbon dioxide as a byproduct) is different than the atmosphere. Scientists have calculated exactly how much this changes Δ14C in the atmosphere, and it turns out to be not much – to be sure though, when scientists use Δ14C measurements to calculate how much fossil fuel CO2 has been added to the atmosphere, they make a correction for this respiration effect. Nuclear Nuclear power has a much higher Δ14C value than the atmosphere (which is what caused the 14C “bomb spike” in the 1960s). 13C The relative proportion of 13C in our atmosphere is steadily decreasing over time. Before the industrial revolution, δ13C of our atmosphere was approximately -6.5‰; now the value is around -8‰. Recall that plants have less 13C relative to the atmosphere (and therefore have a more negative δ13C value of around -25‰). Most fossil fuels, like oil and coal, which are ancient plant and animal material, have the same δ13C isotopic fingerprint as other plants. The annual trend–the overall decrease in atmospheric δ13C–is explained by the addition of carbon dioxide to the atmosphere that must come from the terrestrial biosphere and/or fossil fuels. In fact, we know from Δ14C measurements, inventories, and other sources, that this decrease is from fossil fuel emissions, and is an example of the Suess Effect. Seasonal Variations Total atmospheric carbon dioxide levels (not isotopic ratios, but just total carbon dioxide) show strong seasonal variations. In the summer (in the northern hemisphere–where most of the Earth’s land sits), carbon dioxide decreases as it is fixed by plants via photosynthesis. In the fall and winter, carbon dioxide increases as many plants stop photosynthesizing and some of the carbon dioxide they fixed is released through respiration from plants, animals, and soils. Seasonal δ13C variations show the opposite pattern. δ13C increases in the summer and decreases in the winter. When plants take up carbon dioxide, they prefer 12C over 13C. This leaves relatively more 13C in the atmosphere, which increases the δ13C of the atmosphere. However, in the winter, when the plants release more carbon dioxide than they consume, this carbon dioxide entering the atmosphere is relatively poor in 13C. This decreases the δ13C of the atmosphere during the fall and winter of each year since the carbon dioxide released from the plants is relatively rich in 12C–decreasing the ratio of 13C to 12C in the atmosphere. (Northern Hemissphere). NOAA NOAA Stable Carbon and thee Carbon Cycle 6.2 Isotopic discrimination of land photosynthesis Keeling Significance Climate change and rising CO2 are altering the behavior of land plants in ways that influence how much biomass they produce relative to how much water they need for growth. This study shows that it is possible to detect changes occurring in plants using long-term measurements of the isotopic composition of atmospheric CO2. These measurements imply that plants have globally increased their water use efficiency at the leaf level in proportion to the rise in atmospheric CO2 over the past few decades. While the full implications remain to be explored, the results help to quantify the extent to which the biosphere has become less constrained by water stress globally. Keeling Abstract A decrease in the 13C/12C ratio of atmospheric CO2 has been documented by direct observations since 1978 and from ice core measurements since the industrial revolution. This decrease, known as the 13C-Suess effect, is driven primarily by the input of fossil fuel-derived CO2 but is also sensitive to land and ocean carbon cycling and uptake. Using updated records, we show that no plausible combination of sources and sinks of CO2 from fossil fuel, land, and oceans can explain the observed 13C-Suess effect unless an increase has occurred in the 13C/12C isotopic discrimination of land photosynthesis. A trend toward greater discrimination under higher CO2 levels is broadly consistent with tree ring studies over the past century, with field and chamber experiments, and with geological records of C3 plants at times of altered atmospheric CO2, but increasing discrimination has not previously been included in studies of long-term atmospheric 13C/12C measurements. We further show that the inferred discrimination increase of 0.014 ± 0.007‰ ppm−1 is largely explained by photorespiratory and mesophyll effects. This result implies that, at the global scale, land plants have regulated their stomatal conductance so as to allow the CO2 partial pressure within stomatal cavities and their intrinsic water use efficiency to increase in nearly constant proportion to the rise in atmospheric CO2 concentration. Keeling (2017) Atmospheric evidence for a global secular increase in carbon isotopic discrimination of land photosynthesis 6.3 Isotopic signature of Anthropocene Dean Abstract We consider whether the Anthropocene is recorded in the isotope geochemistry of the atmosphere, sediments, plants and ice cores, and the time frame during which any changes are recorded, presenting examples from the literature. Carbon and nitrogen isotope ratios have become more depleted since the 19th century, with the rate of change accelerating after ~ ad 1950, linked to increased emissions from fossil fuel consumption and increased production of fertiliser. Lead isotope ratios demonstrate human pollution histories several millennia into the past, while sulphur isotopes can be used to trace the sources of acid rain. Radioisotopes have been detectable across the planet since the 1950s because of atmospheric nuclear bomb tests and can be used as a stratigraphic marker. We find there is isotopic evidence of widespread human impact on the global environment, but different isotopes have registered changes at different times and at different rates. Dean (2014) Is there an isotopic signature of the Anthropocene?(pdf) "],["decoupling.html", "7 Decoupling", " 7 Decoupling Hausfather Absolute Decoupling of Economic Growth and Emissions in 32 Countries Between 1990 and 2019, global emissions of CO2 increased by 56%. Historically, economic growth has been closely linked to increased energy consumption — and increased CO2 emissions in particular — leading some to argue that a more prosperous world is one that necessarily has more impacts on our natural environment and climate. There is a lively academic debate about our ability to “absolutely decouple” emissions and growth — that is, the extent to which the adoption of clean energy technology can allow emissions to decline while economic growth continues. Over the past 15 years, however, something has begun to change. Rather than a 21st century dominated by coal that energy modelers foresaw, global coal use peaked in 2013 and is now in structural decline. These 32 countries show that it is possible to have economic growth at the same time that CO2 emissions decline, even accounting for embodied emissions in goods imported from overseas. However, these are mostly relatively wealthy countries whose economies tend to be increasingly driven by lower-energy information technology and service sectors. We have relatively few examples of low- or middle-income countries with a focus on energy-intensive manufacturing experiencing absolute decoupling to date. Absolute decoupling is possible. There is no physical law requiring economic growth — and broader increases in human wellbeing — to necessarily be linked to CO2 emissions. All of the services that we rely on today that emit fossil fuels — electricity, transportation, heating, food — can in principle be replaced by near-zero carbon alternatives, though these are more mature in some sectors (electricity, transportation, buildings) than in others (industrial processes, agriculture). Hausfather Hubacek Abstract Decoupling economic growth from resource use and emissions is a precondition to stay within planetary bound- aries. A number of countries have achieved a reduction in their production-based emissions in the past decade. However, the decline in PBE has often been achieved via outsourcing of emissions to other countries, which may even lead to higher emissions globally. Therefore, a consumption-based perspective that accounts for a country’s emissions along global supply chains should also be employed when investigating progress in decoupling. Here we investigate the progress countries made in reducing their production-based and consumption-based emissions despite growth in gross domestic product (GDP). We found that 32 out of 116 countries (mainly developed ones) achieved absolute decoupling between GDP and production-based emissions in recent years (2015–2018), and 23 countries achieved absolute decoupling between GDP and consumption-based emissions. 14 countries have de- coupled GDP growth from both production- and consumption-based emissions. Even countries that have achieved absolute decoupling are still adding emissions to the atmosphere thus showing the limits of ‘green growth’ and the growth paradigm. We also observed that decoupling can be temporary, and decoupled countries may switch back to increasing emissions, which means that continuous eﬀorts are needed to maintain decoupling. An analysis of driving factors shows that whether a country can achieve decoupling mainly depends on reducing emission intensity along domestic and import supply chains. This highlights the importance of decarbonizing supply chains and international collaboration in controlling emissions. Hubacek Conclusion The results show that 32 countries (mainly developed ones) have ab- solute decoupling between GDP and production-based emissions in re- cent years (2015–2018). However, the decline in PBE could have been achieved via outsourcing of emissions to other countries. Our analy- sis shows that only 23 countries achieved absolute decoupling between GDP and consumption-based emissions. Another 67 countries (or 58%) have relatively decoupled, and 19 (or 16%) coupled economic growth with CBE. 6 countries were in an economic recession during the study period. We also observed that decoupling can be temporary, and decou- pled countries may switch back to increasing emissions, which means that continuous eﬀorts are needed to maintain decoupling. An analysis of driving factors shows that whether a country can achieve decoupling mainly depends on reducing emission intensity along domestic and im- port supply chains. This highlights the importance of decarbonizing sup- ply chains and international collaboration in controlling emissions. While there have been some achievements in decarbonizing global value chains these have been by far not suﬃcient as overall global emis- sions have continued to rise. Even though some countries have achieved absolute decoupling, they are still adding emissions to the atmosphere thus showing the limits of ‘green growth’ and the growth paradigm. Even if all countries decouple in absolute terms, this might still not be suﬃcient to avert dangerous climate change. Therfore, decoupling can only serve as one of the indicators and steps toward fully decarbonizing the economy and society. Hubacek (2021) Evidence of Decoupling (pdf) "],["eei---earths-energy-imbalance.html", "8 EEI - Earth’s Energy Imbalance", " 8 EEI - Earth’s Energy Imbalance Trenberth EEI explained The Earth is warming from human activities, primarily because of increases in carbon dioxide and other greenhouse gases (GHGs) in the atmosphere that reduce the outgoing infrared radiation from the planet escaping to space. This creates an energy imbalance at the top-of-atmosphere (TOA) called Earth’s energy imbalance (EEI). It creates heating of the planet, which is manifested in multiple ways, only one of which is the rise in global mean surface temperature GMST. The EEI is arguably the most important metric related to climate change. It is the net result of all the processes and feedbacks in play in the climate system. However, it is also important to recognize the components of radiation at TOA, the absorbed solar radiation (ASR) and net outgoing longwave radiation (OLR). The ASR is the net incoming after reflected radiation is accounted for and varies with clouds. The net EEI is the ASR-OLR. A key reason for this breakdown relates to proposed geoengineering, in particular, so-called solar radiation management (SRM), a euphemistic name if ever there was one. SRM alters ASR while the problem is trapping of OLR. In between are all the weather systems and hydrological cycle. The radiative heat is variously transferred into sensible heat (related to temperatures), latent energy (related to changes in phase of water), potential energy (related to gravity and height), and kinetic energy (related to movement). The richness of the phenomena and transformations among these various forms of energy are what makes this problem both challenging and interesting scientifically. It is not (yet) possible to measure EEI directly, although changes measured from satellites are believed to be reliable, albeit biased. The only practical way to estimate net EEI is through an inventory of the changes in energy. Assessing EEI In our assessment of the EEI, the focus is on the well observed period from 2005 to 2019 (see section 3). The EEI is about 460 TW or globally 0.90 ± 0.15 W \\(m^−2\\). This can be compared with the net ASR and OLR of about 240 W \\(m^−2\\) as an estimate of the flow-through energy. Consequently, the EEI is very small and cannot be directly discerned or measured. Nevertheless, it is very large compared with estimated direct human influences such as the total electricity generated globally (about 5.7 TW in 2018) About 93% of the extra heat from the EEI ends up in the ocean as increasing ocean heat content (OHC). On average nearly 3% of the EEI goes into melting ice and another 4% goes into raising temperatures of land and melting permafrost, while less than 1% remains in the atmosphere. The global warming signal in OHC is large compared with the natural variability, unlike GMST, so that trends in OHC can be detected in four years. The second-best signal-to-noise ratio is in the related sea level rise (SLR), as about 40% comes from OHC and the associated expansion of the ocean, while the rest mainly comes from melting of land ice: glaciers, Greenland, Antarctica that puts more water into the ocean. For SLR the trend detection occurs in about five years while for GMST the trend detection requires more than two decades. All components of the climate system react to heating by trying to get rid of excess heat in one way or another. The most effective method overall globally is radiative cooling as higher temperatures increase radiation by the fourth power of absolute temperature. In the ocean, heating occurs from the top down; warm on top of colder water is a stable configuration so that the stability and stratification of the ocean increase. Whereas globally, GMST and SSTs have clearly increased since about the 1970s, for deeper ocean layers there is a delay that increases with depth. Globally, the top 500 m of the ocean are clearly warming since 1980, for 500–1000 m depth since 1990, 1000–1500 m layer since 1998, and from 1500 to 2000 m since 2005. Indeed, it is a major challenge for climate models to get this heat penetration right, since it depends on unresolved sub-grid scale processes like mixing and convection, and how well or whether tidal mixing is included. Under La Niña conditions the ocean stores extra heat, and then releases heat during El Niño events. All five oceans are warming, with the largest amounts of warming in the Atlantic Ocean and Southern Ocean surrounding Antarctica. That is a concern for Antarctica’s ice as warmer waters can creep under Antarctica’s ice shelves, thinning them and resulting in calving off huge icebergs. EEI observations So how well is EEI known and does it matter? Knowing how much extra energy affects weather systems and rainfall is vital to understand the increasing weather extremes. Because those weather events move energy around and help the climate system get rid of energy by radiating it to space, these processes also affect the rise in GMST. In other words, they affect the nature and magnitude of climate change, and have major implications for how well the outcomes can be modeled and predicted. There are good estimates of TOA radiation variations from Clouds and Earth’s Radiant Energy System (CERES). The exact calibration is not well known because of questions about sampling, especially clouds, but it is thought that the changes throughout the time series are reasonably reliable. There is an apparent trend in the CERES EEI of 0.4 W \\(m^−2\\) \\(decade^−1\\) for March 2000–December 2021. This trend is mainly due to an increase in ASR associated with decreased reflection by reduced Arctic sea-ice, and changes in clouds, reduced aerosols and increases in GHGs. Fig: Monthly time series of CERES EBAF Ed4.1 net radiation at the TOA (positive down) relative to an estimated mean of 0.7 W \\(m^−2\\) for 2000–2015 (blue). The mean annual cycle is removed, and the heavy black line is the 12 month running mean (includes data through 2021). The total solar irradiance contribution is in red (updated, see Coddington et al (2016)) with the mean (1361 W \\(m^−2\\)) removed, and converted to a radiative forcing by dividing by 4 and multiplying by 0.7 to account for the albedo. The Sun is often invoked as a possible source of climate change but contributions from changes in the Sun are very small. All energy from the oceans, land and ice must go through the atmosphere to reach the TOA, and the standard deviation of annual mean TOA net radiation is about three times that of the atmospheric energy tendency (figure below), highlighting that it is not atmospheric energy or temperatures so much as clouds that cause the TOA variability Fig: Times series of 12 month running means of CERES TOA radiation (black) along with total atmospheric energy change (orange), land estimate (brown) and ocean heat content changes from two sources (green and light blue). The inset gives average values for all components including land (brown) and ice (blue) in W \\(m^−2\\) for 2005–2019. The thin black line is zero. In the figure, the estimated inventory of the mean values for 2005–2019 are given. The ice time series is too small to be seen and the land values barely emerge in 2015 and 2019. Ideally, it should be possible to add up the contributions from all sources and they should agree with CERES. In the figure the agreement is reasonable from 2010 to 2016. The ability to close the TOA energy budget beyond a long-term average is improving but remains a limitation on how well it is possible to analyze what is going on in the climate system and why. Desirably, all data should be assimilated into a comprehensive Earth system model and each component initialized, to provide the starting point for predictions. The failure and indeed inability of models to match observations in the ocean, land and ice domains demonstrates their limitations, but short-term predictions are potentially a way forward to challenge and improve both models and observations. It is vital to understand the net energy gain, and how much and where heat is redistributed within the Earth system. How much heat might be moved to where it can be purged from the Earth via radiation to limit warming? Utilizing the EEI framework, the relevant observations and their synthesis challenges models and highlights needed improvements, but with prospects for major payoffs from better information about what is going on, and why, and what the outlook is for the future. Trenberth (2022) A perspective on climate change from Earth’s energy imbalance (pdf) "],["extreme-weather-events.html", "9 Extreme Weather Events", " 9 Extreme Weather Events Di Capua Abstract Extreme weather events are rising at a pace which exceeds expectations based on thermodynamic arguments only, changing the way we perceive our climate system and climate change issues. Every year, heatwaves, floods and wildfires, bring death and devastation worldwide, increasing the evidence about the role of anthropogenic climate change in the increase of extremes. In this viewpoint article, we summarize some of the most recent extremes and put them in the context of the most recent research on atmospheric and climate sciences, especially focusing on changes in thermodynamics and dynamics of the atmosphere. While some changes in extremes are to be expected and are clearly attributable to rising greenhouse gas emissions, other seem counterintuitive, highlighting the need for further research in the field. In this context, research on changes in atmospheric dynamics plays a crucial role in explaining some of these extremes and more needs to be done to improve our understanding of the physical mechanisms involved Di Capua Memo Even for lay persons it will be obvious that heat extremes will increase in a warming world. But it may be unexpected by how much: monthly heat extremes that were three standard deviations above average during the baseline period 1951–1980 have already increased over 90-fold in frequency over the global land area, while the formerly near-unprecedented 4-sigma events have increased 1000-fold to affect 3% of the land area in any given month. Marine heatwaves have also doubled in the last few decades, and they are expected to see a 23-fold increase under a 2 °C warming scenario. Part of this is as expected simply by shifting a Gaussian normal distribution towards warmer values; the more extreme an event, the larger is the factor by which its likelihood increases. However, explaining the full extent of the global increase in extreme heat requires additional, dynamical effects. And heat—especially lasting heat—is a silent killer. The death toll of the 2003 European heat wave has been estimated as ∼70 000. Since early 2012, the fingerprint of climate change can be detected in any single day in the observed record. There are no more days on Earth where global weather is not significantly different from what it would be without human influence—on nearly all days even when just considering the weather patterns without the increase in global-mean temperature. Nearly the entire Earth surface has warmed since the late 19th century (except for the prominent ‘warming hole’ south of Greenland and Iceland. The intensity and speed of warming differ by region, with land areas warming twice as much as the ocean surface since 1970. Key heatwave characteristics, such as frequency, duration and cumulative heat (i.e. the heat produced by heatwaves days inside a season), show increasing trends since 1950 at global scale, with stronger trends in tropical and northern latitudes. Trends for these key variables have been accelerating in the past few decades. While the world-wide rise in heat extremes is easily understood given the rise in global mean temperature, mean global rainfall and extreme precipitation trends depict a more complex relationship. Global rainfall is expected to increase as evaporation from warmer oceans increases. Extreme rainfall events have shown a steep increase in the last few decades (especially in tropical regions), with 1 in 4 record breaking rainfall events being attributable to climate change. Beijing was hit by a severe flood event which saw the highest rainfall record of the last 140 years (744.8 mm in less the 4 d). Perhaps counterintuitively, some areas even show opposite trends in mean precipitation rates and extreme rainfall events. One such example is the Indian summer monsoon system, which shows a slight decrease in its mean seasonal precipitation rates together with a three-fold increase in extreme rainfall events. When considering the effect of climate change on extremes, it is not enough to look at trends in mean values. Despite the global-mean (and often also local) rainfall increase, the frequency and severity of droughts has also increased in some regions, for a number of reasons. One overall reason is that with approximately constant relative humidity, air will contain (and at some point rain out) 7% more moisture per degree of warming, while the resupply of water via evaporation increases only by 2%–3% per degree. The additional evaporation and rainfall tends to end up in heavy rain rather than alleviating drought: Half of it comes down in the wettest 6 d each year and the heaviest rainfall events increase most strongly. Also, increasing agricultural and ecological droughts (i.e. loss of soil moisture and drying vegetation) can be caused not just by declining precipitation but also by rising temperatures causing faster evapotranspiration. In the past decade, wildfire activity has produced some new extreme fires that are unprecedented regarding propagation speed, intensity, location, timing and burnt area. While warm extremes are to be expected due to anthropogenic global warming, cold extreme are projected to decrease in this century. Nevertheless, despite the general increase in global surface temperatures, a few regions show a cooling trend in the historical record. One such example is central Siberia, which features a cooling trend during boreal winter. Cold air outbreaks in central Siberia and North America have been shown to result from sudden stratospheric warming events and a disruption of the stratospheric Polar vortex. In general, the largest portion of the change is to be attributed to thermodynamic effects. However, dynamic changes can further exacerbate thermodynamic driven changes and atmosphere dynamics and changes in weather patterns play an important role at regional scale. Amplified Rossby waves with preferred phase position, in particular waves with wave numbers 5 and 7, can lead to concurrent heatwaves (and crop failures) in the mid-latitudes. Arctic amplification, despite being more prominent in winter than summer, may also affect westerly winds, storm tracks and wave-guides in the mid-latitudes. Analyzing the ability of models to reproduce amplified waves 5 and 7 shows that even a small bias in upper tropospheric circulation features can have a strong impact on surface temperature and rainfall patterns. Europe has emerged as a hot-spot of heat extremes: it has seen a stronger increase in summer heat than other regions in the northern mid-latitudes. This enhanced warming has been related to dynamical changes such as an increase of double jet patterns, which could explain all of the additional rise in heat waves beyond what is expected simply by thermodynamics. Both shrinking Arctic sea ice and reduced snow cover over northern Eurasia in spring can also contribute to increased blocking over Europe and consequent frequency of heatwaves. Sea surface temperature anomalies (in particular the northern Atlantic ‘warming hole’) can also reinforce heatwaves in central Europe. Obtaining robust conclusions about changes in weather extremes requires long time series, given that extreme events are by definition rare events and are not easy to model. Nevertheless, the signal of climate change has now clearly emerged from the noise for many types of extremes. Disentangling the dynamic mechanisms is harder again and represents a current frontline of research. Di Capua (2023) Extreme weather in a changing climate "],["paleoclimate.html", "10 Paleoclimate 10.1 Holocen Thermal Maxima", " 10 Paleoclimate Earth’s paleoclimate history provides guidance with a precision and reliability that climate models cannot match. Ice cores were usually the paleoclimate data source of choice for those scientists concerned about human-made climate change. That’s understandable because ice cores provide precise data on atmospheric composition as well as climate change. However, ice cores cover only several hundred thousand years. That sounds like a long time, but Earth was mostly in ice ages during that time. The ice cores encompass several interglacial periods, but none of them were much warmer than our present global temperature. (James Hansen: Sophies Planet Ch.40) 10.1 Holocen Thermal Maxima Abstract Bova Proxy reconstructions from marine sediment cores indicate peak temperatures in the first half of the last and current interglacial periods (the thermal maxima of the Holocene epoch, 10,000 to 6,000 years ago, and the last interglacial period, 128,000 to 123,000 years ago) that arguably exceed modern warmth1,2,3. By contrast, climate models simulate monotonic warming throughout both periods4,5,6,7. This substantial model–data discrepancy undermines confidence in both proxy reconstructions and climate models, and inhibits a mechanistic understanding of recent climate change. Here we show that previous global reconstructions of temperature in the Holocene1,2,3 and the last interglacial period8 reflect the evolution of seasonal, rather than annual, temperatures and we develop a method of transforming them to mean annual temperatures. We further demonstrate that global mean annual sea surface temperatures have been steadily increasing since the start of the Holocene (about 12,000 years ago), first in response to retreating ice sheets (12 to 6.5 thousand years ago), and then as a result of rising greenhouse gas concentrations (0.25 ± 0.21 degrees Celsius over the past 6,500 years or so). However, mean annual temperatures during the last interglacial period were stable and warmer than estimates of temperatures during the Holocene, and we attribute this to the near-constant greenhouse gas levels and the reduced extent of ice sheets. We therefore argue that the climate of the Holocene differed from that of the last interglacial period in two ways: first, larger remnant glacial ice sheets acted to cool the early Holocene, and second, rising greenhouse gas levels in the late Holocene warmed the planet. Furthermore, our reconstructions demonstrate that the modern global temperature has exceeded annual levels over the past 12,000 years and probably approaches the warmth of the last interglacial period (128,000 to 115,000 years ago). Bova (2021) Nature (Paywall) "],["pattern-effect.html", "11 Pattern Effect", " 11 Pattern Effect Abtract Our planet’s energy balance is sensitive to spatial inhomogeneities in sea surface temperature and sea ice changes, but this is typically ignored in climate projections. Here, we show the energy budget during recent decades can be closed by combining changes in effective radiative forcing, linear radiative damping and this pattern effect. The pattern effect is of comparable magnitude but opposite sign to Earth’s net energy imbalance in the 2000s, indicating its importance when predicting the future climate on the basis of observations. After the pattern effect is accounted for, the best-estimate value of committed global warming at present-day forcing rises from 1.31 K (0.99–2.33 K, 5th–95th percentile) to over 2 K, and committed warming in 2100 with constant long-lived forcing increases from 1.32 K (0.94–2.03 K) to over 1.5 K, although the magnitude is sensitive to sea surface temperature dataset. Further constraints on the pattern effect are needed to reduce climate projection uncertainty. Nature article (paywall) "],["temperature-measurements.html", "12 Temperature Measurements 12.1 Hockey Stick Graph 12.2 El Niño - La Niña", " 12 Temperature Measurements Temperatures have increased over virtually the entire planet since the mid-19th century, but the warming rate has not been the same everywhere. When looking at the changes relative to the global average, it is clear the Arctic and land areas are warming faster than the ocean. 12.1 Hockey Stick Graph Wikipedia Whal abstract The Mann et al. (1998) Northern Hemisphere annual temperature reconstruction over 1400–1980 is examined in light of recent criticisms concerning the nature and pro- cessing of included climate proxy data. A systematic sequence of analyses is presented that examine issues concerning the proxy evidence, utilizing both indirect analyses via exclusion of proxies and processing steps subject to criticism, and direct analyses of principal compo- nent (PC) processing methods in question. Altogether new reconstructions over 1400–1980 are developed in both the indirect and direct analyses, which demonstrate that the Mann et al. reconstruction is robust against the proxy-based criticisms addressed. In particular, re- constructed hemispheric temperatures are demonstrated to be largely unaffected by the use or non-use of PCs to summarize proxy evidence from the data-rich North American region. When proxy PCs are employed, neither the time period used to “center” the data before PC calculation nor the way the PC calculations are performed significantly affects the results, as long as the full extent of the climate information actually in the proxy data is represented by the PC time series. Clear convergence of the resulting climate reconstructions is a strong indicator for achieving this criterion. Also, recent “corrections” to the Mann et al. reconstruc- tion that suggest 15th century temperatures could have been as high as those of the late-20th century are shown to be without statistical and climatological merit. Our examination does suggest that a slight modification to the original Mann et al. reconstruction is justifiable for the first half of the 15th century (∼ +0.05–0.10 ◦ ), which leaves entirely unaltered the primary conclusion of Mann et al. (as well as many other reconstructions) that both the 20th century upward trend and high late-20th century hemispheric surface temperatures are anomalous. Whal (2007) Robustness of the Mann, Bradley, Hughes reconstruction (pdf) 12.2 El Niño - La Niña "],["water-vapor.html", "13 Water Vapor", " 13 Water Vapor SkepticalScience The amount of water vapor in the atmosphere exists in direct relation to the temperature. If you increase the temperature, more water evaporates and becomes vapor, and vice versa. So when something else causes a temperature increase (such as extra CO2 from fossil fuels), more water evaporates. Then, since water vapor is a greenhouse gas, this additional water vapor causes the temperature to go up even further—a positive feedback. How much does water vapor amplify CO2 warming? Studies show that water vapor feedback roughly doubles the amount of warming caused by CO2. So if there is a 1°C change caused by CO2, the water vapor will cause the temperature to go up another 1°C. When other feedback loops are included, the total warming from a potential 1°C change caused by CO2 is, in reality, as much as 3°C. The other factor to consider is that water is evaporated from the land and sea and falls as rain or snow all the time. Thus the amount held in the atmosphere as water vapour varies greatly in just hours and days as result of the prevailing weather in any location. So even though water vapour is the greatest greenhouse gas, it is relatively short-lived. On the other hand, CO2 is removed from the air by natural geological-scale processes and these take a long time to work. Consequently CO2 stays in our atmosphere for years and even centuries. A small additional amount has a much more long-term effect. Generally it is held that the WV condenses out within a period of 14days. As atmospheric CO2 levels rise relentlessly week on week, month on month, year on year, atmospheric water vapour reaches a rapid equilibration according to its vapour pressure in relation to the atmospheric presure and temperature. Water vapour isn’t 10x more effective a GC than CO2. Despite the fact that the water vapour concentration of the atmosphere is 5 times that of CO2 (around 0.3% by mass for water vapour cf around 0.06% by mass for CO2), the contribution of CO2 to the greenhouse effect is at least 10% (and more like 25-30% with the water vapour feedback). Atmospheric CO2 doesn’t fall out of the atmosphere. As we pump CO2 into the atmosphere it accumulates day by day, month by month, year by year. That can’t happen with water vapor. Atmospheric CO2 concentrations rise cumulatively (and very very quickly now). The water vapour that we pump into the atmosphere is a tiny supplement to the natural evaporative/precipitation cycle, and since this comes straight out of the lower atmosphere within a week or two it can (a) have only a very small effect and (b) caanot be cumulative. Man can’t “add” water vapour to the atmosphere. The atmospheric water vapour levels are essentially “defined” by the atmospheric temperature and pressure. What happens to all of that water (e.g the vast amount from natural evaporation)?. It all comes straight out as precipitation. What stays in the atmosphere is what the atmosphere can support in relation to the atmospheric temperature and pressure. In fact the research indicates that the atmosphere tends to maintain a relatively constant relative humidity. SkepticalScience ACS It’s true that water vapor is the largest contributor to the Earth’s greenhouse effect. On average, it probably accounts for about 60% of the warming effect. However, water vapor does not control the Earth’s temperature, but is instead controlled by the temperature. This is because the temperature of the surrounding atmosphere limits the maximum amount of water vapor the atmosphere can contain. If a volume of air contains its maximum amount of water vapor and the temperature is decreased, some of the water vapor will condense to form liquid water. This is why clouds form as warm air containing water vapor rises and cools at higher altitudes where the water condenses to the tiny droplets that make up clouds. The greenhouse effect that has maintained the Earth’s temperature at a level warm enough for human civilization to develop over the past several millennia is controlled by non-condensable gases, mainly carbon dioxide, CO2, with smaller contributions from methane, CH4, nitrous oxide, N2O, and ozone, O3. Since the middle of the 20th century, small amounts of man-made gases, mostly chlorine- and fluorine-containing solvents and refrigerants, have been added to the mix. Because these gases are not condensable at atmospheric temperatures and pressures, the atmosphere can pack in much more of these gases . Thus, CO2 (as well as CH4, N2O, and O3) has been building up in the atmosphere since the Industrial Revolution when we began burning large amounts of fossil fuel. If there had been no increase in the amounts of non-condensable greenhouse gases, the amount of water vapor in the atmosphere would not have changed with all other variables remaining the same. The addition of the non-condensable gases causes the temperature to increase and this leads to an increase in water vapor that further increases the temperature. This is an example of a positive feedback effect. The warming due to increasing non-condensable gases causes more water vapor to enter the atmosphere, which adds to the effect of the non-condensables. There is also a possibility that adding more water vapor to the atmosphere could produce a negative feedback effect. This could happen if more water vapor leads to more cloud formation. Clouds reflect sunlight and reduce the amount of energy that reaches the Earth’s surface to warm it. If the amount of solar warming decreases, then the temperature of the Earth would decrease. In that case, the effect of adding more water vapor would be cooling rather than warming. But cloud cover does mean more condensed water in the atmosphere, making for a stronger greenhouse effect than non-condensed water vapor alone – it is warmer on a cloudy winter day than on a clear one. Thus the possible positive and negative feedbacks associated with increased water vapor and cloud formation can cancel one another out and complicate matters. The actual balance between them is an active area of climate science research. ACS Trenberth It is the well-known positive feedbacks within the climate system that play off the changes otherwise forced on the climate system and amplify the changes. They depend on the temperature changes and heating already going on. Most notable is water vapour feedback. As the Earth and its oceans warm up, the water-holding capacity of the atmosphere increases at a rate of about 7% per degree Celsius (or about 4% per degree Fahrenheit). And the record high sea temperatures ensure that there is more moisture in the form of water vapour in the atmosphere as a result. Estimates are 5 to 15% relative to prior to the 1970s, when global temperature increases began in earnest. But water vapour is a powerful greenhouse gas. The increases have likely increased global heating by an amount comparable to that from increases in carbon dioxide. And we are seeing the consequences! In the current climate, for average all-sky conditions, water vapour is estimated to account for 50% of the greenhouse effect, carbon dioxide 19%, ozone 4%, and other gases 3%; while clouds make up a quarter of the greenhouse effect. The main greenhouse gases of carbon dioxide, ozone, methane, and nitrous oxide do not condense and precipitate as water vapour does. The result is orders of magnitude differences in the lifetime of these gases (decades to centuries) compared with about nine days for water vapour. It is because of this vigorous hydrological cycle the average atmospheric life of a water vapour molecule is just 9 days. Although the main water vapour increases may be near the surface, upper tropospheric water vapour is more critically important for the net greenhouse effect. Trenberth (2023) How rising water vapour in the atmosphere is amplifying warming and making extreme weather worse "],["albedo.html", "14 Albedo", " 14 Albedo Some text on Albedo "],["atmosphere.html", "15 Atmosphere 15.1 Emissions 15.2 Aerosols 15.3 Ozone Layer 15.4 Stratosphere shrinking 15.5 Contrails 15.6 Clouds 15.7 Attributing Emissions", " 15 Atmosphere - Emissions - CO2 - NO2 - Methane - - Attributing Emissions - Norway&#39;s Responsibility 15.1 Emissions Fig: Cumulative Emissions 1751-2018 by Country/Region The UK (like the US) is 5X more responsible for global warming than the average nation. 15.1.1 Volcanos Dessler The most well-known effect of volcanic eruptions is to cool the climate. This comes from the injection of sulfur gases into the stratosphere. Once in the stratosphere, the sulfur combines with water vapor to form little droplets referred to as volcanic aerosols. These tiny particles reflect incoming sunlight back to space, acting like a shade over the Earth’s surface, leading to a cooling effect. For most eruptions, this is the dominant effect. The 1991 eruption of Mt. Pinatubo, for example, released enough sulfur to cool the climate by about 0.5C for a few years after the eruption. A more dramatic example of the cooling effect of volcanic eruptions occurred in 1816, often referred to as the “Year Without a Summer”. The eruption of Mt. Tambora in Indonesia the previous year had released an enormous quantity of sulfur into the stratosphere, leading to a drastic decrease in global temperatures. The Northern Hemisphere experienced unseasonable frosts, snowfalls, and prolonged cold during summer, resulting in widespread crop failures, skyrocketing food prices, and severe famine. This unusual and grim weather influenced the arts, most notably by confining Mary Shelley indoors, where she began penning her iconic novel, Frankenstein. HT did inject sulfur gases into the stratosphere (0.4 MtSO2), but far less than Mt. Pinatubo did (~20 MtSO2). Thus, we expect it to produce a relatively small cooling effect. HT did inject sulfur gases into the stratosphere (0.4 MtSO2), but far less than Mt. Pinatubo did (~20 MtSO2). Thus, we expect it to produce a relatively small cooling effect. The overall impact of HT will therefore be the net difference between the cooling effect of aerosols and the warming effect of water vapor. I am presently working with a group led by Dr. Mark Schoeberl on a publication estimating these terms, which is presently in peer review, so I won’t comment on our results other than to say they’re generally consistent with previous work. Here is a summary of what others have found: Jenkins et al.: They just calculated the warming impact of water vapor and concluded that it would increase the global average surface temperature by a few hundredths of a degree. Zhang et al.: They included both aerosol cooling and water vapor warming and concluded: “Ts will decrease by about 0.0315–0.1118°C in the next 1–2 years”. Zhu et al.: They concluded that the net effect of the volcano would be to cool, with total radiative forcing of around -0.2 W/m^2. Most of the water was sent really high into the stratosphere, above 25 km. At that height, water has a minimal effect on the climate. Dessler (2023) The climate impact of the Hunga-Tonga volcanic eruption 15.1.2 Anual Greenhouse Gas Index (AGGI) Figure shows radiative forcing for CO2, CH4, N2O and groupings of gases that capture changes predominantly in the CFCs, HCFCs, and the HFCs through 2021. Carbon dioxide is by far the largest contributor to total forcing from these gases and methane is the second largest contributor. Figure: Radiative forcing, relative to 1750, of virtually all long-lived greenhouse gases. The NOAA Annual Greenhouse Gas Index (AGGI), which is indexed to 1 for the year 1990, is shown on the right axis. The “CFC” grouping includes some other long-lived gases that are not CFCs (e.g., CCl4, CH3CCl3, and Halons), but the CFCs account for the majority (95% in 2021) of this radiative forcing. The “HCFC” grouping includes the three most abundant of these chemicals (HCFC-22, HCFC-141b, and HCFC-142b). The “HFC” grouping includes the most abundant HFCs (HFC-134a, HFC-23, HFC-125, HFC-143a, HFC-32, HFC-152a, HFC-227ea, and HFC-365mfc) and SF6 for completeness, although SF6 only accounted for a small fraction of the radiative forcing from this group in 2021 (13%). Figure: Pre-1978 changes in the CO2-equivalent abundance and AGGI based on the ongoing measurements of all greenhouse gases reported here, measurements of CO2 going back to the 1950s from C.D. Keeling [Keeling et al., 1958], and atmospheric changes derived from air trapped in ice and snow above glaciers [Machida et al., 1995, Battle et al., 1996, Etheridge, et al., 1996; Butler, et al., 1999]. Equivalent CO2 atmospheric amounts (in ppm) are derived with the relationship (Table 1) between CO2 concentrations and radiative forcing from all long-lived greenhouse gases. NOAA AGGI 15.1.3 CO2 NOAA Global Monitoring Center NOAA Global Monitoring Center James Hansen The CO2 growth rate (Fig. 5) is now a bit below the peaks that occur in conjunction with strong El Ninos. However, the CO2 growth rate is not declining. CO2 growth has not even slowed as a result of the reduced economic activity associated with Covid-19. James Hansen 13 May 2021 15.1.3.1 Measurement of CO2 Mauna Loa Ryan Abstract A continuous 37 year record of the quiescent CO2 outgassing of Mauna Loa volcano was derived from atmospheric measurements made 6 km downslope of the summit caldera at Mauna Loa Observatory. The volcanic plume is sometimes trapped in the temperature inversion near the ground at night and transported downslope to the observatory. The amount of volcanic CO2 was greatest shortly after the 1975 and 1984 eruptions and then decreased exponentially with decay constants of 6.5 and 1.6 years respectively. Between 1959 and 1973 the decay constant was 6.1 years. The total reservoir mass of CO2 during each of the three quiescent periods was similar and estimated to be between 2 X 108 kg and 5 X 108 kg (0.2 Mt to 0.5 Mt). The 1975 eruption may have been preceded by a small increase in CO2 emissions. A similar increase has occurred since early 1993. Condensation nuclei (CN), presumably consisting of sulfate aerosol, were measured in the volcanic plume throughout the 1974 to 1994 record. The post-1975 period had consistently high levels of CN. Between 1977 and 1980, light-scattering aerosols were detected, coincident with a period of visible fuming at the summit. CN levels after the 1984 eruption were greatly reduced. Two brief periods of low CN emissions during this time correlate with temporary halts or reductions in the rate of summit expansion. These temporary reversals in the inflation of the mountain did not affect the steady exponential decline of the CO2 emissions rate. Upper limits were set on the amounts of H2O, O3, CH4, SO2, aerosol carbon, radon, CO, and H2 present in the plume at various periods between 1974 and 1993. The ratio of SO2 to CO2 was less than 1.8 X 10-3 between 1988 and 1992. Ryan (1995) Quiescent Outgassing of Mauna Loa Volcano 1958-1994 NOAA Mauna Loa Observatory dto. Measurement Methods Wet Chemical Analysis Beck Abstract More than 90,000 accurate chemical analyses of CO2 in air since 1812 are summarised. The historic chemical data reveal that changes in CO2 track changes in temperature, and therefore climate in contrast to the simple, monotonically increasing CO2 trend depicted in the post-1990 literature on climate-change. Since 1812, the CO2 concentration in northern hemispheric air has fluctuated exhibiting three high level maxima around 1825, 1857 and 1942 the latter showing more than 400 ppm. Between 1857 and 1958, the Pettenkofer process was the standard analytical method for determining atmospheric carbon dioxide levels, and usually achieved an accuracy better than 3%. These determinations were made by several scientists of Nobel Prize level distinction. Following Callendar (1938), modern climatologists have generally ignored the historic determinations of CO2, despite the techniques being standard text book procedures in several different disciplines. Chemical methods were discredited as unreliable choosing only few which fit the assumption of a climate CO2 connection. Beck (2007) “180 years of CO2 analysis by chemical methods” (paywall) Beck (pdf) Keeling on Beck Beck questions whether the rise in atmospheric CO2 over the past 50 years is truly unprecedented, citing observations that appear to indicate much higher variability inj the 19th and 20th centuries. If Beck’s contentions were true, they would overthrow 50 years of scientific advance and discovery. Unfortunately for Beck - as well as for humanity - yhe claim’s don’t stand up. As Keeling grasped already in 1957 - before ha had shown that CO2 was increasing - the earlier chemical measurements exhibit far too much geographic and short-term variability to plausibly be reprenstaive of the background. The variablility of these early measurements must therefore be attributed to “local or regional” factors or poor measurement practice. Keeling on Beck “180 years of CO2 analysis by chemical methods” 15.1.3.2 Antropogenic CO2 Figure Source How do we know that recent CO2 increases are due to human activities? RealClimate RealClimate Simple Explanation realClimate Technical NOAA Isotopes Measurement O’Connor Abstract: In this work, a semi-empirical relationship of carbon dioxide emissions with atmospheric CO 2 concentrations has been developed that is capable of closely replicating observations from 1751 to 2018. The analysis was completed using data from fossil-fuel-based and land-use change based CO 2 emissions, both singly and together. Evaluation of emissions data from 1750 to 1890 yields a linear CO 2 concentration component that may be attributed to the net flux from land-use changes combined with a rapidly varying component of the terrestrial sink. This linear component is then coupled across the full-time period with a CO 2 concentration calculation using fossil-fuel combustion/cement production emissions with a single, fixed fossil-fuel combustion airborne fraction [AF FF ] value that is determined by the ocean sink coupled with the remaining slowly varying component of the land sink. The analysis of the data shows that AF FF has remained constant at 51.3% over the past 268 years. However, considering the broad range of variables including emission and sink processes influencing the climate, it may not be expected that a single value for AF FF would accurately reproduce the measured changes in CO 2 concentrations during the industrial era. O’Connor (2020) Modeling of Atmospheric Carbon Dioxide (CO2) Concentrations as a Function of Fossil-Fuel and Land-Use Change CO2 Emissions Coupled with Oceanic and Terrestrial Sequestration (pdf) (pdf SI) 15.1.3.3 C14 Measurement Basu We report national scale estimates of CO2 emissions from fossil-fuel combustion and cement production in the United States based directly on atmospheric observations, using a dual-tracer inverse modeling framework and CO2 and Δ14CO2 measurements obtained primarily from the North American portion of the National Oceanic and Atmospheric Administration’s Global Greenhouse Gas Reference Network. The derived US national total for 2010 is 1,653 ± 30 TgC yr−1 with an uncertainty (1σ) that takes into account random errors associated with atmospheric transport, atmospheric measurements, and specified prior CO2 and 14C fluxes. The atmosphere-derived estimate is significantly larger (&gt;3σ) than US national emissions for 2010 from three global inventories widely used for CO2 accounting, even after adjustments for emissions that might be sensed by the atmospheric network, but which are not included in inventory totals. It is also larger (&gt;2σ) than a similarly adjusted total from the US Environmental Protection Agency (EPA), but overlaps EPA’s reported upper 95% confidence limit. In contrast, the atmosphere-derived estimate is within 1σ of the adjusted 2010 annual total and nine of 12 adjusted monthly totals aggregated from the latest version of the high-resolution, US-specific “Vulcan” emission data product. Derived emissions appear to be robust to a range of assumed prior emissions and other parameters of the inversion framework. While we cannot rule out a possible bias from assumed prior Net Ecosystem Exchange over North America, we show that this can be overcome with additional Δ14CO2 measurements. These results indicate the strong potential for quantification of US emissions and their multiyear trends from atmospheric observations. Basu (2020) Estimating US fossil fuel CO2 emissions from measurements of C14 in atmospheric CO2 15.1.3.4 Globale CO2 Rise The global CO2 rise: Facts and Denial Tricks RealClimate 15.1.3.5 Turnover time Climate Myth: CO2 has a short residence time “[T]he overwhelming majority of peer-reviewed studies [find] that CO2 in the atmosphere remained there a short time.” The claim goes like this: Predictions for the Global Warming Potential (GWP) by the IPCC express the warming effect CO2 has over several time scales; 20, 100 and 500 years. But CO2 has only a 5 year life time in the atmosphere. Therefore CO2 cannot cause the long term warming predicted by the IPCC. This claim is false. (A) is true. (B) is also true. But B is irrelevant and misleading so it does not follow that C is therefore true. The claim hinges on what life time means. To understand this, we have to first understand what a box model is: In an environmental context, systems are often described by simplified box models. A simple example (from school days) of the water cycle would have just 3 boxes: clouds, rivers, and the ocean. A representation of the carbon cycle (ignore the numbers for now) would look like this one from NASA. In the IPCC 4th Assessment Report glossary, “lifetime” has several related meanings. The most relevant one is: “Turnover time (T) (also called global atmospheric lifetime) is the ratio of the mass M of a reservoir (e.g., a gaseous compound in the atmosphere) and the total rate of removal S from the reservoir: T = M / S. For each removal process, separate turnover times can be defined. In soil carbon biology, this is referred to as Mean Residence Time.” In other words, life time is the average time an individual particle spends in a given box. It is calculated as the size of box (reservoir) divided by the overall rate of flow into (or out of) a box. The IPCC Third Assessment Report 4.1.4 gives more details. In the carbon cycle diagram above, there are two sets of numbers. The black numbers are the size, in gigatonnes of carbon (GtC), of the box. The purple numbers are the fluxes (or rate of flow) to and from a box in gigatonnes of carbon per year (Gt/y). A little quick counting shows that about 200 Gt C leaves and enters the atmosphere each year. As a first approximation then, given the reservoir size of 750 Gt, we can work out that the residence time of a given molecule of CO2 is 750 Gt C / 200 Gt C y-1 = about 3-4 years. (However, careful counting up of the sources (supply) and sinks (removal) shows that there is a net imbalance; carbon in the atmosphere is increasing by about 3.3 Gt per year). It is true that an individual molecule of CO2 has a short residence time in the atmosphere. However, in most cases when a molecule of CO2 leaves the atmosphere it is simply swapping places with one in the ocean. Thus, the warming potential of CO2 has very little to do with the residence time of CO2. What really governs the warming potential is how long the extra CO2 remains in the atmosphere. CO2 is essentially chemically inert in the atmosphere and is only removed by biological uptake and by dissolving into the ocean. Biological uptake (with the exception of fossil fuel formation) is carbon neutral: Every tree that grows will eventually die and decompose, thereby releasing CO2. (Yes, there are maybe some gains to be made from reforestation but they are probably minor compared to fossil fuel releases). Dissolution of CO2 into the oceans is fast but the problem is that the top of the ocean is “getting full” and the bottleneck is thus the transfer of carbon from surface waters to the deep ocean. This transfer largely occurs by the slow ocean basin circulation and turn over (*3). This turnover takes 500-1000ish years. Therefore a time scale for CO2 warming potential out as far as 500 years is entirely reasonable (See IPCC 4th Assessment Report Section 2.10). SkepticalScience 15.1.4 LNG Howarth Abstract Before 2016, the export of liquefied natural gas (LNG) from the United States was banned, but since that time exports have risen rapidly, fueled in part by the rapid growth in shale gas production. Today the United States is the largest exporter of LNG. This paper presents a full lifecycle assessment for greenhouse gas emissions from LNG. These emissions depend on the type of tanker used to transport the LNG, with emissions far larger when LNG is transported by older, steam-powered tankers burning heavy fuel oil. The largest source of emissions in this case is from venting of methane lost by evaporation from the storage tanks, called boil off. More modern tankers, whether powered by steam or 4-stroke or 2-stroke engines, can capture this boil-off methane and use it for their power, thereby greatly lowering methane emissions. For scenarios for LNG that is transported by more modern tankers, the single largest source of emissions in the full lifecycle are those from the production, processing, storage, and transport of the natural gas that comprises the feedstock for LNG. Fugitive emissions of unburned methane are particularly important, but so are the carbon dioxide emissions from the energy intensive processes behind modern shale gas extraction. In all of the scenarios considered, across all types of tankers used to transport LNG, methane emissions exceed emissions of carbon dioxide from the final combustion of LNG. Carbon dioxide emissions other than from this final combustion are significant, but smaller than the carbon dioxide from the final combustion. While some proponents of LNG have argued it has a climate benefit by replacing coal, the analysis presented here disproves this. Across all scenarios considered, total greenhouse gas emissions from LNG are larger than those from coal, ranging from 24% to 274% greater. Howarth (2023) The Greenhouse Gas Footprint of Liquefied Natural Gas (LNG) Exported from the United States (pdf) 15.1.5 Carbon Cycle Figure: Simplified schematic of the global carbon cycle. Numbers represent reservoir mass, also called ‘carbon stocks’ in PgC (1 PgC = 10 15 gC) and annual carbon exchange fluxes (in PgC yr –1 ). Black numbers and arrows indicate reservoir mass and exchange fluxes estimated for the time prior to the Industrial Era, about 1750 (see Section 6.1.1.1 for references). Fossil fuel reserves are from GEA (2006) and are consistent with numbers used by IPCC WGIII for future scenarios. The sediment storage is a sum of 150 PgC of the organic carbon in the mixed layer (Emerson and Hedges, 1988) and 1600 PgC of the deep-sea CaCO 3 sediments available to neutralize fossil fuel CO 2 (Archer et al., 1998). Red arrows and numbers indicate annual ‘anthropogenic’ fluxes averaged over the 2000–2009 time period. These fluxes are a perturbation of the carbon cycle during Industrial Era post 1750. These fluxes (red arrows) are: Fossil fuel and cement emissions of CO 2 (Section 6.3.1), Net land use change (Section 6.3.2), and the Average atmospheric increase of CO 2 in the atmosphere, also called ‘CO 2 growth rate’ (Section 6.3). The uptake of anthropogenic CO 2 by the ocean and by terrestrial ecosystems, often called ‘carbon sinks’ are the red arrows part of Net land flux and Net ocean flux. Red numbers in the reservoirs denote cumulative changes of anthropogenic carbon over the Industrial Period 1750–2011 (column 2 in Table 6.1). By convention, a positive cumulative change means that a reservoir has gained carbon since 1750. The cumulative change of anthropogenic carbon in the terrestrial reservoir is the sum of carbon cumulatively lost through land use change and carbon accumulated since 1750 in other ecosystems (Table 6.1). Note that the mass balance of the two ocean carbon stocks Surface ocean and Intermediate and deep ocean includes a yearly accumulation of anthropogenic carbon (not shown). Uncertainties are reported as 90% confidence intervals. Emission estimates and land and ocean sinks (in red) are from Table 6.1 in Section 6.3. The change of gross terrestrial fluxes (red arrows of Gross photosynthesis and Total respiration and fires) has been estimated from CMIP5 model results (Section 6.4). The change in air–sea exchange fluxes (red arrows of ocean atmosphere gas exchange) have been estimated from the difference in atmospheric partial pressure of CO 2 since 1750 (Sarmiento and Gruber, 2006). Individual gross fluxes and their changes since the beginning of the Industrial Era have typical uncertainties of more than 20%, while their differences (Net land flux and Net ocean flux in the figure) are determined from independent measurements with a much higher accuracy (see Section 6.3). Therefore, to achieve an overall balance, the values of the more uncertain gross fluxes have been adjusted so that their difference matches the Net land flux and Net ocean flux estimates. Fluxes from volcanic eruptions, rock weathering (silicates and carbonates weathering reactions resulting into a small uptake of atmospheric CO 2 ), export of carbon from soils to rivers, burial of carbon in freshwater lakes and reservoirs and transport of carbon by rivers to the ocean are all assumed to be pre-industrial fluxes, that is, unchanged during 1750–2011. Some recent studies (Section 6.3) indicate that this assumption is likely not verified, but global estimates of the Industrial Era perturbation of all these fluxes was not available from peer-reviewed literature. The atmospheric inventories have been calculated using a conversion factor of 2.12 PgC per ppm (Prather et al., 2012). WG1AR5ch6 (pdf) 15.1.6 Methane The last mass extinction of life on earth, where 95% of species disappeared, was due to methane-induced rapid warming of the atmosphere (Lee, 2014; Brand et al, 2016). Bendell (2018) Deep Adaption: A Map for Navigating Climate Tradegy (pdf) Methane, the largest component of natural gas, is sometimes called a “short-lived climate pollutant” because it remains in the atmosphere for far less time than carbon dioxide, which can remain in the atmosphere for hundreds of years. But methane is also a climate “super-pollutant,” 86 times more potent than carbon dioxide at warming the atmosphere over a 20-year period. Sources of methane include wetlands, rice paddies, livestock, biomass burning, organic waste decomposition and fossil fuel drilling and transport. James Hansen The methane (CH4) growth rate[3] is shocking. A CH4 increase causes tropospheric ozone (O3) and stratospheric water vapor (H2O) to also increase. Including these indirect effects, the climate forcing by observed CH4 growth is half as large as the climate forcing by CO2. After CH4 nearly stabilized early this century, growth has returned and recently accelerated to its highest rate in the period of accurate global data, with increased growth at least in part as a result of “fracking” for gas and reliance on gas as the complement to intermittent renewable energies. James Hansen 13 May 2021 15.1.6.1 Global Methane Assessment The Global Methane Assessment shows that human-caused methane emissions can be reduced by up to 45 per cent this decade. Such reductions would avoid nearly 0.3°C of global warming by 2045 and would be consistent with keeping the Paris Climate Agreement’s goal to limit global temperature rise to 1.5 degrees Celsius (1.5˚C) within reach. The assessment, for the first time, integrates the climate and air pollution costs and benefits from methane mitigation. Because methane is a key ingredient in the formation of ground-level ozone (smog), a powerful climate forcer and dangerous air pollutant, a 45 per cent reduction would prevent 260 000 premature deaths, 775 000 asthma-related hospital visits, 73 billion hours of lost labour from extreme heat, and 25 million tonnes of crop losses annually. Global Methane Assessment Report Inkl: Methane Far Worse 15.1.6.2 Cut Methane Now Methane is the biggest and really the only lever we have to slow temperature rise during the next two decades. Methane’s potency and short atmospheric life make it a key greenhouse gas for policy makers to focus on as a way to combat global warming in the near term because the impact of those cuts will be felt almost immediately. “If we cut methane emissions substantially during the 2020s, the abundance or concentration in the atmosphere will also drop rapidly during the 2020s,” said Drew Shindell, an earth science professor at Duke University. “If we cut CO2 emissions, it takes a long time for actual concentrations to drop, and then longer for the climate to adjust.” Inside 15.1.6.3 Spotting Methane from Space Methane is a key driver of climate change, with 80 times the global warming impact of carbon dioxide over a 20-year period. But methane only lingers in the atmosphere for about nine years, compared to a century for CO2. That means reducing methane emissions from oil and gas wells and pipelines, livestock operations, landfills and other sources around the world will have an outsize impact on reducing global warming. Two separate efforts to launch satellites that can scan the globe for methane emissions at a scope and level of detail not possible before, and to share their data with the public. The first is MethaneSat, a subsidiary of the Environmental Defense Fund that is set to launch its satellite in 2022 and start delivering data in 2023. MethaneSat will be able to scan 200-kilometer-wide swaths of the earth with spectrometers that can detect methane at concentrations of 2 to 3 parts per billion, down to resolutions of about 100 meters by 400 meters. This will be the best performance of any satellite-based methane tracking technology yet launched. In comparison, the Tropomi sensors on the European Space Agency’s Copernicus Sentinel satellite can detect about 11 parts per billion at resolutions of 7 kilometers, and the sensors on satellites operated by Canadian-based company GHGSat can capture about 55 parts per billion, albeit at much tighter spatial dimensions, down to roughly 25 meters square. MethaneSat will be able to capture leaks as low as 5 kilograms per hour per square kilometer. Newly released research finds that roughly half of global methane emissions can be cut over the next decade at no net cost. Of that low-cost reduction potential, 80 percent could come from the global oil and gas industries. CanaryMedia 15.1.7 Methane Reservoir Laptev Sea Methane bubbles regularly reach the surface of the Laptev Sea in the East Siberian Arctic Ocean (ESAO), each of them a small blow to our efforts to mitigate climate change. The source of the methane used to be a mystery, but a joint Swedish-Russian-U.S. investigation recently discovered that an ancient gas reservoir is responsible for the bubbly leaks. Methane in the Laptev Sea is stored in reservoirs below the sea’s submarine permafrost or in the form of methane hydrates—solid ice-like structures that trap the gas inside. It is also produced by microbes in the thawing permafrost itself. Not all of these sources are created equal: Whereas microbial methane is released in a slow, gradual process, disintegrating hydrates and reservoirs can lead to sudden, eruptive releases. Methane is escaping as the Laptev’s submarine permafrost is thawed by the relative warmth of overlying seawater. With an even stronger greenhouse effect than carbon dioxide, methane releases into the atmosphere could substantially amplify global warming. The source of the methane was an old reservoir, deep below the permafrost. The big finding was that we really have something that’s coming out from a deep pool. As the permafrost thaws, it opens up new pathways that allow methane to pass through. There is a risk that this methane release might increase, so it will eventually have a sizable effect on the climate. It is quite plausible that there are other sources—the thawing permafrost or the hydrates that can be the major source of methane in other parts of this enormous system. The permafrost is a closed lid over the seafloor that’s keeping everything in place. And now we have holes in this lid. Eos 15.1.8 Methane-Hydrates Ruppel Abstract Gas hydrate, a frozen, naturally-occurring, and highly-concentrated form of methane, sequesters significant carbon in the global system and is stable only over a range of low-temperature and moderate-pressure conditions. Gas hydrate is widespread in the sediments of marine continental margins and permafrost areas, locations where ocean and atmospheric warming may perturb the hydrate stability field and lead to release of the sequestered methane into the overlying sediments and soils. Methane and methane-derived carbon that escape from sediments and soils and reach the atmosphere could exacerbate greenhouse warming. The synergy between warming climate and gas hydrate dissociation feeds a popular perception that global warming could drive catastrophic methane releases from the contemporary gas hydrate reservoir. Appropriate evaluation of the two sides of the climate-methane hydrate synergy requires assessing direct and indirect observational data related to gas hydrate dissociation phenomena and numerical models that track the interaction of gas hydrates/methane with the ocean and/or atmosphere. Methane hydrate is likely undergoing dissociation now on global upper continental slopes and on continental shelves that ring the Arctic Ocean. Many factors—the depth of the gas hydrates in sediments, strong sediment and water column sinks, and the inability of bubbles emitted at the seafloor to deliver methane to the sea-air interface in most cases—mitigate the impact of gas hydrate dissociation on atmospheric greenhouse gas concentrations though. There is no conclusive proof that hydrate-derived methane is reaching the atmosphere now, but more observational data and improved numerical models will better characterize the climate-hydrate synergy in the future. Ruppel (2016) The interaction of climate change and methane hydrates (pdf) 15.1.9 Methane emission rates Guardian Methane is four times more sensitive to global warming than previously thought, a new study shows. The result helps to explain the rapid growth in methane in recent years and suggests that, if left unchecked, methane related warming will escalate in the decades to come. The growth of this greenhouse gas – which over a 20 year timespan is more than 80 times as potent than carbon dioxide – had been slowing since the turn of the millennium but since 2007 has undergone a rapid rise, with measurements from the US National Oceanic and Atmospheric Administration recording it passing 1,900 parts a billion last year, nearly triple pre-industrial levels. About 40% of methane emissions come from natural sources such as wetlands, while 60% come from anthropogenic sources such as cattle farming, fossil fuel extraction and landfill sites. Possible explanations for the rise in methane emissions range from expanding exploration of oil and natural gas, rising emissions from agriculture and landfill, and rising natural emissions as tropical wetlands warm and Arctic tundra melts. But another explanation could be a slowdown of the chemical reaction that removes methane from the atmosphere. The predominant way in which methane is “mopped up” is via reaction with hydroxyl radicals (OH) in the atmosphere. The hydroxyl radical has been termed the ‘detergent’ of the atmosphere because it works to cleanse the atmosphere of harmful trace gases,” said Redfern. But hydroxyl radicals also react with carbon monoxide, and an increase in wildfires may have pumped more carbon monoxide into the atmosphere and altered the chemical balance. “On average, a carbon monoxide molecule remains in the atmosphere for about three months before it’s attacked by a hydroxyl radical, while methane persists for about a decade. So wildfires have a swift impact on using up the hydroxyl ‘detergent’ and reduce the methane removal. Guardian (2022) Methane much more sensitive to global heating than previously thought Nisbet (in The Conversation) Since 2006, the amount of heat-trapping methane in Earth’s atmosphere has been rising fast and, unlike the rise in carbon dioxide (CO₂), methane’s recent increase seems to be driven by biological emissions, not the burning of fossil fuels. This might just be ordinary variability – a result of natural climate cycles such as El Niño. Or it may signal that a great transition in Earth’s climate has begun. the rate at which methane is increasing in the atmosphere has accelerated recently. Something like this has happened before: sudden surges in methane marked the transitions from cold ice ages to warm interglacial climates. Methane was about 0.7 parts per million (ppm) of the air before humans began burning fossil fuels. Now it is over 1.9 ppm and rising fast. Roughly three-fifths of emissions come from fossil fuel use, farming, landfills and waste. The remainder is from natural sources, especially vegetation rotting in tropical and northern wetlands. Methane is both a driver and a messenger of climate change. We don’t know why it is now rising so rapidly, but the pattern of growth since late 2006 resembles how methane behaved during great flips in Earth’s climate in the distant past. Today’s growth seems to be driven by new emissions from wetlands, especially near the equator but perhaps also from Canada (beavers are methane factories which pull huge amounts of plant matter into ponds they’ve made) and Siberia. This is a result of climate change: increasing rainfall has made wetlands wetter and bigger while rising temperatures have boosted plant growth, providing more decomposing matter and so more methane. Emissions from huge cattle lots in tropical Africa, India and Brazil may also be rising and rotting waste in landfills near megacities like Delhi are important sources too. Rising methane concentrations are the bellwethers of great climate-warming events. With each flip from a glacial to an interglacial climate there have been sudden, sharp rises in atmospheric methane, likely from expanding tropical wetlands. These great climate flips that ended each ice age are known as terminations. Each has a Roman numeral, ranging from Termination IX which happened about 800,000 years ago to Termination IA which initiated the modern climate less than 12,000 years ago. For example, around 131,000 years ago during Termination II, the British climate suddenly flipped from glaciers in the Cotswolds to hippopotami wallowing in what is now Trafalgar Square. Full terminations take several thousands of years to complete, but many include a creeping onset of warming, then a very abrupt phase of extremely rapid climate change that can take a century or less. In the abrupt phase of the great change that brought about the modern climate, Greenland’s temperature rose by around 10°C within a few decades. During these abrupt phases, methane climbs very steeply indeed. Methane fluctuated widely in pre-industrial times. But its increasingly rapid growth since 2006 is comparable with records of methane from the early years of abrupt phases of past termination events. In glacial terminations, the entire climate system reorganises. In the past, this took Earth out of stable ice age climates and into warm inter-glacials. But we are already in a warm interglacial. What comes next is hard to imagine. Roman numerals IX to I denote past great climate transitions. There is no Roman number zero, but then any future termination-scale transition will be different – a temperature step from our present interglacial climate to some new future that is warmer yet. Methane’s signal is still unclear, but the question remains: has Termination Zero begun? Nisbet (2023) Rising methane could be a sign that Earth’s climate is part-way through a ‘termination-level transition’ Nisbet Abstract Atmospheric methane’s rapid growth from late 2006 is unprecedented in the observational record. Assessment of atmospheric methane data attributes a large fraction of this atmospheric growth to increased natural emissions over the tropics, which appear to be responding to changes in anthropogenic climate forcing. Isotopically lighter measurements of urn:x-wiley:08866236:media:gbc21450:gbc21450-math-0001 are consistent with the recent atmospheric methane growth being mainly driven by an increase in emissions from microbial sources, particularly wetlands. The global methane budget is currently in disequilibrium and new inputs are as yet poorly quantified. Although microbial emissions from agriculture and waste sources have increased between 2006 and 2022 by perhaps 35 Tg/yr, with wide uncertainty, approximately another 35–45 Tg/yr of the recent net growth in methane emissions may have been driven by natural biogenic processes, especially wetland feedbacks to climate change. A model comparison shows that recent changes may be comparable or greater in scale and speed than methane’s growth and isotopic shift during past glacial/interglacial termination events. It remains possible that methane’s current growth is within the range of Holocene variability, but it is also possible that methane’s recent growth and isotopic shift may indicate a large-scale reorganization of the natural climate and biosphere is under way. Nisbet Key Points The rapid growth in the atmospheric methane burden that began in late 2006 is very different from methane’s past observational record Recent studies point to strongly increased emissions from wetlands, especially in the tropics This increase is comparable in scale and speed to glacial/interglacial terminations when the global climate system suddenly reorganized Nisbet Plain Language Summary Atmospheric methane’s unprecedented current growth, which in part may be driven by surging wetland emissions, has strong similarities to ice core methane records during glacial-interglacial “termination” events marking global reorganizations of the planetary climate system. Here we compare current and termination-event methane records to test the hypothesis that a termination-scale change may currently be in progress Fig: Methane growth rate averaged by latitudinal zone, from 2000 through 2021, updated from NOAA data. Red “warm” colors—growth. Blue “cool” colors—decline. The vertical axis denotes the sine of latitude, which weights each latitude band by its atmospheric mass. The Inter-Tropical Convergence Zone migrates seasonally from roughly 30°N to 30°S (sine latitude 0.5 to −0.5), while the Arctic zone is the band north of sine latitude 0.91. The current growth event began in late 2006. Note the remarkable growth since 2020. Data from https://gml.noaa.gov/aftp/data/trace_gases/ch4c13/flask/surface/. Nisbet Memo Nisbet (2023) Atmospheric Methane: Comparison Between Methane’s Record in 2006–2022 and During Glacial Terminations 15.1.10 Methane (other) Guardian Another setback has arisen in the attempt to neutralise methane as it escapes from beneath melting Arctic ice. Methane bubble plumes are increasingly being seen in the Arctic, and Wadhams is frustrated that the Intergovernmental Panel on Climate Change (IPCC) has not yet accepted his theory that, as the ice melts, we could face a catastrophic escape of methane that has been stored for 20,000 years. Estimates, he says, range from 50 to 700 gigatonnes, which could “cause maybe a degree [centigrade] of warming, more or less instantly”, bringing forward by 15–35 years the average date at which the global mean temperature rise exceeds 2°C above pre-industrial levels. The best geoengineering prevention for that relies, again, on the ocean. “If you blow a fine powder, or aerosol, of an iron salt called ferric chloride over the sea surface in the place where methane is bubbling out, it reacts with the methane, producing ferric hydroxide, which dissolves in the water,” he says. Frustratingly for the theory’s backers, a test voyage this year by the University of Copenhagen found no evidence that it could work efficiently enough to remove the required amounts of the gas. Guardian](https://www.theguardian.com/environment/2021/jun/23/cloud-spraying-and-hurricane-slaying-could-geoengineering-fix-the-climate-crisis) Kolbert Sudd - South Sudan methane Sump Starting in 2007, for example, methane levels in the atmosphere took an unexpected jump. Methane is a far more potent greenhouse gas than CO2, so scientists were alarmed. They eventually figured out, on the basis of the methane’s isotopic composition, that the source of the increase couldn’t be fossil-fuel production, even though oil and gas wells often leak methane into the air. Instead, the culprit must be microbes, either the sort that live in a marsh or the sort that live in a cow’s gut. Recent research suggests that the bulk of the extra methane is coming from the Sudd, a huge wetland in South Sudan, and that warming itself is responsible for the uptick in microbial activity. If that’s the case, then a spiral is likely to ensue: more methane will produce more warming, which will produce yet more methane, and so on. Kolbert (2022) Climate Change from A to Z 15.1.11 Methane - Wetland Feedback Peng Abstract Atmospheric methane growth reached an exceptionally high rate of 15.1 ± 0.4 parts per billion per year in 2020 despite a probable decrease in anthropogenic methane emissions during COVID-19 lockdowns 1 . Here we quantify changes in methane sources and in its atmospheric sink in 2020 compared with 2019. We find that, globally, total anthropogenic emissions decreased by 1.2 ± 0.1 teragrams of methane per year (Tg CH 4 yr −1 ), fire emissions decreased by 6.5 ± 0.1 Tg CH 4 yr −1 and wetland emissions increased by 6.0 ± 2.3 Tg CH 4 yr −1 . Tropospheric OH concentration decreased by 1.6 ± 0.2 per cent relative to 2019, mainly as a result of lower anthropogenic nitrogen oxide (NO x ) emissions and associated lower free tropospheric ozone during pandemic lockdowns 2 . From atmospheric inversions, we also infer that global net emissions increased by 6.9 ± 2.1 Tg CH 4 yr −1 in 2020 relative to 2019, and global methane removal from reaction with OH decreased by 7.5 ± 0.8 Tg CH 4 yr −1 . Therefore, we attribute the methane growth rate anomaly in 2020 relative to 2019 to lower OH sink (53 ± 10 per cent) and higher natural emissions (47 ± 16 per cent), mostly from wetlands. In line with previous findings 3,4 , our results imply that wetland methane emissions are sensitive to a warmer and wetter climate and could act as a positive feedback mechanism in the future. Our study also suggests that nitrogen oxide emission trends need to be taken into account when implementing the global anthropogenic methane emissions reduction pledge 5 . Peng (2022) Wetland emission and atmospheric sink changes explain methane growth in 2020 (pdf) 15.1.12 Methane Removal Pyzik a group of researchers from California University Long Beach are proposing a method of removing methane by using a group of bacteria known as methanotrophs to naturally convert methane to carbon dioxide and biomass. All the bacteria in this group ‘eat’ methane, removing it from air and converting part of it to cells as a source of sustainable protein. A strain of bacteria within this group called methylotuvimicrobium buryatense 5GB1C that can remove methane efficiently even when it is present in lower amounts. Typically, this group of bacteria thrive in environments with high levels of methane (between 5,000 and 10,000 parts per million (ppm)). The normal concentrations in our atmosphere have much lower levels of only about 1.9 ppm of methane. But certain areas such as landfills, rice fields and oilwells emit higher concentrations of about 500 ppm. The strain’s high methane consumption rate is probably due to a low energy requirement and greater attraction for methane – more than five times more than that of other bacteria. The bacteria oxidise the methane to CO2. The biggest barrier to implementation now is technical: we need to increase the methane treatment unit 20-fold. To implement methane-eating bacteria on a mass scale, thousands of high-functioning reactors will be needed. Any emissions reduction strategies that enhance bacterial activity in natural communities may also result in increased nitrous oxide (N2O) emission, which has 10 times the global heating potential than that of methane. Critically, this methanotrophic bacteria-based technology does not produce nitrous oxide emissions. Recent projections predicted that global heating can be reduced 0.21C to 0.22C by removing 0.3 to 1 petagrams of methane by 2050. Pyzik (2023) Bacteria that ‘eat’ methane could slow global heating 15.1.13 Hydrogen (Leakage) EDF EDF (2022) STUDY: Emissions of Hydrogen Could Undermine Its Climate Benefits; Warming Effects Are Two to Six Times Higher Than Previously Thought RMI RMI (2022) Hydrogen Reality Check #1: Hydrogen Is Not a Significant Warming Risk Fan Fan (2022) Hydrogen Leakage: A Potential Risk for the Hydrogen Economy Ocko Abstract Given the urgency to decarbonize global energy systems, governments and industry are moving ahead with efforts to increase deployment of hydrogen technologies, infrastructure, and applications at an unprecedented pace, including USD billions in national incentives and direct investments. While zero- and low-carbon hydrogen hold great promise to help solve some of the world’s most pressing energy challenges, hydrogen is also an indirect greenhouse gas whose warming impact is both widely overlooked and underestimated. This is largely because hydrogen’s atmospheric warming effects are short-lived – lasting only a couple decades – but standard methods for characterizing climate impacts of gases consider only the long-term effect from a one-time pulse of emissions. For gases whose impacts are short-lived, like hydrogen, this long-term framing masks a much stronger warming potency in the near to medium term. This is of concern because hydrogen is a small molecule known to easily leak into the atmosphere, and the total amount of emissions (e.g., leakage, venting, and purging) from existing hydrogen systems is unknown. Therefore, the effectiveness of hydrogen as a decarbonization strategy, especially over timescales of several decades, remains unclear. This paper evaluates the climate consequences of hydrogen emissions over all timescales by employing already published data to assess its potency as a climate forcer, evaluate the net warming impacts from replacing fossil fuel technologies with their clean hydrogen alternatives, and estimate temperature responses to projected levels of hydrogen demand. We use the standard global warming potential metric, given its acceptance to stakeholders, and incorporate newly published equations that more fully capture hydrogen’s several indirect effects, but we consider the effects of constant rather than pulse emissions over multiple time horizons. We account for a plausible range of hydrogen emission rates and include methane emissions when hydrogen is produced via natural gas with carbon capture, usage, and storage (CCUS) (“blue” hydrogen) as opposed to renewables and water (“green” hydrogen). For the first time, we show the strong timescale dependence when evaluating the climate change mitigation potential of clean hydrogen alternatives, with the emission rate determining the scale of climate benefits or disbenefits. For example, green hydrogen applications with higher-end emission rates (10 %) may only cut climate impacts from fossil fuel technologies in half over the first 2 decades, which is far from the common perception that green hydrogen energy systems are climate neutral. However, over a 100-year period, climate impacts could be reduced by around 80 %. On the other hand, lower-end emissions (1 %) could yield limited impacts on the climate over all timescales. For blue hydrogen, associated methane emissions can make hydrogen applications worse for the climate than fossil fuel technologies for several decades if emissions are high for both gases; however, blue hydrogen yields climate benefits over a 100-year period. While more work is needed to evaluate the warming impact of hydrogen emissions for specific end-use cases and value-chain pathways, it is clear that hydrogen emissions matter for the climate and warrant further attention from scientists, industry, and governments. This is critical to informing where and how to deploy hydrogen effectively in the emerging decarbonized global economy. Ocko (2022) Climate consequences of hydrogen emissions 15.2 Aerosols Hansen The global warming acceleration is due to the one huge climate forcing that we have chosen not to measure: the forcing caused by imposed changes of atmospheric aerosols. It’s a shame that we are not measuring the aerosol climate forcing to take advantage of this vast geophysical experiment to improve our understanding. The human-made aerosol forcing is almost as large as the CO2 forcing, but it is of the opposite sign, i.e., aerosols cause cooling. Aerosols cause cooling by reflecting sunlight to space, thus by itself an increase of aerosols causes a temporary energy imbalance – more energy going out than coming in. Earth restores energy balance by cooling off, thus reducing heat radiation to space. The aerosol climate forcing is complex, as the largest part of their effect seems to be via their role as cloud condensation nuclei. Added condensation nuclei tend to make the average cloud particle smaller; that tends to make brighter, longer-lived clouds, but it’s a complicated story. We have so far only felt a fraction of the eventual warming due to the presumed decrease of aerosols of the past several years. in the absence of adequate aerosol measurements – let’s use Earth’s measured energy imbalance to estimate the impact of aerosol reductions on global warming. Earth’s energy imbalance is measured to a good accuracy via precise monitoring of the rising global ocean temperature because the ocean is the repository for about 90 percent of the excess energy. Von Schuckmann et al. (2020)[4] report that the average imbalance over the period 1971-2018 was 0.47 ±0.1 W/m2, but in period 2010-2018 the imbalance was 0.87 ±0.1 W/m2. Additional information on the energy imbalance is provided by combining the absolute calibration provided by measuring the change in the ocean heat content with the spatial and temporal information provided by satellite-borne radiometers. The CERES (Clouds and the Earth’s Radiant Energy System) instruments[5] measure outgoing radiation – both reflected sunlight and emitted terrestrial heat radiation. CERES cannot measure the tiny imbalance between the incoming and outgoing fluxes of radiation, but the stability of its sensors is sufficient to infer valuable information about the planet’s energy imbalance. Specifically, the CERES data – in addition to having temporal variation of Earth’s energy imbalance consistent with the ocean data of von Schuckmann et al. – show that most of the increased imbalance since 2015 is due to an increase of absorbed solar energy, i.e., a decrease in Earth’s reflectivity. That is consistent with the expectation that the largest effect of aerosols on Earth’s radiation balance and climate is via their effect on clouds. We can only infer that Earth’s energy imbalance – which was less than or about half a watt per square meter during 1971-2015 – has approximately doubled to about 1 W/m2 since 2015. This increased energy imbalance is the cause of global warming acceleration. We should expect the global warming rate for the quarter of a century 2015-2040 to be about double the 0.18°C/decade rate during 1970-2015. Hansen (2021) July 2021 temp Update Faustian Bargain Hansen The role of aerosols in climate change is uncertain because aerosol properties are not measured well enough to define their climate forcing. Aerosol impact is suggested by the gap between observed global warming and expected warming due to GHGs based on ECS inferred from paleoclimate. Fig: Observed global surface temperature (black line) and expected GHG warming with two choices for ECS. The blue area is the estimated aerosol cooling effect. The temperature peak in the World War II era is in part an artifact of inhomogeneous ocean data in that period. Our best estimate for ECS, 1.2°C per W/m 2 , yields a gap of 1.5°C between expected and actual warming in 2022. Aerosols are the likely cooling source. The other negative forcing discussed by IPCC – surface albedo change – is estimated by IPCC to be –0.12 ± 0.1 W/m 2 , an order of magnitude smaller than aerosol forcing. Absence of global warming over the 70-year period 1850-1920 (Fig. SPM.1 of IPCC AR6 WG1 report) is a clue about aerosol forcing. GHG forcing increased 0.54 W/m 2 in 1850-1920, which causes an expected warming ~0.4°C by 1920 for ECS = 1°C per W/m2 . Natural forcings – solar irradiance and volcanic aerosols – might contribute to lack of warming, but no persuasive case has been made for the required downward trends of those forcings. Human-made aerosols are the likely offset of GHG warming. Such aerosol cooling is a Faustian bargain because payment in enhanced global warming will come due once we can no longer tolerate the air pollution. Ambient air pollution causes millions of deaths per year, with particulates most responsible. The mystery is the absence of warming in the past 6,000 years. Aerosol cooling could have offset GHG warming. Growing population, agriculture and land clearance produced aerosols and CO2 ; wood was the main fuel for cooking and heating. Nonlinear aerosol forcing is largest in a pristine atmosphere, so it is unsurprising that aerosols tended to offset CO2 warming as civilization developed. Global aerosols are not monitored with detail needed to define aerosol climate forcing. IPCC 13 estimates forcing from assumed precursor emissions, a herculean task due to many aerosol types and complex cloud effects. Aerosol forcing uncertainty is comparable to its estimated value. Fig: (a) Estimated greenhouse gas and aerosol forcings relative to 1750 values. (b) Aerosol forcing as percent of GHG forcing. Forcings for dark blue area are relative to 1750. Light blue area adds 0.5 W/m2 forcing estimated for human-caused aerosols from fires, biofuels and land use. If human-made aerosol forcing was – 0.5 W/m2 by 1750, offsetting +0.5 W/m2 GHG forcing, this forcing should be included. Such aerosol forcing – largely via effects of land use and biomass fuels on clouds – continues today. Thirty million people in the United States use wood for heating. Such fuels are also common in Europe and much of the world. IPCC aerosol forcing slowly becomes important relative to GHG forcing. Civilization always produced aerosols as well as GHGs. As sea level stabilized, organized societies and population grew as coastal biologic productivity increased and agriculture developed. Wood was the main fuel. Aerosolstravel great distances, as shown by Asian aerosols in North America. Humans contributed to both rising GHG and aerosol climate forcings in the past 6,000 years. One result is that human-caused aerosol climate forcing is at least 0.5 W/m2 more than usually assumed. Thus, the Faustian payment that will eventually come due is also larger. Recent global warming does not yield a unique ECS because warming depends on three major unknowns with only two basic constraints. Unknowns are ECS, net climate forcing (aerosol forcing is unmeasured), and ocean mixing (many ocean models are too diffusive). Constraints are observed global temperature change and Earth’s energy imbalance (EEI). Many climate models compensate for excessive ocean mixing (which reduces surface warming) by using aerosol forcing less negative than the real world, thus achieving realistic surface warming. This issue is unresolved and complicated by the finding that cloud feedbacks can buffer ocean heat uptake, affecting interpretation of EEI. IPCC reports may have gravitated toward climate sensitivity near 3°C for 2×CO2 in part because of difficulty that models have in realistically simulating amplifying cloud feedbacks and a climate model tendency for excessive mixing of heat into the deep ocean. The great inadvertent aerosol experiment Sulfate aerosols are cloud condensation nuclei (CCN), so sulfate emissions by ships result in a larger number of smaller cloud particles, thus affecting cloud albedo and cloud lifetime. Ships provide a large percentage of sulfates in the North Pacific and North Atlantic regions. It has been suggested that cooling by these clouds is overestimated because of cloud liquid water adjustments, but liquid water path (LWP) effects are substantial even in regions without visible ship-tracks. Sulfate indirect aerosol forcing is estimated to -1.11 ± 0.43 W/m2 over the global ocean. Changes of IMO emission regulations provide a great opportunity for insight into aerosol climate forcing. Sulfur content of fuels was limited to 1% in 2010 near the coasts of North America and in the North Sea, Baltic Sea and English Channel, and further restricted there to 0.1% in 2015. In 2020 a limit of 0.5% was imposed worldwide. The 1% limit did not have a noticeable effect on ship-tracks, but a striking reduction of ship-tracks was found after the 2015 IMO regulations, especially in the regions near land where emissions were specifically limited. Following the additional 2020 regulations, global ship-tracks were reduced more than 50%. Earth’s albedo (reflectivity) measured by CERES (Clouds and Earth’s Radiant Energy System) satellite-borne instruments over the 22-years March 2000 to March 2022 reveal a decrease of albedo and thus an increase of absorbed solar energy coinciding with the 2015 change of IMO emission regulations. Global absorbed solar energy is +1.05 W/m 2 in the period January 2015 through December 2022 relative to the mean for the first 10 years of data. Increased solar energy absorption occurred despite 2015-2020 being the declining phase of the ~11-year solar irradiance cycle. Fig: Global absorbed solar radiation (W/m 2 ) relative to mean of the first 120 months of CERES data. CERES data are available at http://ceres.larc.nasa.gov/order_data.php Given the large increase of absorbed solar energy, cloud changes are likely the main cause. Potential causes of the cloud changes include: 1) reduced aerosol forcing, 2) cloud feedbacks to global warming, 3) natural variability. Climate models predict a reduction of cloud albedo in this region as a feedback effect driven by global warming. Continued monitoring of absorbed energy can confirm the reality of the change, but without global monitoring of detailed physical properties of aerosols and clouds, it will be difficult to apportion observed change among the candidate causes. Hansen (2023) PipelinePaper230705 (pdf) Simons The Northern Hemisphere mid latitude Sea Surface Temperatures have gone through the roof since the shipping desulphurization regulations came into effect on January 1st, 2020. This is clearly visible when looking at the 12-month (Oct-Sept) trend. Simmons (2023) Twitter 15.3 Ozone Layer 15.3.1 Artic Ozone Hole Berwyn The ozone layer, Earth’s protection against intense ultraviolet radiation, is at risk, despite the progress made in protecting atmospheric ozone by the 1987 Montreal Protocol. Warming of the surface of the Arctic is matched by a colder polar vortex high in the atmosphere, which is speeding the breakdown of the Earth’s shield against ultraviolet rays. As greenhouse gases heated the surface of the planet, the researchers said, they have also, during the past 50 years, cooled the upper layers of the atmosphere over the Arctic. In the colder stratosphere, long-lived pollutants like chlorofluorocarbons and halons from refrigerants and industrial solvents break down and release chlorine and bromine, which react with sunlight to destroy ozone. Concentrations of those pollutants in the atmosphere have decreased by about 10 percent since the ban, allowing the ozone layer above Antarctica to heal over the past 20 years, but progressively colder temperatures in the stratosphere above the Arctic are increasing the destruction of ozone in that region Berwyn (2020) Ozone Alarm in the High North - InsideClimateNews von der Gathen - Abstract Chemical loss of Arctic ozone due to anthropogenic halogens is driven by temperature, with more loss occurring during cold winters favourable for formation of polar stratospheric clouds (PSCs). We show that a positive, statistically significant rise in the local maxima of PSC formation potential (PFPLM) for cold winters is apparent in meteorological data collected over the past half century. Output from numerous General Circulation Models (GCMs) also exhibits positive trends in PFPLM over 1950 to 2100, with highest values occurring at end of century, for simulations driven by a large rise in the radiative forcing of climate from greenhouse gases (GHGs). We combine projections of stratospheric halogen loading and humidity with GCM-based forecasts of temperature to suggest that conditions favourable for large, seasonal loss of Arctic column O3 could persist or even worsen until the end of this century, if future abundances of GHGs continue to steeply rise. von der Gathen (2021) Climate change favours large seasonal loss of Arctic ozone 15.4 Stratosphere shrinking The thickness of the atmospheric layer has contracted by 400 metres since the 1980s, the researchers found, and will thin by about another kilometre by 2080 without major cuts in emissions. The changes have the potential to affect satellite operations, the GPS navigation system and radio communications. The discovery is the latest to show the profound impact of humans on the planet. In April, scientists showed that the climate crisis had shifted the Earth’s axis as the massive melting of glaciers redistributes weight around the globe. The stratosphere extends from about 20km to 60km above the Earth’s surface. Below is the troposphere, in which humans live, and here carbon dioxide heats and expands the air. This pushes up the lower boundary of the stratosphere. But, in addition, when CO2 enters the stratosphere it actually cools the air, causing it to contract. Guardian Pisoft Abstract Rising emissions of anthropogenic greenhouse gases (GHG) have led to tropospheric warming and stratospheric cooling over recent decades. As a thermodynamic consequence, the troposphere has expanded and the rise of the tropopause, the boundary between the troposphere and stratosphere, has been suggested as one of the most robust fingerprints of anthropogenic climate change. Conversely, at altitudes above ~55 km (in the mesosphere and thermosphere) observational and modeling evidence indicates a downward shift of the height of pressure levels or decreasing density at fixed altitudes. The layer in between, the stratosphere, has not been studied extensively with respect to changes of its global structure. Here we show that this atmospheric layer has contracted substantially over the last decades, and that the main driver for this are increasing concentrations of GHG. Using data from coupled chemistry-climate models we show that this trend will continue and the mean climatological thickness of the stratosphere will decrease by 1.3 km following representative concentration pathway 6.0 by 2080. We also demonstrate that the stratospheric contraction is not only a response to cooling, as changes in both tropopause and stratopause pressure contribute. Moreover, its short emergence time (less than 15 years) makes it a novel and independent indicator of GHG induced climate change. Pisoft 15.4.1 N2O The growth rate of the third strongest greenhouse gas, N2O, does not provide any good news. Its growth rate continues to increase. James Hansen 13 May 2021 15.5 Contrails Pearce New research shows that condensation trails from aircraft exhaust are playing a significant role in global warming. Experts are concerned that efforts to change aviation engine design to reduce CO2 emissions could actually create more contrails and raise daily temperatures even more. Like regular cirrus clouds, contrail clouds trap heat radiating from the earth’s surface, causing warming in the air below. Contrails are human-made clouds. They form in air above about 25,000 feet, when that air is moist and colder than -40 degrees Celsius. Like regular clouds, they arise when water vapor, in this case from the engine exhausts, forms into droplets by condensing onto particles in the air, in this case soot from the engines. Within a second, the water droplets freeze to make tiny ice crystals that show up visually as contrails. If the air is not cool or moist enough, contrails may not form or may disappear quickly. But at other times, they stick around – either as tight, white lines in the sky, like chalk marks, or gradually spreading to create thin layers of ice clouds. They are similar to natural cirrus clouds and are often called contrail cirrus clouds. Contrail cirrus clouds cover around 0.6 percent of the global skies at any one time — nine times the amount covered by contrails themselves. In areas with high amounts of air traffic, they can merge to cover as much as 38,000 square miles, roughly the size of Indiana, and last for many hours or even days. Like regular cirrus clouds, contrail cirrus clouds have two competing effects on climate. They shade us by reflecting incoming sunlight back into space. But they also trap heat radiating from the earth’s surface, so causing warming in the air below. During the day, cooling compensates part of the warming. But at night, with no sunlight, only the warming effect operates. Red-eye flights are a red light for climate. The average effect on the earth’s radiation balance of contrails and contrail cirrus is 50 milliwatts per square meter of the earth’s surface. The figure is for 2006, the base year for the U.S. Federal Aviation Administration dataset used by the authors. It was double the 24 milliwatts from the CO2 that had accumulated in the atmosphere from a century of aviation (and is a significant part of a total anthropogenic effect at the time of around 1,600 milliwatts). One is to divert aircraft away from air where contrails are likely to form. This can be done vertically by changing altitude, or horizontally by detouring around the problem air. But aircraft currently fly the shortest routes and at altitudes that minimize fuel burn …controlling contrail formation in this way… will almost certainly lead to increases in aircraft CO2 emissions. A second approach to minimizing contrails is to change fuels — from kerosene-based fuels to biofuels, hydrogen, liquid natural gas, or even electricity. Even if fuel changes reduce soot emissions, researchers estimate contrail production will increase by a factor of 2.8 by 2050. Pearce (2019) Airplane Contrails make Planet warmer Kaldeira (twitter thread) Canary Media It has long been unclear just how much contrails contribute to climate change. But recent research has shed more light on the issue. A 2020 study by the European Union found that contrails and other non-CO2 aircraft emissions warm the planet twice as much as the carbon dioxide released by airplanes. And a 2021 study found that, while aviation contributes about 2.4 percent of global annual CO2 emissions, flying is actually responsible for 4 percent of global warming when all factors are included. Canary Media (2022) Major airlines are teaming up to tackle planet-warming plane contrails Klöwer (2021) Quantifying aviation’s contribution to global warming Transport and Environment The report recommends using clean fuels to reduce the amount of pollutants released by jets and changing flight paths to fly at lower altitude, where contrail formation is avoided. The scientists note that rerouting less than 2% of flights in Japan had reduced the warming effect of contrails by nearly 60%.[2] The report also says the EU could require the blending of e-fuels into all jet fuel sold in European countries. T&amp;E said the EU cannot afford to wait five to eight years to implement these measures, as the report proposes, and that they need to be included in the Commission’s upcoming Sustainable and Smart Mobility Strategy, due in December. Contrail avoidance also needs to be prioritised in the revision of the Single European Sky, given its potential to deliver substantial cuts to aviation’s climate impact. Pricing for non-CO2 emissions will also be needed to incentivise airlines to use eco-friendly flight paths. Transport and Environment (2020) Airline contrails warm the planet twice as much as CO2 Eu Study 15.6 Clouds Ceppi Significance A key challenge of our time is to accurately estimate future global warming in response to a doubling of atmospheric carbon dioxide—a number known as the climate sensitivity. This number is highly uncertain, mainly because it remains unclear how clouds will change with warming. Such changes in clouds could strongly amplify or dampen global warming, providing a climate feedback. Here, we perform a statistical learning analysis that provides a global observational constraint on the future cloud response. This constraint supports that cloud feedback will amplify global warming, making it very unlikely that climate sensitivity is smaller than 2 °C. Ceppi Abstract Global warming drives changes in Earth’s cloud cover, which, in turn, may amplify or dampen climate change. This “cloud feedback” is the single most important cause of uncertainty in Equilibrium Climate Sensitivity (ECS)—the equilibrium global warming following a doubling of atmospheric carbon dioxide. Using data from Earth observations and climate model simulations, we here develop a statistical learning analysis of how clouds respond to changes in the environment. We show that global cloud feedback is dominated by the sensitivity of clouds to surface temperature and tropospheric stability. Considering changes in just these two factors, we are able to constrain global cloud feedback to 0.43 ± 0.35 W⋅m−2⋅K−1 (90% confidence), implying a robustly amplifying effect of clouds on global warming and only a 0.5% chance of ECS below 2 K. We thus anticipate that our approach will enable tighter constraints on climate change projections, including its manifold socioeconomic and ecological impacts. Ceppi (2021) Observational evidence that cloud feedback amplifies global warming Simmons Simmons (2023) Twitter Loeb Satellite and in situ observations independently show an approximate doubling of Earth’s Energy Imbalance (EEI) from mid-2005 to mid-2019. Marked decreases in clouds and sea-ice and increases in trace gases and water vapor combine to increase the rate of planetary heat uptake. Robust decreases in low and middle cloud amounts observed in both hemisphere. Ocean vertical mixing appears to be main driver of global changes in SST. Loeb (2022) Recent Variations in EEI, SST &amp; Clouds 15.7 Attributing Emissions 15.7.1 Norway’s Responsibility In real life responsibility is more than what is legally binding The emissions of CO2 that occur within Norway’s territory are dwarfed by the emissions that result from combustion of all the oil and gas Norway produces. Because these fossil fuels are exported before being combusted, the emissions are allocated to the accounts of other countries. If Norway had generated electricity from the gas and then exported the electricity, for example, then emissions from that electricity generation would be allocated to Norway’s accounts. There is therefore an element of artificiality associated with this allocation. It takes two to tango. Norway’s territorial emissions of CO2 were about 42 Mt in 2019, and over 1971–2019 totalled about 1.9 Gt. In comparison, emissions from Norwegian oil and gas since 1971 have been about 16 Gt. A similar amount (~15 Gt) will be emitted if all remaining Norwegian oil and gas resources are extracted from the continental shelf. In 2019, emissions from Norwegian oil and gas amounted to 84 tonnes of CO2 for every person in Norway. Norways Export Emissions (Robbie Andrew) In Norwegian politics, there’s been a very successful attempt to separate the discussion of oil policy from the discussion of climate policy. The two were never really tightly linked [in the country] until roughly the last decade, and this division has become increasingly difficult to maintain. Norwegian politicians also haven’t been alone in creating the conditions that made this division possible. They’ve been helped immensely by the international climate regime. From the very beginning of international climate policy, there was this agreement that countries had to account for the emissions that they create when they burn fossil fuels. All the responsibility was placed on the demand side, not the supply side, which was very convenient for Norway. Europe is the primary market for Norway’s oil and gas. But determining the climate effects of Norwegian production is not straightforward. One study has estimated a clear climate benefit from reducing oil output, but the market is complex and the result really depends on your assumptions about how other actors will behave and how the market will evolve over time. The big irony here is that Norway is a fairly large fossil-fuel producer, but we use relatively few fossil fuels directly in our energy use. Nearly all of our electricity has for a long time come from hydropower. In most years, we even export quite a lot of renewable electricity to our neighbors. The only place where fossil fuels are used to directly produce energy is to run the platforms offshore. They use gas to run the turbines to get the energy needed for oil and gas production. The government’s new climate plan, which was unveiled just a few days ago, does include a number of new and more aggressive measures to reduce Norway’s domestic emissions. The proposal to increase the already quite high CO2 tax on offshore emissions came as something of a surprise, and it is likely to pass even if it is currently being challenged by the industry. However, it is important to keep in mind that this proposal only targets the production-related emissions of Norwegian oil, not the level of oil that is being extracted and exported. As such, it is in line with the historical separation between climate and oil policymaking, which tends to focus only on emissions happening within Norway and exclude any concern for the climate impact of exported oil and gas. The Norwegian paradox has worked out fairly well up until the last few years because there has been little focus on the production of fossil fuels, and because Norway is small enough to avoid the scrutiny that some larger nations face. But this is quickly changing, both in the domestic and international political discussion. There is now a lot more focus on the supply side of fossil fuels than 10 years ago, with several countries like Denmark announcing an end to drilling and new research showing a mismatch between planned fossil-fuel production and ideas such as a “non-proliferation treaty” for fossil fuels being floated. The treaty would bring the world together in agreeing to end the use of fossil fuels much like the UN came together to curb the spread of nuclear weapons. This will make it increasingly hard for Norway to hold on to a leadership claim as long as oil production keeps being expanded into new areas. Norways Climate - Petroleum Dilemma (Bard Lahn) 15.7.2 Global North vs South Responsibility The global North is responsible for 92% of total excess carbon dioxide emissions. Climate breakdown is colonial in character and ultimately requires an anti-colonial struggle in response. (Jason Hickel) Fig. by (AndrewFanning?) 15.7.3 Concrete / Cement CanaryMedia Concrete is everywhere, and it accounts for 7 to 8 percent of global carbon emissions. Quick facts about clean concrete for people who don’t work with concrete Cement is the most carbon-intensive component in concrete. One easy way to lower carbon impact is to stop the common industrial practice of chucking extra cement in the mix. Apparently, this is widespread and results in more cement in the finished product than what the engineers actually asked for. Governments are the biggest purchasers of concrete (think highways, roads, bridges). If they start demanding carbon accounting or giving preference to lower-carbon concrete suppliers, it would have an outsize influence on the industry. A bill now up before California’s legislature would do just that. Another bill in California would cut carbon from concrete by 40 percent by the end of 2035. This one has support from Democrats, Republicans, industry and environmental groups. Crucially, it includes a “border adjustment mechanism,” which means the carbon limits apply to imported concrete. That ensures a level playing field for concrete suppliers if the law goes into effect. (Canary Media Newsletter by Julian Spector 1 July 2021 (No Link)) CanryMedia "],["forests.html", "16 Forests 16.1 Tropicalforests 16.2 Forests tipping: go from sink to source of CO2 due to temperature increase. 16.3 Deforestation 16.4 Amazonas Firetrap 16.5 Plant and Cut - Forest CCS 16.6 Deforestation Footprint", " 16 Forests 16.1 Tropicalforests Tropical rainforests have almost no soil, their incredible diversity allows for direct recycling in the first centi- or decimeters. But they need a size to funtcion properly, to maintain their climate. Thus destroying them for farmland is an idiocy beyond comprehension, because they just become steppe after short. Reduced in size they collapse quickly, that’s what they do around the world, with dire consequences. e.g. erosion, drought … 16.2 Forests tipping: go from sink to source of CO2 due to temperature increase. New research shows that Earth’s overheated climate will alter forests at a global scale even more fundamentally, by flipping a critical greenhouse gas switch in the next few decades. The study suggests that, by 2040, forests will take up only half as much carbon dioxide from the atmosphere as they do now, if global temperatures keep rising at the present pace. Global warming has contributed to thinning canopies in European forests and to sudden die-offs of aspen trees in Colorado, as well as insect outbreaks that are killing trees around the world. In many places, forests are not growing back. The data show a clear temperature limit, above which trees start to exhale more CO2 than they can take in through photosynthesis. The findings mark a tipping point, of sorts, at which “the land system will act to accelerate climate change rather than slow it down,” Trees From Sink to Source (InsideClimateNews) At present, the land provides a “climate service” by absorbing around 30 per cent of the emissions caused by humans each year. Unlike other tipping elements in the Earth system, the climate tipping point for the terrestrial biosphere could be exceptionally close – 20-30 years away – without action. Plant respiration, the process by which plants produce energy for growth, causes CO2 to be released into the atmosphere. The ‘buffer’ or ‘discount’ against carbon emissions that we currently receive from the biosphere is more fragile than we previously realised. Climate models are tools used by scientists to simulate how the world is likely to respond to greenhouse gas emissions. However, it is worth noting that the global dataset used in the study uses “very few samples from tropical regions”. This means that it is still not fully understood how tropical forests are responding to rising temperatures. Independent Memo Duffy The temperature dependence of global photosynthesis and respiration determine land carbon sink strength. While the land sink currently mitigates ~30% of anthropogenic carbon emissions, it is unclear whether this ecosystem service will persist and what hard temperature limits, if any, regulate carbon uptake. The mean temperature of the warmest quarter (3-month period) passed the thermal maximum for photosynthesis during the past decade. At higher temperatures, respiration rates continue to rise in contrast to sharply declining rates of photosynthesis. Under business-as-usual emissions, this divergence elicits a near halving of the land sink strength by as early as 2040. The difference between gross primary productivity and total ecosystem respiration (carbon uptake by vegetation minus carbon loss to the atmosphere) comprises the metabolic component of the land carbon sink [net ecosystem productivity (NEP)]. To date, land ecosystems provide a climate regulation service by absorbing ~30% of anthropogenic emissions annually. While temperature functions as a key driver of year-to-year changes in the land carbon sink, its temperature response is still poorly constrained at biome to global scales, making the carbon consequences of anticipated warming uncertain. Like all biological processes, metabolic rates for photosynthesis and respiration are temperature dependent; they accelerate with in- creasing temperature, reach a maximum rate, and decline thereafter. Highly divergent land carbon sink trajectories from Earth system models. Continued future increases in sink strength due to the CO2 fertilization. The temperature response of global photosynthesis shows distinct maxima at 18°C for C3 and 28°C for C4 plant systems. In contrast to photosynthesis, respiration rates increase across the range of ambient temperatures (up to 38°C), with no evidence of Tmax or rate decline. The thermal maxima of leaf and soil respiration reside at ~60°-70°C. Responses diverge at temperatures above Tmax. The imbalance grows more pronounced as temperature increases. Current climate mostly lies just below Tmax where slight increases in temperature act as climate fertilization of land carbon uptake. Under anticipated warming foreshadowed by historical temperature extremes and coincident land carbon loss—however, more and more time will be spent above Tmax. Past this threshold, the land carbon balance will first weaken and ultimately reverse sign from carbon sink to carbon source. 25°C constitutes a powerful tipping point for the land sink of carbon and a formidable positive climatic feedback, Currently, less than 10% of the terrestrial biosphere experiences where land carbon uptake is degraded. For regions that do experience these temperatures, exposure is limited to 1 to 2 months or constitutes areas with sparse to no vegetation. Under business-as-usual emissions, by 2100, up to half of the terrestrial biosphere could experience temperatures past the treshold. The impact of elevated temperatures on the land sink is more than a function of cumulative area. Biomes that cycle 40 to 70% of all terrestrial carbon including the rainforests of the Amazon and Southeast Asia and the Taiga forests of Russia and Canada are some of the first to exceed biome-specific Tmax for half the year or more. This reduction in land sink strength is effectively front-loaded in that a 45% loss occurs by midcentury, with only an additional 5% loss by the end of the century. These estimates are conservative as they assume full recovery of vegetation after temperature stress and ignore patterns and lags in recovery. In contrast to any CO2 fertilization effect, anticipated higher temperatures associated with elevated CO2 could degrade land carbon uptake. Failure to account for this results in a gross overestimation of climate change mitigation provided by terrestrial vegetation. We are rapidly entering temperature regimes where biosphere productivity will precipitously decline and calls into question the future viability of the land sink. Duffy(2021) Temperature tipping point of the terrestrial biosphere (pdf) 16.2.1 Photosynthesis Failure Pyzik on Doughty Tropical forests could become so hot that some kinds of leaves will no longer be able to conduct photosynthesis. The photosynthetic machinery in tropical trees begins to fail at about 46.7C on average. The research suggests that forests may be nearing dangerous temperature thresholds sooner than expected. Using a combination of high-resolution data from Nasa’s thermal imaging instruments on the International Space Station and ground-based experiments in tropical forests across the world, researchers found that a small fraction, approximately 0.01% of all leaves, are already exposed to temperatures beyond their functional limits. Models predict that once we hit a global temperature increase of 3.9 C, these forests might experience mass leaf damage. Leaf-warming experiments revealed a nonlinear rise in temperatures. Warming leaves by 2, 3 or 4C, the highest leaf temperatures actually increased by 8C. A concerning nonlinear feedback not expected. Tropical forest air temperatures increase by greater than 4C, could give massive leaf death, possible tree mortality and species turnover across all tropical forests. The photosynthetic response would be the tip of the iceberg in terms of effects – reduced carbon uptake, likely increased mortality and even triggering possible transitions from forest to savannah. The importance of this work is that it is a first look at the specific impact of this leaf-scale warming on photosynthesis in tropical forests. While it is quite specific in one sense, it also provides a really interesting look at one of the underpinning processes in this region, and what might happen to it in the near future . What the study doesn’t look at is heatwaves. We still might see tree deaths from overheating for limited periods during heatwaves. Pyzik (2023) Tropical forests face ‘massive leaf death’ from global heating. (Guardian) Doughty Abstract The critical temperature beyond which photosynthetic machinery in tropical trees begins to fail averages approximately 46.7 °C (Tcrit)1. However, it remains unclear whether leaf temperatures experienced by tropical vegetation approach this threshold or soon will under climate change. Here we found that pantropical canopy temperatures independently triangulated from individual leaf thermocouples, pyrgeometers and remote sensing (ECOSTRESS) have midday peak temperatures of approximately 34 °C during dry periods, with a long high-temperature tail that can exceed 40 °C. Leaf thermocouple data from multiple sites across the tropics suggest that even within pixels of moderate temperatures, upper canopy leaves exceed Tcrit 0.01% of the time. Furthermore, upper canopy leaf warming experiments (+2, 3 and 4 °C in Brazil, Puerto Rico and Australia, respectively) increased leaf temperatures non-linearly, with peak leaf temperatures exceeding Tcrit 1.3% of the time (11% for more than 43.5 °C, and 0.3% for more than 49.9 °C). Using an empirical model incorporating these dynamics (validated with warming experiment data), we found that tropical forests can withstand up to a 3.9 ± 0.5 °C increase in air temperatures before a potential tipping point in metabolic function, but remaining uncertainty in the plasticity and range of Tcrit in tropical trees and the effect of leaf death on tree death could drastically change this prediction. The 4.0 °C estimate is within the ‘worst-case scenario’ (representative concentration pathway (RCP) 8.5) of climate change predictions2 for tropical forests and therefore it is still within our power to decide (for example, by not taking the RCP 6.0 or 8.5 route) the fate of these critical realms of carbon, water and biodiversity. Doughty (2023) Tropical forests are approaching critical temperature thresholds (paywall) 16.3 Deforestation 16.3.1 Warming effects of deforestation Watts on Butt The agricultural heartland of Mato Grosso, where crops are already suffering from drought and extreme heat, would be just over half a degree celsius hotter by 2050 if deforestation continued at the rapid rate of recent years. The average tree had a cooling effect equivalent to two to three 2.5kW air conditioners working at full power every hour of every day - through evapotranspiration. More and more, we are demonstrating the big benefits the forests bring to surrounding regions. For farmers, they bring cooler air and more rainfall. Hopefully putting numbers on these benefits will help to persuade a broader set of people to protect forest areas. Earlier this year, a paper showed that forest clearance reduced rainfall up to 125 miles away. More recently, research at a greater scale demonstrated that the Amazon was coupled with the South American monsoon and that continued deforestation could reduce regional precipitation by 30% with dire consequences for food production. Until now, studies on the impact of forest clearance on heat have concentrated on local effects with a clear correlation between loss of tree cover and higher temperatures in the area where the trees were cut down. The new research went further by looking at whether there is also a warming effect over a wider area. Using satellite data and artificial intelligence, the authors found a 0.7C increase in temperature for each 10-percentage point loss of forest within a radius of 60 miles. If we could reduce deforestation, then we could avert a good amount of regional warming. I see that as a big opportunity. It demonstrates the big benefit of reducing deforestation for local farmers … The most important thing is that states like Mato Grosso can follow different futures. This hands back control to regions and states. They could really reduce the amount of warming they will be exposed to. Watts (2023) Deforestation has big impact on regional temperatures, study of Brazilian Amazon shows Butt Significance Tropical deforestation warms the climate with negative impacts on people living nearby. Most previous studies have focused on the local warming caused by deforestation and less is known about how deforestation impacts surrounding areas. Our study used satellite data to show that deforestation in the Amazon caused substantial warming up to 100 km away from the location of forest loss. We show that this nonlocal warming increased deforestation-induced warming by a factor of four. We estimate that reducing deforestation in the Brazilian Amazon could reduce future warming in the southern Amazon by 0.56 °C. These findings highlight the role of deforestation in regional climate change and emphasize the importance of reducing deforestation for climate adaptation and resilience in the Amazon. Butt Abstract Tropical deforestation impacts the climate through complex land–atmosphere interactions causing local and regional warming. However, whilst the impacts of deforestation on local temperature are well understood, the regional (nonlocal) response is poorly quantified. Here, we used remote-sensed observations of forest loss and dry season land–surface temperature during the period 2001 to 2020 to demonstrate that deforestation of the Amazon caused strong warming at distances up to 100 km away from the forest loss. We apply a machine learning approach to show nonlocal warming due to forest loss at 2–100 km length scales increases the warming due to deforestation by more than a factor 4, from 0.16 K to 0.71 K for each 10-percentage points of forest loss. We estimate that rapid future deforestation under a strong inequality scenario could cause dry season warming of 0.96 K across Mato Grosso state in southern Brazil over the period 2020 to 2050. Reducing deforestation could reduce future warming caused by forest loss to 0.4 K. Our results demonstrate the contribution of tropical deforestation to regional climate warming and the potential for reduced deforestation to deliver regional climate adaptation and resilience with important implications for sustainable management of the Amazon. Figure: Forest loss and surface temperature change during 2001 to 2020. (A) Percentage point loss (%) in forest fraction. (B) Change in surface temperature (ΔT, Kelvin) of the driest month. Change in forest fraction and ΔT over 2001 to 2020 is calculated as the difference between the mean of the first 3-y and the last 3-y of the study period (i.e., 2001–2003 versus 2018–2020). Data are shown for the Amazon basin with the boundary of the Brazilian Amazon biome also shown. Butt (2023) Amazon deforestation causes strong regional warming 16.4 Amazonas Firetrap PIK News Fire can be a decisive factor for a potential tipping of the Amazon rainforest, as it is capable of locking large parts of the Amazon in a treeless state. While naturally not occurring in rainforests, fire can play an increasing role once the forest is damaged, thinned or completely lost, up to a status where fire is the dominating driver of the ecosystem. Fire is the important factor for locking the Amazon in a grassland state, preventing 56-86% of the Amazon from regrowing, depending on the strength of climate change. Reversing the Amazon forest loss becomes increasingly harder the more forest is lost, and fire puts another lever onto this coherence. Usually, the trees of the Amazon transport enormous amounts of water back to the atmosphere, which they originally received as rain. This water can form new rain locally or downwind in a process called moisture recycling basically forming “flying rivers”, not only stabilizing the Amazon as whole but also enabling it to extent into regions which would be too dry without this process. This coherence is the main reason why the Amazon is considered a tipping element of the Earth system. Global warming and deforestation can damage these flying rivers leading to a self-reinforcing feedback of forest loss. The new study now underlines how fire dynamics help to push and lock the Amazon towards and in a savanna-like or treeless state. n contrast, in simulations without fire, the forest was able to recover over a longer time period of within 250 years, which emphasizes the important role of fire for the irreversibility of tropical deforestation. For the first time, it has been possible to calculate the feedbacks between fire, rainforest and climate in a process-based manner using the Earth system model POEM (Potsdam Earth Model). PIK News (2023) Amazon in the firetrap: Deforestation and warming lock rainforest in dry and damaged grassland state Druke Abstract The Amazon forest is regarded as a tipping element of the Earth system, susceptible to a regime change from tropical forest to savanna and grassland due to anthropogenic land use and climate change. Previous research highlighted the role of fire in amplifying irreversible large-scale Amazon die-back. However, large-scale feedback analyses which integrate the interplay of fire with climate and land-use change are currently lacking. To address this gap, here we applied the fire-enabled Potsdam Earth Model to examine these feedback mechanisms in the Amazon. By studying forest recovery after complete deforestation, we discovered that fire prevents regrowth across 56-82% of the potential natural forest area, contingent on atmospheric carbon dioxide levels. This emphasizes the significant contribution of fire to the irreversible transition, effectively locking the Amazon into a stable grassland state. Introducing fire dynamics into future assessments is vital for understanding climate and land-use impacts in the region. Druke Conclusions Employing a ﬁre-enabled Earth system model, this study demonstrated that ﬁre could prevent the recovery of 56–82% of the Amazon forest (353–515 Mio ha, depending on atmospheric CO 2 concentration) after a large-scale deforestation event, showing a history-dependent bi-stability of the Amazon basin ecosystem. Several positive feedback loops, for instance, the reduction of evapotranspiration and precipitation related to tree loss, increased temperatures, and ﬁre activity, stabilized the grassland state in more than half of the Amazon basin in our model simulations. On the other hand, with deactivated ﬁre disturbance, the forest was able to almost completely recover from the grassland state. Therefore, our model simulations show that ﬁre is a crucial factor in evaluating the potential future forest recovery. Fire disturbance, along with large-scale deforestation, can create a lock-in effect that prevents the forest from returning to its ori- ginal state. This implies that the system state could change dra- matically if deforestation and climate change surpass certain thresholds. Our results provide another strong argument for the need to protect the Amazon forests, by stopping deforestation and reducing global CO 2 emissions as they question the feasibility of future reforestation measures without ﬁre control. Druke (2023) Fire may prevent future Amazon forest recovery after large-scale deforestation (pdf) 16.5 Plant and Cut - Forest CCS Wood can also serve purely as a long-term carbon storage device. The key to locking away the carbon is to cut off the oxygen supply to microbes, thereby preventing decomposition. Natural experiments show how this can be done. 19th-century lumberjacks in the US and Canada frequently stored logs on the surfaces of the Great Lakes or floated them down rivers, some of which ended up sinking along the way. These have remained in such good condition that a modern-day cottage industry has arisen to recover the logs and turn them into everything from hardwood floors to violins. New Zealand has a similar industry with logs that were fortuitously buried in swamps as long as 60,000 years ago. Based on such examples, scholars have proposed chopping down trees or collecting fallen logs and intentionally stowing them away. That could mean sinking them to the bottom of lakes, interring them in abandoned mines or burying them in specially dug trenches. The idea hasn’t gotten much traction yet, but in 2013, the Quebec Ministry of Agriculture, Fisheries and Food funded a pilot project to dig a trench and bury 35 metric tons of wood. The project came to about $29 per metric ton of CO2 sequestered, according to government scientist Ghislain Poisson, in line with a theoretical estimate of $10-$50. That is cheaper than most high-tech forms of carbon capture and storage, which usually involve machines that filter carbon out of the air and pump it underground. Sequestering carbon at the typical power plant, where emissions are highly concentrated, runs to $30-$91 per metric ton of CO2, but in open air, which is the holy grail, costs theoretically range from $94-$232. To help this promising new technology get off the ground (or rather, into the ground), the federal government offers a tax credit of about $35 for every metric ton of CO2 removed in industrial carbon capture and storage. It’s a policy that has enjoyed strong bipartisan support for over a decade. Plant and Cut (CNN) 16.6 Deforestation Footprint (see: env) Hoang: Mapping Deforestation Footprint](https://www.nature.com/articles/s41559-021-01417-z) "],["grasslands.html", "17 Grasslands", " 17 Grasslands Rosen It took ages for grasses to grow in numbers that might constitute a grassland. And grasslands only started to occupy serious real estate in the past 10 million years—basically yesterday. They now cover roughly one-third of Earth’s land area. Grasslands rank among the most imperiled and least protected biomes on Earth. They are disappearing even faster than forests, and much of what remains has suffered varying degrees of damage. The tendency to overlook and undervalue grasslands is a product of their reputation as degraded and thus disposable landscapes—a misperception rooted in centuries of scientific confusion and cultural bias. It reflects a deeply held preference for forests, mainly among people of European descent, that has warped global grassland science and policy. Veldman proposed the term old-growth grassland to differentiate ancient, intact grasslands from those that form after humans clear a forest or abandon farmland. Grasses prevail when, for one reason or another, conditions are inhospitable to trees; trees prevail when they grow dense enough to shade out grasses. In many places, grasslands and forests coexist in a slow-motion tug-of-war. Across Africa, French foresters diagnosed naturally treeless landscapes as severely deforested and colonial governments seized control of the land from locals in the name of restoration. In Madagascar, a former French colony, it’s taken centuries to overturn the narrative of human destruction. “We’ve been told from primary school that Madagascar was covered in forests,” Cédrique Solofondranohatra, a Malagasy botanist, says. Then, supposedly, people came, cut down the trees, and set fire to the landscape, creating vast, artificial grasslands that few scientists even bothered to study. Over the past 15 years, however, work by Solofondranohatra, Bond, and others has uncovered evidence that grassy ecosystems existed on the island long before humans arrived. Grasslands store less carbon per acre than forests, on average, but in a volatile climate, they can often store it longer. Rosen (2022) Trees are overated "],["groundwater.html", "18 Groundwater 18.1 Groundwater rise", " 18 Groundwater 18.1 Groundwater rise Pierre-Louise Unlike rising seas, where the dangers are obvious, groundwater rise has remained under the radar. Hydrologists are aware of the problem and it’s all over the scholarly research, but it has yet to surface in a significant way outside of those bubbles. Groundwater rise is only briefly mentioned in the most recent edition of the National Climate Assessment, released in 2018; it’s absent from many state and regional climate adaptation plans, and even from flood maps. Any coastal area where “the land is really flat, and the geology is [the kind of] loose material that water moves through really easily,” says Hill, is “where this is really going to be a problem.” This includes places like Miami, but also Oakland, California, and Brooklyn, New York. Silicon Valley communities like Mountain View are susceptible to groundwater rise, as is Washington, DC. Worldwide, the area at risk includes portions of northwestern Europe and coastal areas of the United Kingdom, Africa, South America, and Southeast Asia. And because of how groundwater moves, people who are at risk may not know it until it’s too late. “One of the most important things about the groundwater is that the rising groundwater level precedes any inundation of the surface,” says Rozell. Put another way, we will experience groundwater flooding long before the ocean comes lapping at our front door. It might seem puzzling that rising seas could cause groundwater to rise. At first blush the two seem unrelated, but the connection is actually simple. That it has long been ignored reflects our bias toward addressing problems we can easily see. To understand the link, it first helps to understand a bit about groundwater. The water nestled in sediments underground started as surface water, like rain or snow, and eventually seeped down. A layer of saturated soil rests below a layer of unsaturated soil; the boundary between the two is what’s known as the water table. And in many coastal areas this layer of saturated soil, which can be meters thick, rests atop salt water from the ocean. As sea levels rise, the groundwater gets pushed up because salt water is denser than fresh water. Pierre-Louise (2021) How rising groundwater caused by climate change could devastate coastal communities "],["ice-sheet.html", "19 Ice Sheet 19.1 Greenland 19.2 Antarctica 19.3 Arctic Sea Ice 19.4 Ice Sheet Collapse", " 19 Ice Sheet Most climate models are unrealistically insensitive to freshwater injected by melting ice. Ice sheet models are unrealistically lethargic in the face of rapid, large climate change. James Hansen (2021) Foreword in DellaSala DA (ed). Conservation Science and Advocacy for a Planet in Peril. Amsterdam: Elsevier, 2021 (pdf) [(loc.pdf)[pdf/James_Hansen_2021_ForewordDellaSalaBook.pdf) Ice sheet collapse is an exponential process. Hansen (2023) PipelinePaper230705 (pdf) Ice Melts Discussions between the first author (JEH) and field glaciologists 20 years ago revealed a frustration of the glaciologists with the conservative tone of IPCC’s assessment of ice sheets and sea level rise. One of the glaciologists said – regarding a photo of a moulin (a vertical shaft that carries meltwater to the base of the ice sheet) on Greenland – “the whole ice sheet is going down that damned hole!” Their concern was based on observed ice sheet changes and paleoclimate evidence of sea level rise by several meters in a century, which suggest that ice sheet collapse is an exponential process. Thus, as an alternative to the IPCC approach that relies on ice sheet models coupled to atmosphere-ocean GCMs (global climate models), a study was made that avoided use of an ice sheet model, as described in the paper Ice Melt. 14 In the GCM simulation, a growing amount of freshwater was added to the ocean surface mixed layer around Greenland and Antarctica, with the flux in the early 21 st century based on estimates from in situ glaciological studies and satellite observations of sea level trends near Antarctica. Doubling times of 10 and 20 years were used for the growth of freshwater flux. One merit of the GCM used in Ice Melt was its reduced, more realistic, small-scale ocean mixing, with a result that Antarctic Bottom Water in the model was formed close to the Antarctic coast 14 as it is in the real world. Continued growth of GHG emissions and meltwater led to shutdown of the North Atlantic and Southern Ocean overturning circulations, amplified warming at the foot of the ice shelves that buttress the ice sheets, and other feedbacks consistent with “nonlinearly growing sea level rise, reaching several meters over a time scale of 50-150 years.” 14 This paper exposed urgency to understand the dynamical change and the climate chaos that would occur with ice sheet collapse, a situation that may have occurred during the Eemian period when it was about as warm as today, as discussed in the Ice Melt paper. That period has potential to help us understand how close we are to a point of no return and sea level rise of several meters. Ice Melt was blackballed from IPCC’s AR6 report, which is a form of censorship, 15 as alternative views normally are acknowledged in science. Science grants ultimate authority to nature. In the opinion of JEH, IPCC is comfortable with gradualism and does not want its authority challenged. Concern about locking in nonlinearly growing sea level rise is amplified in our present paper by the revelation that the equilibrium response to current atmospheric composition is a nearly ice-free Antarctica. Portions of the ice sheets well above sea level may be recalcitrant to rapid change, but enough ice is in contact with the ocean to provide of the order of 25 m (80 feet) of sea level rise. The implication is that if we allow a few meters of sea level rise, that may lock in a much larger sea level rise. Hansen (2016) Ice Melts (pdf) 19.1 Greenland Abstract Noel Under anticipated future warming, the Greenland ice sheet (GrIS) will pass a threshold when meltwater runoff exceeds the accumulation of snow, resulting in a negative surface mass balance (SMB &lt; 0) and sustained mass loss. Here we dynamically and statistically downscale the outputs of an Earth system model to 1 km resolution to infer that a Greenland near‐surface atmospheric warming of 4.5 ± 0.3 °C—relative to pre‐industrial—is required for GrIS SMB to become persistently negative. Climate models from CMIP5 and CMIP6 translate this regional temperature change to a global warming threshold of 2.7 ± 0.2 °C. Under a high‐end warming scenario, this threshold may be reached around 2055, while for a strong mitigation scenario it will likely not be passed. Depending on the emissions scenario taken, our method estimates a 6‐13 cm sea level rise from GrIS SMB in the year 2100. Noel (2021) Greenland Ice Sheet Loss (pdf) Boers Significance It has been suggested that, in response to anthropogenic global warming, the Greenland Ice Sheet may reach a tipping point beyond which its current configuration would become unstable. A crucial nonlinear mechanism for the existence of this tipping point is the positive melt-elevation feedback: Melting reduces ice sheet height, exposing the ice sheet surface to warmer temperatures, which further accelerates melting. We reveal early-warning signals for a forthcoming critical transition from ice-core-derived height reconstructions and infer that the western Greenland Ice Sheet has been losing stability in response to rising temperatures. We show that the melt-elevation feedback is likely to be responsible for the observed destabilization. Our results suggest substantially enhanced melting in the near future. Boers Abstract The Greenland Ice Sheet (GrIS) is a potentially unstable component of the Earth system and may exhibit a critical transition under ongoing global warming. Mass reductions of the GrIS have substantial impacts on global sea level and the speed of the Atlantic Meridional Overturning Circulation, due to the additional freshwater caused by increased meltwater runoff into the northern Atlantic. The stability of the GrIS depends crucially on the positive melt-elevation feedback (MEF), by which melt rates increase as the overall ice sheet height decreases under rising temperatures. Melting rates across Greenland have accelerated nonlinearly in recent decades, and models predict a critical temperature threshold beyond which the current ice sheet state is not maintainable. Here, we investigate long-term melt rate and ice sheet height reconstructions from the central-western GrIS in combination with model simulations to quantify the stability of this part of the GrIS. We reveal significant early-warning signals (EWS) indicating that the central-western GrIS is close to a critical transition. By relating the statistical EWS to underlying physical processes, our results suggest that the MEF plays a dominant role in the observed, ongoing destabilization of the central-western GrIS. Our results suggest substantial further GrIS mass loss in the near future and call for urgent, observation-constrained stability assessments of other parts of the GrIS. Boers (2021) Western Greenland Ice Sheet is close to a tipping point Guardian 19.2 Antarctica Antarctica is larger than the US + Mexico and covered by an ice sheet several miles/km thick +80% of all global fresh water!). Early IPCC reports said Antarctica would be stable for a thousand years. But, back in 2007, Richard Alley (Penn State) said it’s already melting 100 years ahead of schedule. Hunziker (2023) The Truth About IPCC Reports 19.2.1 Sea-level Rise from Antarctica If it all melted, would raise global sea levels by 57 metres DeConto Abstract The Paris Agreement aims to limit global mean warming in the twenty-first century to less than 2 degrees Celsius above preindustrial levels, and to promote further efforts to limit warming to 1.5 degrees Celsius. The amount of greenhouse gas emissions in coming decades will be consequential for global mean sea level (GMSL) on century and longer timescales through a combination of ocean thermal expansion and loss of land ice. The Antarctic Ice Sheet (AIS) is Earth’s largest land ice reservoir (equivalent to 57.9 metres of GMSL), and its ice loss is accelerating4. Extensive regions of the AIS are grounded below sea level and susceptible to dynamical instabilities5,6,7,8 that are capable of producing very rapid retreat. Yet the potential for the implementation of the Paris Agreement temperature targets to slow or stop the onset of these instabilities has not been directly tested with physics-based models. Here we use an observationally calibrated ice sheet–shelf model to show that with global warming limited to 2 degrees Celsius or less, Antarctic ice loss will continue at a pace similar to today’s throughout the twenty-first century. However, scenarios more consistent with current policies (allowing 3 degrees Celsius of warming) give an abrupt jump in the pace of Antarctic ice loss after around 2060, contributing about 0.5 centimetres GMSL rise per year by 2100—an order of magnitude faster than today. More fossil-fuel-intensive scenarios result in even greater acceleration. Ice-sheet retreat initiated by the thinning and loss of buttressing ice shelves continues for centuries, regardless of bedrock and sea-level feedback mechanisms or geoengineered carbon dioxide reduction. These results demonstrate the possibility that rapid and unstoppable sea-level rise from Antarctica will be triggered if Paris Agreement targets are exceeded. DeConto (2021) The Paris Climate Agreement and future sea-level rise from Antarctica (Nature Paywall) Abrupt Jump in Ice Loss around 2060 The world faces a situation where there is an “abrupt jump” in the pace of Antarctic ice loss around 2060. The oceans would have to cool back down before the ice sheet could heal, which would take a very long time. On a societal timescale it would essentially be a permanent change. This tipping point for Antarctica could be triggered by a global temperature rise of 3C (5.4F) above the preindustrial era feasible by 2100 under governments’ current policies. These ice shelves won’t be able to just grow back. Antarctica is being winnowed away by a warming atmosphere as well as the heating oceans, with warming seawater entering crevasses and gnawing away at “pinning points” that hold enormous bodies of ice to submerged bedrock. A rapid acceleration of melting could cause a cascading effect where huge amounts of ice and water flow uninterrupted into the Southern Ocean. Once in motion, the impacts from such dramatic ice loss would unfurl over centuries. Milman (Guardian) 19.2.2 Amundsen Sea ice-shelf melting Naughten Abstract Ocean-driven melting of floating ice-shelves in the Amundsen Sea is currently the main process controlling Antarctica’s contribution to sea-level rise. Using a regional ocean model, we present a comprehensive suite of future projections of ice-shelf melting in the Amundsen Sea. We find that rapid ocean warming, at approximately triple the historical rate, is likely committed over the twenty-first century, with widespread increases in ice-shelf melting, including in regions crucial for ice-sheet stability. When internal climate variability is considered, there is no significant difference between mid-range emissions scenarios and the most ambitious targets of the Paris Agreement. These results suggest that mitigation of greenhouse gases now has limited power to prevent ocean warming that could lead to the collapse of the West Antarctic Ice Sheet. Naughten Implications Our simulations present a sobering outlook for the Amundsen Sea. Substantial ocean warming and ice-shelf melting is projected in all future climate scenarios, including those considered to be unrealistically ambitious. A baseline of rapid twenty-first-century ocean warming and consequent sea-level rise appears to be committed. This warming is primarily driven by an acceleration of the Amundsen Undercurrent transporting warmer CDW onto the continental shelf. Basal melting increases across all ice shelves in the Amundsen Sea, including in regions providing critical buttressing to the grounded ice sheet. Naughten (2023) Unavoidable future increase in West Antarctic ice-shelf melting over the twenty-first century 19.2.3 Thwaites Voosen An alarming crackup has begun at the foot of Antarctica’s vulnerable Thwaites Glacier, whose meltwater is already responsible for about 4% of global sea level rise. An ice sheet the size of Florida, Thwaites ends its slide into the ocean as a floating ledge of ice 45 kilometers wide. But now, this ice shelf, riven by newly detected fissures on its surface and underside, is likely to break apart in the next 5 years or so, scientists reported today at a meeting of the American Geophysical Union. The Thwaites Eastern Ice Shelf (TEIS) buttresses one third of Thwaites Glacier. Removal of TEIS has the potential to increase the contribution of Thwaites Glacier to sea level rise by up to 25%. Recent research shows that the ice shelf is losing its grip on a submarine shoal that acts as a pinning point and the shear margin that separates TEIS from the Thwaites Glacier Tongue has extended, further weakening the TEIS connection to the pinning point. A sequence of Sentinel-1 radar imagery shows that parallel wing and comb cracks have recently formed rifts at high angles to the main shear margin and are propagating into the central part of the ice shelf at rates as high as 2km per year. We use satellite data, ground-penetrating radar, and GPS measurements to suggest that final collapse of Thwaites Glacier’s last remaining ice shelf may be initiated by intersection of rifts with hidden basal crevasse zones within as little as 5 years. The central part of TEIS has no obvious surface crevasses and smooth surface topography, except for the surface expression of a pronounced basal channel aligned parallel to ice flow. Despite this smooth surface, ground-penetrating radar shows a weak zone of thin ice and complex basal topography, including numerous basal crevasses, that is not in local hydrostatic equilibrium. This local disequilibrium suggests the presence of elevated vertical shear stresses that further weaken this critical part of the ice shelf. GPS stake network observations show no measurable regional strain in the horizontal plane because large-scale flow is being accommodated by the lateral shear margin. In the near future, the propagating rifts are likely to intersect this weak zone, triggering rifting along the basal crevasses and, subsequently, along the basal channel and a into secondary set of basal crevasses on the eastern side of the basal channel. This ``zigzag’’ rift sequence would disconnect the main flow from the influence of the pinning point (and compressive arches) and will ultimately lead to a complete disintegration of the ice shelf. Voosen (2021) Ice shelf holding back keystone Antarctic glacier within years of failure 19.2.4 Gyre Ross Voosen Unlike fast-shrinking Arctic sea ice, the sea ice ringing Antarctica seemed more resistant to climate change—until recently. But now a long-term decline may have set in, and it could have unexpected and ominous domino effects, according to several recent studies. Dwindling sea ice could strengthen a whirling current called the Ross Gyre, bringing warm waters closer to land and hastening the collapse of the West Antarctic ice sheet, which locks up enough water to raise global sea levels by 3.3 meters. The warmer water and glacial melt expected from a stronger gyre already show hints of slowing part of the global ocean’s overturning circulation, a critical “conveyor belt” of currents that distributes heat and removes carbon dioxide from the atmosphere. Although climate models predict an eventual decline in Antarctic sea ice, the ice cover was actually expanding slightly until a decade ago. Then from 2014 to 2017, the ice began to vanish rapidly, losing more in 3 years than the Arctic had lost in 3 decades. The ice rebounded for a few years, then resumed its downward march, reaching record lows last year and again this year. This erratic behavior makes it difficult to know whether the ice’s long-term decline has begun in earnest. In some regions—including the seas off West Antarctica—a decline is already unmistakable. In these waters, hidden beneath sea ice, spins the 1000-kilometer-wide Ross Gyre, fed by warm currents from farther north. As sea ice thinned, the force of surface winds on newly exposed water strengthened the gyre and expanded it.The larger gyre brought warm water closer to the glaciers of West Antarctica, which spill out into the ocean as ice shelves and are vulnerable to melting from below. Within 30 years of its expansion, the gyre could warm the waters beneath the glaciers by 1°C — an unprecedented heat wave that would accelerate erosion of the ice. Most alarming, the gyre expanded even in scenarios where greenhouse emissions dropped and climate warming slowed. As soon as the sea ice started to decline in the model, the expansion occurred. It’s out of control now because of what humans have already done. As the gyre expands, it would also send warm water and freshwater from the melting glaciers away from the ice shelves and toward the Ross Sea, where they could disrupt a process called bottom water formation. Sea ice continually forms and blows away in the Ross Sea. Enriched in salt expelled by the ice and exposed to the frigid wind, the surface waters grow heavy enough to sink into the abyss. This bottom water “factory” is one of the engines for the global overturning circulation, the large-scale flows that shuttle heat and nutrients throughout the world’s ocean basins, while also sequestering carbon dioxide in the deep sea. Arrays of robotic Deep Argo floats, which sink into the depths and then surface to transmit data, have found that these bottom waters have started to warm, according to a study published last year. Moreover, a 63-year record from the Ross Sea, also published in 2022, found that waters close to the surface had steadily become less dense. Both effects could contribute to the faltering of the bottom-water factory and the overturning circulation. Oceanographers have similar worries about a more famous part of the overturning circulation, in the Atlantic Ocean, but they have not yet detected any weakening in modern observations. But the change in the Southern Ocean is clear, says Sang-Ki Lee, a physical oceanographer at the National Oceanic and Atmospheric Administration’s Atlantic Oceanographic and Meteorological Laboratory. Using a climate model calibrated by historical ocean measurements, Lee and his colleagues found that the lower part of the overturning circulation has weakened by up to 20% since the 1970s. As sea ice declines and the gyre expands, Antarctic bottom water formation could slow further. Late last month in Nature, a group led by Qian Li, a physical oceanographer at the Massachusetts Institute of Technology, published a new high-resolution ocean model predicting that, by 2050, the lower cell of the overturning circulation will have weakened by 40% from present times due to increased meltwater. And that means the ocean’s ability to mitigate climate change by soaking up nearly one-third of humanity’s annual carbon emissions could falter as well. Voosen (2023) Dwindling sea ice may speed melting of Antarctic glaciers 19.3 Arctic Sea Ice ARCTIC SEA ICE AT RECORD LOW for this time of year. This is an enormous source of amplifying feedback. Losing the remaining Arctic sea ice and its reflection of solar energy back to space would be equivalent to another one trillion tons of CO2. Peter Carter (tweet) 19.4 Ice Sheet Collapse Guardian Ice sheets can collapse into the ocean in spurts of up to 600 metres (2,000 feet) a day, a study has found, far faster than recorded before. Scientists said the finding, based on sea floor sediment formations from the last ice age, was a “warning from the past” for today’s world in which the climate crisis is eroding ice sheets. Guardian (2023) Ice sheets can collapse at 600 metres a day, far faster than feared Batchelor Abstract Rates of ice-sheet grounding-line retreat can be quantified from the spacing of corrugation ridges on deglaciated regions of the seafloor1,2, providing a longterm context for the approximately 50-year satellite record of ice-sheet change3–5. However, the few existing examples of these landforms are restricted to small areas of the seafloor, limiting our understanding of future rates of grounding-line retreat and, hence, sea-level rise. Here we use bathymetric data to map more than 7,600 corrugation ridges across 30,000 km2 of the mid-Norwegian shelf. The spacing of the ridges shows that pulses of rapid grounding-line retreat, at rates ranging from 55 to 610 m day−1, occurred across low-gradient (±1°) ice-sheet beds during the last deglaciation. These values far exceed all previously reported rates of grounding-line retreat across the satellite3,4,6,7 and marine-geological1,2 records. The highest retreat rates were measured across the flattest areas of the former bed, suggesting that near-instantaneous ice-sheet ungrounding and retreat can occur where the grounding line approaches full buoyancy. Hydrostatic principles show that pulses of similarly rapid grounding-line retreat could occur across low-gradient Antarctic ice-sheet beds even under present-day climatic forcing. Ultimately, our results highlight the often-overlooked vulnerability of flat-bedded areas of ice sheets to pulses of extremely rapid, buoyancy-driven retreat. Batchelor (2023) Rapid, buoyancy-driven ice-sheet retreat of hundreds of metres per day "],["ocean.html", "20 Ocean 20.1 Ocean Temperature 20.2 Ocean Skin 20.3 Ocean Heat Content 20.4 El Niño - La Niña 20.5 Ocean Acidification 20.6 Ocean-Atmosphere Carbon Balance 20.7 Sea Level Rise 20.8 AMOC - Gulf Stream 20.9 Denmark Strait cataract 20.10 Whale Mitigation 20.11 Antarctica’s Role 20.12 Failing phytoplankton, failing oxygen", " 20 Ocean IPCC SROCC The SROCC is the second special report that the IPCC has published this year and the third of the IPCC’s sixth assessment cycle. The report on climate change and land was released in August, while the 1.5C report was published in October 2018. The next special report will be on “climate change and cities”, which will be published during the seventh assessment cycle of the IPCC – and so will come after its sixth assessment report (AR6) in 2021-22. The special report “assesses new knowledge” since the IPCC’s fifth assessment report (AR5) – published in 2013-14 – and its 1.5C report. It covers “how the ocean and cryosphere have and are expected to change with ongoing global warming, the risks and opportunities these changes bring to ecosystems and people, and mitigation, adaptation and governance options for reducing future risks”. The global ocean – comprising the Arctic, Pacific, Atlantic, Indian, and Southern oceans, as well as their marginal seas – covers 71% of the Earth surface, the report notes. It contains “about 97% of the Earth’s water, supplies 99% of the Earth’s biologically-habitable space, and provides roughly half of the primary production on Earth”. The cryosphere refers to frozen components of the Earth system that are at or below the land and ocean surface. These include “snow, glaciers, ice sheets, ice shelves, icebergs, sea ice, lake ice, river ice, permafrost and seasonally frozen ground”, the report notes. IPCC SROCC (2021) Carbonbrief on SROCC “All people on Earth depend directly or indirectly on the ocean and cryosphere,” the report warns, noting that “human communities in close connection with coastal environments, small islands, polar areas and high mountains are particularly exposed” to changes, such as sea level rise and melting glaciers. It is “virtually certain” that the global ocean has warmed unabated since 1970, the report stresses, while “global warming has led to widespread shrinking of the cryosphere”. These changes are increasingly pushing adaptation responses “to their limits”, with the most vulnerable people having “the lowest capacity” to respond. Sustainable development and climate change resilience depend “critically on urgent and ambitious emissions reductions coupled with coordinated sustained and increasingly ambitious adaptation actions”. In this detailed Q&amp;A, Carbon Brief unpacks what the report says about how climate change is affecting the Earth’s ice and oceans – and the wider impacts that is having on sea levels, marine life and human society, as well as extreme events and potential “tipping points”. Carbonbrief on SROCC 20.1 Ocean Temperature EPA Based on the historical record, increases in sea surface temperature have largely occurred over two key periods: between 1910 and 1940, and from about 1970 to the present. Sea surface temperature appears to have cooled between 1880 and 1910. Changes in sea surface temperature can alter marine ecosystems in several ways. For example, variations in ocean temperature can affect what species of plants, animals, and microbes are present in a location, alter migration and breeding patterns, threaten sensitive ocean life such as corals, and change the frequency and intensity of harmful algal blooms such as “red tide.”1 Over the long term, increases in sea surface temperature could also reduce the circulation patterns that bring nutrients from the deep sea to surface waters. Changes in reef habitat and nutrient supply could dramatically alter ocean ecosystems and lead to declines in fish populations, which in turn could affect people who depend on fishing for food or jobs.2,3 Because the oceans continuously interact with the atmosphere, sea surface temperature can also have profound effects on global climate. Increases in sea surface temperature have led to an increase in the amount of atmospheric water vapor over the oceans.4 This water vapor feeds weather systems that produce precipitation, increasing the risk of heavy rain and snow (see the Heavy Precipitation and Tropical Cyclone Activity indicators). Changes in sea surface temperature can shift storm tracks, potentially contributing to droughts in some areas.5 Increases in sea surface temperature are also expected to lengthen the growth season for certain bacteria that can contaminate seafood and cause foodborne illnesses, thereby increasing the risk of health effects.6 EPA IUCN The ocean absorbs vast quantities of heat as a result of increased concentrations of greenhouse gases in the atmosphere, mainly from fossil fuel consumption. The Fifth Assessment Report published by the Intergovernmental Panel on Climate Change (IPCC) in 2013 revealed that the ocean had absorbed more than 93% of the excess heat from greenhouse gas emissions since the 1970s. This is causing ocean temperatures to rise. Data from the US National Oceanic and Atmospheric Administration (NOAA) shows that the average global sea surface temperature – the temperature of the upper few metres of the ocean – has increased by approximately 0.13°C per decade over the past 100 years. A 2012 paper published in the journal Geophysical Research Letters revealed that the deep ocean is also affected, with one third of the excess heat absorbed 700 m below the sea surface. Modelling studies published in IPCC’s 2013 Report predict that there is likely to be an increase in mean global ocean temperature of 1-4oC by 2100. The ocean’s ability to absorb excess heat has shielded humans from even more rapid changes in climate. Without this oceanic buffer, global temperatures would have risen much more than they have done to date. IPCC’s Fourth Assessment Report published in 2007 estimated that the Earth had experienced a warming of 0.55°C since the 1970s. According to an analysis by the Grantham Institute, if the same amount of heat that has gone into the top 2,000 m of the ocean between 1955 and 2010 had gone into the lower 10 km of the atmosphere, the Earth would have seen a warming of 36°C. Ocean warming leads to deoxygenation – a reduction in the amount of oxygen dissolved in the ocean – and sea-level rise – resulting from the thermal expansion of sea water and continental ice melting. The rising temperatures, coupled with ocean acidification (the decrease in pH of the ocean due to its uptake of CO2), affect marine species and ecosystems and, consequently, the fundamental benefits humans derive from the ocean. Marine fishes, seabirds and marine mammals all face very high risks from increasing temperatures, including high levels of mortalities, loss of breeding grounds and mass movements as species search for favourable environmental conditions. Coral reefs are also affected by increasing temperatures which cause coral bleaching and increase their risk of mortality. A 2012 report by the Food and Agriculture Organization of the United Nations estimates that marine and freshwater capture fisheries and aquaculture provide 4.3 billion people with about 15% of their animal protein. Fisheries and aquaculture are also a source of income for millions of people worldwide. By altering distributions of fish stocks and increasing the vulnerability of fish species to diseases, ocean warming is a serious risk to food security and people’s livelihoods globally. Economic losses related to ocean warming are likely to run from tens to hundreds of millions of dollars. Rising temperatures also affect vegetation and reef-building species such as corals and mangroves, which protect coastlines from erosion and sea-level rise. Rising sea levels and erosion will particularly affect low-lying island countries in the Pacific Ocean, destroying housing and infrastructure and forcing people to relocate. The rise in sea surface temperatures is causing more severe hurricanes and the intensification of El Niño events bringing droughts and floods. This can have significant socio-economic and health effects in some regions of the world. Warming ocean temperatures are linked to the increase and spread of diseases in marine species. Humans risk direct transmission of these diseases when consuming marine species, or from infections of wounds exposed in marine environments. IUCN 20.2 Ocean Skin Bellenger Abstract The ocean skin is composed of thin interfacial microlayers of temperature and mass of less than 1 mm where heat and chemical exchanges are controlled by molecular diffusion. It is characterized by a cooling of ∼−0.2 K and an increase in salinity of ∼0.1 g/kg (absolute salinity) relative to the water below. A surface observation-based air-sea CO2 flux estimate considering the variation of the CO2 concentration in these microlayers has been shown to lead to an increase in the global ocean sink of the anthropogenic CO2 by +0.4 PgC yr−1 (15% of the global sink). This study analyzes this effect in more details using a 15-year (2000–2014) simulation from an Earth System Model (ESM) that incorporates a physical representation of the ocean surface layers (diurnal warm layer and rain lenses) and microlayers. Results show that considering the microlayers increases the simulated global ocean carbon sink by +0.26 to +0.37 PgC yr−1 depending on assumptions on the chemical equilibrium. This is indeed about 15% of the global sink (2.04 PgC yr−1) simulated by the ESM. However, enabling the ocean skin adjustment to feedback on ocean carbon concentrations reduces this increase to only +0.13 (±0.09) PgC y−1. Coupled models underestimate the ocean carbon sink by ∼5% if the ocean skin effect is not included. Bellenger Key Points Key Points Considering the ocean skin increases the global ocean \\({CO}_2\\) sink by +0.26 to +0.37 PgC \\({yr}^{−1}\\) (∼15% for 2000–2014) in an Earth System Model Enabling the ocean skin adjustment to feedback on ocean carbon concentrations dampens this increase to +0.13 PgC \\({yr}^{−1}\\) (∼5% for 2000–2014) This global adjustment depends on the \\({CO}_2\\) flux formulation and ultimately on the model capacity to transfer \\({CO}_2\\) into the ocean interior Bellenger Plain Language Summary The ocean skin is a thin layer of less than a millimeter that is in contact with the atmosphere, where the heat and chemical exchanges are controlled by molecular diffusion. It typically corresponds to a temperature at the ocean interface that is cooler by −0.2 K than the water at a depth of a millimeter. It also corresponds to a salinity that is slightly higher at the interface. Taking into account these temperature and salinity changes in this thin layer can change calculations of the global ocean carbon sink substantially. We use a global Earth System Model including a representation of the ocean skin to study this impact. We found an increase of 15% in the simulated global ocean carbon sink. This is consistent with past studies. Enabling the flux to feedback on the ocean carbon concentration significantly reduces its impact. We conclude by discussing the uncertainties in the global ocean carbon sink associated with the formulation of the carbon flux and the representation of the ocean skin. Bellenger (2023) Sensitivity of the Global Ocean Carbon Sink to the Ocean Skin in a Climate Model (PayWall) 20.3 Ocean Heat Content While the atmosphere varies a bit year to year, over 90% of heat trapped by increased atmospheric greenhouse gas concentrations ends up in the oceans. There the accumulation of heat year-over-year is unambiguous. 20.3.1 Deep Ocean Heat Content Bagnell Abstract The historical evolution of Earth’s energy imbalance can be quantified by changes in the global ocean heat content. However, historical reconstructions of ocean heat content often neglect a large volume of the deep ocean, due to sparse observations of ocean temperatures below 2000 m. Here, we provide a global reconstruction of historical changes in full-depth ocean heat content based on interpolated subsurface temperature data using an autoregressive artificial neural network, providing estimates of total ocean warming for the period 1946-2019. We find that cooling of the deep ocean and a small heat gain in the upper ocean led to no robust trend in global ocean heat content from 1960-1990, implying a roughly balanced Earth energy budget within −0.16 to 0.06 \\(Wm^{−2}\\) over most of the latter half of the 20th century. However, the past three decades have seen a rapid acceleration in ocean warming, with the entire ocean warming from top to bottom at a rate of 0.63 ± 0.13 \\(Wm^{−2}\\). These results suggest a delayed onset of a positive Earth energy imbalance relative to previous estimates, although large uncertainties remain. Bagnell Memo Over the past 15 years, the Argo program5 has deployed thousands of autonomous floats which provide continuous observations of the temperature in the upper half of the ocean, to a depth of 2000 m. This has allowed for a convergence in estimates of OHC over the last fifteen years2,5 and increased confidence in calculations of the ongoing EEI in light of independent confirmation from modern satellite observations2,6,7. However, several challenges exist for reducing uncertainty in estimates of total ocean warming and extending it over longer time periods. First, the deep ocean below 2000 m remains poorly observed, even during the Argo era, which leads to additional uncertainty on current estimates of total warming. While absolute temperature changes in the deep ocean are small8, the large volume of the ocean below 2000 m makes it a potentially meaningful contributor to the global heat inventory. Repeat hydrographic sampling indicates that the deep ocean may be warming significantly in some regions9, particularly the Southern Ocean8, whereas other regions may still be cooling as a response to cold periods in the past millennium10, making it critical to include the heat content of the deep ocean in global estimates of ocean warming. The second issue is that, prior to 2005, data collection was conducted primarily by scientific research vessels and ships of opportunity, leaving areas outside of major trade routes or research transects with few direct observations2,11. This leaves large gaps in the observational record that must be filled in order to estimate OHC. Several methods have been devised to overcome these gaps in ocean temperature observations and to produce estimates of historical changes in OHC. One common approach applies objective mapping to interpolate the sparse temperature records in space and time. However, while these objective mapping products can reconstruct ocean temperatures back to ~1950, they do not extend below 2000 m due to the sparse sampling at these depths. Dynamical data-assimilation models offer an alternative approach to objective mapping and provide full-depth estimates of OHC, but data sparsity means these models are poorly constrained at depth, leading to large cross-model varianc. Another approach based on the passive transport of surface temperature anomalies into the interior ocean can also reconstruct full-depth temperature anomalies and OHC changes, but relies on the potentially incorrect assumption of steady-state circulation16 and is sensitive to the initial condition used in the simulation10,16 and to poorly known surface ocean temperatures dating back several millennia. Finally, statistical methods have been used to detect large-scale trends in the deep ocean temperature from repeat hydrographic sampling, but these have coarse spatial resolution and do not cover the period prior to the mid-1980s. An interpolation product based on in situ temperature data that covers the deep ocean below 2000 m, allowing for a full-depth OHC estimate, remains crucial to reliably estimating historical changes in EEI. Here, we interpolate historical ocean temperature data using an autoregressive artificial neural network (ARANN) to produce a single consistent estimate of the top-to-bottom OHC change for 1946–2019 using in situ temperature data from the World Ocean Database. This approach adapts an established machine learning method to perform an iterative autoregression that adjusts spatio-temporal correlation scales over time from the in situ temperature data itself, and effectively propagates information from well-sampled times and regions to more sparsely sampled areas to produce global maps of temperature anomalies at roughly annual resolution. Figure: Estimates of ocean heat content (OHC) changes for a the global ocean from the surface to seafloor, b the upper 700 m of the ocean, c the depth range 700–2000 m, and (d) the depth range 2000–5500 m. The mean estimates derived from this study (ARANN, blue) are shown with shading covering two standard deviations from the mean over the 240 ARANN ensemble members. The zero anomaly is defined such that the mean OHC of the ARANN estimate for the period 1946–2019 is zero. Also shown are the mean OHC anomaly from the IAP11 (red), NOAA12 (yellow), and JMA13 (purple) objective mapping products, which cover the 0–2000 m depth interval as shown in (b)–(c). These products have been adjusted to the mean ARANN OHC anomaly for 2005–2019. Shown for a the full ocean depth and d the deep ocean are OHC anomalies from passive ocean heat uptake models using Green’s functions (GF)16 (light blue) and an optimized mixing model (OPT-0015)10 (green). The passive ocean heat uptake products are adjusted to the mean ARANN anomaly for 1955–1985. Repeat hydrographic sampling (RHS) gives temperature trends since 1985 in the deep ocean9 (maroon; d). The RHS method gives a linear trend from 1985 to 2000 and from 2000 to 2015, which has been adjusted to the mean ARANN anomaly for 1985–2015. Bagnell (2021) 20th century cooling of the deep ocean contributed to delayed acceleration of Earth’s energy imbalance (pdf) EOS on Bagnell 20.4 El Niño - La Niña Guardian The El Niño-La Niña phenomenon is the biggest cause of year-to-year differences in weather in many regions. In La Niña years, the east-to-west Pacific trade winds are stronger, pushing warm surface waters to the west and drawing up deeper, cooler water in the east. El Niño events happen when the trade winds wane, allowing the warm waters to spread back eastwards, smothering the cooler waters and leading to a rise in global temperatures. Nations bordering the west Pacific, including Indonesia and Australia, experience hotter and drier conditions, though China can suffer flooding in the Yangtze basin after big El Niños. India’s monsoons, and rains in southern Africa can also be suppressed. Other regions, such as east Africa and the southern US, both of which have suffered recent droughts, can get more rain and flooding. In South America, southern regions are wetter, but the Amazon, already approaching a dangerous tipping point, is drier. The effects of El Niño could also be felt as far as the northern hemisphere mid-latitudes, with a likelihood of wetter conditions in Spain from summer onwards and drier conditions on the eastern seaboard of the US in the following winter and spring. The biggest unanswered question is whether climate change favoured more El Niño or more La Niña events. That is crucially important for countries looking at long-term adaptation, and will need much higher-resolution climate models. That can only come about with bigger computers. Guardian (2023) Warning of unprecedented heatwaves as El Niño set to return in 2023 20.4.1 2023 Ocean Heat Surge Climate ReAnlyzer Daily OST Chart) Schuckmann Abstract The Earth climate system is out of energy balance, and heat has accumulated continuously over the past decades, warming the ocean, the land, the cryosphere, and the atmosphere. According to the Sixth Assessment Report by Working Group I of the Intergovernmental Panel on Climate Change, this planetary warming over multiple decades is human-driven and results in unprecedented and committed changes to the Earth system, with adverse impacts for ecosystems and human systems. The Earth heat inventory provides a measure of the Earth energy imbalance (EEI) and allows for quantifying how much heat has accumulated in the Earth system, as well as where the heat is stored. Here we show that the Earth system has continued to accumulate heat, with 381±61 ZJ accumulated from 1971 to 2020. This is equivalent to a heating rate (i.e., the EEI) of 0.48±0.1 W m−2. The majority, about 89 %, of this heat is stored in the ocean, followed by about 6 % on land, 1 % in the atmosphere, and about 4 % available for melting the cryosphere. Over the most recent period (2006–2020), the EEI amounts to 0.76±0.2 W m−2. The Earth energy imbalance is the most fundamental global climate indicator that the scientific community and the public can use as the measure of how well the world is doing in the task of bringing anthropogenic climate change under control. Moreover, this indicator is highly complementary to other established ones like global mean surface temperature as it represents a robust measure of the rate of climate change and its future commitment. We call for an implementation of the Earth energy imbalance into the Paris Agreement’s Global Stocktake based on best available science. The Earth heat inventory in this study, updated from von Schuckmann et al. (2020), is underpinned by worldwide multidisciplinary collaboration and demonstrates the critical importance of concerted international efforts for climate change monitoring and community-based recommendations and we also call for urgently needed actions for enabling continuity, archiving, rescuing, and calibrating efforts to assure improved and long-term monitoring capacity of the global climate observing system. The data for the Earth heat inventory are publicly available, and more details are provided in Table 4. Schuckmann (2023) Heat stored in the Earth system 1960–2020: where does the energy go? (pdf) Henson The El Niño-Southern Oscillation, which has a huge influence on global weather patterns, isn’t behaving as computer models predicted. That’s puzzling scientists. ENSO is a recurring ocean-and-atmosphere pattern that warms and cools the eastern tropical Pacific through El Niño and La Niña events that last from one to three years. Once El Niño or La Niña emerges, the odds reliably shift toward hotter, colder, wetter, or drier conditions for various parts of the globe, from Oceania to North America to Africa. But though ENSO’s effects are well known, the phenomenon itself is notoriously tough to predict. And its slippery nature is complicating crucial multi-decade projections of climate. Many aspects of human-caused climate change are playing out as long predicted, including overall warming of the global atmosphere and oceans as well as the intensification of rainfall extremes and the drying of many subtropical areas. Not so for ENSO. Top global climate models have predicted for more than 20 years that the tropical Pacific would gradually shift toward an “El Niño-like” state, with the surface waters warming more rapidly toward the east than toward the west. Instead, just the opposite is going on. The western tropical Pacific has warmed dramatically, as predicted, but unusually persistent upwelling of cool subsurface water has led to a slight drop in average sea surface temperature over much of the eastern tropical Pacific. The result is a strengthening west-to-east temperature contrast that increasingly resembles La Niña. Scientists expect that El Niño events will continue to occur – such as the one predicted to arrive later this year – but they will take place on a backdrop of an ocean that looks more like La Niña. All this is far more than an esoteric science matter. According to an ENSO Blog entry posted Jan. 26 at climate.gov: “How the sea surface temperature trend pattern will change has profound, worldwide implications. … If you are trying to make decisions based on projections of the future, you need to know the answer. Among the impacts that could be notably different in a La Niña-dominated world: Atlantic hurricane activity is substantially higher on average during La Niña than during El Niño. The U.S. Sun Belt, including much of California, tends to get less rainfall and mountain snow during La Niña, with widespread drought becoming more likely. (There are occasional exceptions, such as the very wet winter of 2022-23 in the Southwest.) The highly vulnerable Horn of Africa is more drought-prone during La Niña, while rains in the African Sahel tend to be more reliable. Typhoons are more likely to slam China, the Philippines, and Vietnam – and less likely to strike Guam, Japan, and Taiwan – during La Niña. Heavy rains and floods often plague eastern Australia during La Niña. The southwest monsoon in India is often wetter than average. There are hints — though not yet enough cases to pass statistical muster — that La Niña events themselves are becoming more frequent, which would go hand in hand with the evolving Pacific backdrop. The La Niña-like temperature contrast in the tropical Pacific has now been strengthening for so long that it’s gotten tougher to ascribe to natural variability. It could be chalked up to a cool phase of the Pacific Decadal Oscillation, another recurring weather pattern that can span 20 to 30 years. Yet that phenomenon is largely influenced by ENSO itself. Climate experts are thus ramping up efforts to diagnose what it is that the state-of-the-art models could be missing and whether the long-expected El Niño-like trend may yet turn up later in the century. At the core of ENSO is the Walker Circulation, the large-scale flow of air over the Pacific tropics. On average, air rises above the very warm waters of the western Pacific and sinks across the eastern Pacific, where chilly water predominates. Completing the Walker Circulation loop (as shown in Figure 3 below) are westward flow a few miles above the Pacific tropics and eastward flow – the famed trade winds – at the surface. Fig: This schematic of average (neutral) conditions over the Pacific Ocean shows the Walker Circulation, with rising air and showers and thunderstorms to the west and descending air to the east. Trade winds (surface arrows) push warm water toward the west, allowing colder water to upwell toward the east. The depth of the upper Pacific Ocean is exaggerated in this schematic. (Image credit: climate.gov) When the Walker Circulation is strong, as it is during La Niña, the east-to-west-blowing trade winds are boosted and there is more upwelling of cold water off Ecuador and Peru. When the Walker Circulation weakens, the trade winds slacken or even reverse, and the resulting westerly surface winds can push warm water all the way to the South American coast. The usual upwelling weakens, and an El Niño event is in place. The warm water leads to rising air thousands of miles farther east than usual, helping to suppress the Walker Circulation and torquing other weather patterns far away. Given that El Niño is fighting against the grain of the usual atmospheric and oceanic conditions, it normally takes only about nine to 12 months before the tropics swing back toward a more typical Walker Circulation. In contrast, La Niña — with an extra-strong version of the Walker Circulation — can persist or recur for as long as three consecutive years, as it did from 2020-21 to 2022-23. There’s no doubt that the tropical Pacific has behaved in more of a La Niña-like than El Niño-like fashion over the past several decades. The questions now center on whether the trend might still be natural variability ­— and if it’s not, what’s forcing it to happen. The cold, remote Southern Ocean could be a big part of the Pacific’s puzzling trend. Much like the eastern tropical Pacific, the Southern Ocean is one of the few other areas on Earth where sea surface temperatures have cooled rather than warmed since the 1980s, in spite of pronounced surface warming over the Antarctic Peninsula and concerns about longer-term deep-ocean warming. Usually it’s the tropical Pacific that triggers weather and climate effects at middle and higher latitudes, but the Southern Ocean itself may be influencing ENSO. Adding to the complexities at hand, it’s possible that whatever factors are now pushing the tropical Pacific toward a La Niña-like state will eventually get overwhelmed by longer-term global warming. That could lead to the El Niño-like outcome that models have long projected — and thus vindicate the models, at least in the long run. In one set of experiments with models that fully couple the atmosphere and ocean, Heede and colleagues found the observed La Niña-like state emerging and persisting for 20 to 100 years, depending on how quickly carbon dioxide is added. Somewhere between 50 and 100 years, the subtropical ocean circulation weakens and warms enough to cut down on cold upwelling, pushing the system toward El Niño-like conditions. There are good reasons why ENSO is so difficult to capture in both seasonal and multi-decadal modeling. For just one example, consider the thermocline, the oceanic boundary that separates warmer near-surface water from cooler deep water. Across the tropical Pacific, the thermocline depth normally varies from about 450 feet in the west to only about 50 feet in the east. That’s paper-thin when compared to the 12,000 miles of distance from west to east along the Pacific equator, and thus difficult for global climate models to capture with precision. “East Africa has been struggling with drought for most of the 21st century, including the last few years,” Seager noted. “The models predict that that region should be getting wetter, and it hasn’t. The fact that it hasn’t is largely consistent with what the equatorial Pacific Ocean is doing. The U.S. Southwest will experience the landscape-parching effects of hotter weather no matter what ENSO does. But any continued tilt toward La Niña-like conditions would also tend to favor the prolonged deficits in rainfall and mountain snowfall that have plagued the region since 2000. Even the bountifully wet winter of 2022-23 is unlikely to turn the long-term tide. “The combined impact of warmer temps and potentially lower precipitation is not good news,” Climate scientists love studying what happens in the tropical Pacific, but my point of view is that no one’s living there. We have to make the link from what happens in the tropical Pacific to what happens over land. Henson (2023) A mystery in the Pacific is complicating climate projections 20.5 Ocean Acidification Mackie Our goal is to provide you with the background to understand the chemical and physical processes behind ocean acidification. This will allow you to evaluate the commentary on the web. We were motivated to write the series by the increasing number comments and posts in the blogosphere based on misconceptions about ocean acidification. However, despite taking 18 posts and 18,000 words we have only scratched the surface of the chemistry. This is not surprising as the concepts we have introduced do not stand alone. Inevitably we have had to leave some things out and simplified others. For each concept we have explained a dozen more cry out for their 15 minutes. Here is a negligently incomplete list of a further 18 Quite Important concepts – each deserving of at least a post – that we didn’t mention or skipped lightly over. There are hundreds more. δ 13 C, Ψ, Activity coefficients and when and how to use them, Alkalinity: A really useful definition for alkalinity (i.e. one that is a measurable quantity), Buffer theory, Burial of CaCO 3 sediments, Carbon vs. oxygen stoichiometry for combustion of different fossil fuels, Congruent/incongruent dissolution, Conservative ions and charge balance in seawater, Dissolution of CaCO 3 above the lysocline, DOM, Fugacity, Inhibition of precipitation, Mass accumulation rate for CaCO 3 sediments, Mixed carbonates (incorporation of other elements), Net global production of CaCO 3 , different pH scales, Revelle Factor. Figure: Carbon reservoirs as preindustrial size (blue circles) and modern size (red circles) with change since the industrial revolution (black circles). Numbers give size of preindustrial with amount of change (+ or –) and also express the change as a %. Size in gigatons of carbon = Gt C. (1 Gt = 1,000 million tons, i.e. billion tons). Mackie Memo The definition of an acid (in aqueous chemistry) is a substance that gives (or donates) an \\(H^{+}\\) (proton) to water to form $H_{3}O^{+} , while a base takes (or accepts) the proton. This means that each acid (or base) reacts with a base (or acid) to produce another acid-base pair. Naive application of Le Chatelier’s principle is not good enough for complex chemistry. Le Chatelier’s Principle is a way to predict how a see-saw like equilibrium reaction responds when it is disturbed. It is a useful way to consider simple reactions. However, Le Chatelier’s principle only applies to single-step chemical reactions. It can’t be applied in a simple way to coupled or sequential reactions. Mackie (2011) OA not not OK An introduction to the chemistry of Ocean Acidification (pdf) Mackie - Individual Chapters on SkepticalScience 20.5.1 Outgassing Sealevel.info Mankind is currently adding about 5 ppmv of CO2 (about 10½ PgC) to the atmosphere each year, but the atmospheric CO2 level is only rising at a rate of about 2.5 ppmv per year. The difference is the rate at which natural negative feedbacks (mainly terrestrial greening and absorption by the oceans) remove CO2 from the air: currently about 2.5 ppmv per year. However, the solubility of gases like CO2 (or CH4) in water does decrease as the water gets warmer (per the temp­er­a­ture depen­dence of Henry’s law), so as the oceans warm they would outgas CO2, if nothing else changed. The capacity of the water to hold dissolved CO2 decreases by about 3% per 1°C by which the water warms. So, when the oceans are absorbing CO2, as is currently the case in most places other than the tropics, if the water warms then the oceans absorb CO2 slightly more slowly. The effect of temperature change on the solubility of gases in water is surely one of the reasons that atmospheric CO2 levels swing up &amp; down by about 90 ppmv over glaciation/deglaciation cycles. (There are almost certainly also biological [2] and/or ice sheet burial mechanisms at work, which increase the magnitude of glacial-interglacial CO2 swings.) The CO2, in turn, works as a GHG to cause warming. That is a slight positive feedback mechanism. That positive feedback loop is undoubtedly one of the causes for the apparent hysteresisin the temperature and CO2 records: Over the last million years, the Earth’s climate has tended to be either mild, as in our current interglacial (the Holocene), or, more of the time, heavily glaciated and cold, with relatively brief, unstable transitions between. Sealevel.info 20.5.2 OAE - Ocean Alkalinity Enhancement State of the planet Ocean alkalinity enhancement (OAE) is a marine carbon dioxide removal (CDR) approach. Publicly funded research projects have begun, and philanthropic funding and start-ups are collectively pushing the field forward. This rapid progress in research activities has created an urgent need to learn if and how OAE can work at scale. The Best Practices Guide to OAE research contains 7 topics broken down into 13 chapters that compare and synthesise previously published methods and offer guidance for future research. State of the planet (2023) Guide to Best Practices in Ocean Alkalinity Enhancement Research 20.6 Ocean-Atmosphere Carbon Balance NASA For eons, the world’s oceans have been sucking carbon dioxide out of the atmosphere and releasing it again in a steady inhale and exhale. The ocean takes up carbon dioxide through photosynthesis by plant-like organisms (phytoplankton), as well as by simple chemistry: carbon dioxide dissolves in water. It reacts with seawater, creating carbonic acid. Carbonic acid releases hydrogen ions, which combine with carbonate in seawater to form bicarbonate, a form of carbon that doesn’t escape the ocean easily. Figure: The concentration of carbon dioxide (CO2) in ocean water (y axis) depends on the amount of CO2 in the atmosphere (shaded curves) and the temperature of the water (x axis). This simplified graph shows that as atmospheric CO2 increases from pre-industrial levels (blue) to double (2X) the pre-industrial amounts (light green), the ocean CO2 concentration increases as well. However, as water temperature increases, its ability dissolve CO2 decreases. Global warming is expected to reduce the ocean’s ability to absorb CO2, leaving more in the atmosphere…which will lead to even higher temperatures. As we burn fossil fuels and atmospheric carbon dioxide levels go up, the ocean absorbs more carbon dioxide to stay in balance. But this absorption has a price: these reactions lower the water’s pH, meaning it’s more acidic. And the ocean has its limits. As temperatures rise, carbon dioxide leaks out of the ocean like a glass of root beer going flat on a warm day. Carbonate gets used up and has to be re-stocked by upwelling of deeper waters, which are rich in carbonate dissolved from limestone and other rocks. In the center of the ocean, wind-driven currents bring cool waters and fresh carbonate to the surface. The new water takes up yet more carbon to match the atmosphere, while the old water carries the carbon it has captured into the ocean. The warmer the surface water becomes, the harder it is for winds to mix the surface layers with the deeper layers. The ocean settles into layers, or stratifies. Without an infusion of fresh carbonate-rich water from below, the surface water saturates with carbon dioxide. The stagnant water also supports fewer phytoplankton, and carbon dioxide uptake from photosynthesis slows. In short, stratification cuts down the amount of carbon the ocean can take up. The ocean does not take up carbon uniformly. It breathes, inhaling and exhaling carbon dioxide. In addition to the wind-driven currents that gently stir the center of ocean basins (the waters that are most limited by stratification), the ocean’s natural, large-scale circulation drags deep water to the surface here and there. Having collected carbon over hundreds of years, this deep upwelling water vents carbon dioxide to the atmosphere like smoke escaping through a chimney. The stronger upwelling brought by the cold phase of the Pacific Decadal Oscillation apparently enhanced the size of the chimney and let more carbon escape to the atmosphere. Figure: The global oceans are connected by deep currents (blue lines) and surface currents (red). Carbon from the atmosphere enters the ocean depths in areas of deep water formation in the North Atlantic and offshore of the Antarctic Peninsula. Where deep currents rise towards the surface, they can release “fossil” carbon dioxide stored centuries ago. After 30 years of measurements, the ocean carbon community is realizing that tracking human-induced changes in the ocean is not as easy as they thought it would be. It wasn’t a mere matter of measuring changes in carbon concentrations in the ocean over time because the natural carbon cycle in the ocean turned out to be a lot more variable than they imagined. “We discovered that natural processes play such an important role that the signals they generate can be as large as or larger than the anthropogenic signal,” says Feely. “Now we are trying to address how these decadal changes affect the uptake of carbon. Once we account for these processes, we can remove them from the data set and calculate the anthropogenic carbon dioxide as the residual.” But to track the increasingly complicated carbon balance sheet, the ocean community needed models, mathematical simulations of the natural world. … Stratification might wind up having competing effects on the overall carbon cycle, with saturation slowing carbon dioxide uptake in surface waters, but also suppressing venting. “The link between the destruction of the ozone layer, the changing wind patterns, and the impact on the carbon cycle is the thing that makes Le Quéré’s paper unique,” says Feely. “It links back to man-made impacts on the climate.” The idea that the man-made ozone hole and global warming have changed the Southern Ocean carbon sink is “disturbing on the one hand, but extremely interesting also,” Scientists realized that to understand the ocean carbon cycle, they are going to have to look for the human fingerprint in ocean circulation and biology, not just in ocean chemistry. NASA Earth Observatory Water Encyclopedia Of the three places where carbon is stored—atmosphere, oceans, and land biosphere—approximately 93 percent of the CO 2 is found in the oceans. The atmosphere, at about 750 petagrams of carbon (a petagram [Pg] is 10 15 grams), has the smallest amount of carbon. Approximately 90 to 100 Pg of carbon moves back and forth between the atmosphere and the oceans, and between the atmosphere and the land biosphere. Although these exchange rates are large relative to the total amount of carbon stored in the atmosphere, the concentration of CO 2 was constant. All trees, nearly all plants from cold climates, and most agricultural crops respond to increasing atmospheric CO 2 levels by increasing the amount of CO 2 they take up for photosynthesis . The oceans contain about 50 times more CO 2 than the atmosphere and 19 times more than the land biosphere. CO 2 moves between the atmosphere and the ocean by molecular diffusion when there is a difference between CO 2 gas pressure (pCO 2 ) between the atmosphere and oceans. For example, when the atmospheric pCO 2 is higher than the surface ocean, CO 2 diffuses across the air-sea boundary into the sea water. The oceans are able to hold much more carbon than the atmosphere because most of the CO 2 that diffuses into the oceans reacts with the water to form carbonic acid and its dissociation products, bicarbonate and carbonate ions . The conversion of CO 2 gas into nongaseous forms such as carbonic acid and bicarbonate and carbonate ions effectively reduces the CO 2 gas pressure in the water, thereby allowing more diffusion from the atmosphere. The oceans are mixed much more slowly than the atmosphere, so there are large horizontal and vertical changes in CO 2 concentration. In general, tropical waters release CO 2 to the atmosphere, whereas high-latitude oceans take up CO 2 from the atmosphere. CO 2 is also about 10 percent higher in the deep ocean than at the surface. The two basic mechanisms that control the distribution of carbon in the oceans are referred to as the solubility pump and the biological pump. Solubility Pump. The solubility pump is driven by two principal factors. First, more than twice as much CO 2 can dissolve into cold polar waters than in the warm equatorial waters. As major ocean currents (e.g., the Gulf Stream) move waters from the tropics to the poles, they are cooled and can take up more CO 2 from the atmosphere. Second, the high latitude zones are also places where deep waters are formed. As the waters are cooled, they become denser and sink into the ocean’s interior, taking with them the CO 2 accumulated at the surface. Biological Pump. Another process that moves CO 2 away from the surface ocean is called the biological pump. Growth of marine plants (e.g., phytoplankton) takes CO 2 and other chemicals from sea water to make plant tissue. Microscopic marine animals, called zooplankton, eat the phytoplankton and provide the basis for the food web for all animal life in the sea. Because photosynthesis requires light, phytoplankton only grow in the nearsurface ocean, where sufficient light can penetrate. Although most of the CO 2 taken up by phytoplankton is recycled near the surface, a substantial fraction, perhaps 30 percent, sinks into the deeper waters before being converted back into CO 2 by marine bacteria. Only about 0.1 percent reaches the seafloor to be buried in the sediments. Scientists research the exchange of carbon dioxide between the atmosphere and ocean. This photograph shows the Ronald H. Brown, a research vessel of the National Oceanic and Atmospheric Administration, in the Equatorial Pacific Ocean during the GASEX II expedition in 2001. The floating instrument in the foreground measures a number of parameters associated with the transfer of CO2 across the air–sea interface. Scientists research the exchange of carbon dioxide between the atmosphere and ocean. This photograph shows the Ronald H. Brown, a research vessel of the National Oceanic and Atmospheric Administration, in the Equatorial Pacific Ocean during the GASEX II expedition in 2001. The floating instrument in the foreground measures a number of parameters associated with the transfer of CO 2 across the air–sea interface. The CO 2 that is recycled at depth is slowly carried large distances by currents to areas where the waters return to the surface (upwelling regions). When the waters regain contact with the atmosphere, the CO 2 originally taken up by the phytoplankton is returned to the atmosphere. This exchange process helps to control atmospheric CO 2 concentrations over decadal and longer time scales. n the 1980s, the oceans removed an estimated 2.0±0.6 Pg of anthropogenic CO 2 each year. Because humans are producing CO 2 at an everincreasing rate, the average ocean removal rate increased to 2.4±0.5 Pg of carbon each year in the 1990s. The uptake of anthropogenic CO 2 by the oceans is driven by the difference in gas pressure in the atmosphere and in the oceans and by the air–sea transfer velocity. Because the pCO 2 is increasing in the atmosphere, CO 2 moves into the ocean in an attempt to balance the oceanic and atmospheric gas pressures. The mechanisms that control the speed with which the CO 2 gas can move from the atmosphere to the oceans (air–sea transfer velocity) are not well understood today. Recent technological advances are helping scientists to better understand these mechanisms. The transfer velocity is related to the surface roughness of the ocean and the wind speed. The difference in pCO 2 is related to the amount of carbon that is converted from CO 2 gas to other nongaseous carbon species in the sea water, like bicarbonate and carbonate ions. This so-called “buffer capacity” is what allows the oceans to hold so much carbon. The relative concentrations of CO 2 (1%), bicarbonate ion (91%) and carbonate ion (8%) control the acidity (pH) of the oceans. Since CO 2 is an acid gas, the uptake of anthropogenic CO 2 uses up carbonate ions and lowers the oceanic pH. The carbonate ion concentration of surface sea water will decrease by an estimated 30 percent with a doubling of atmospheric CO 2 from preindustrial levels (280 to 560 ppm). As the carbonate ion concentration decreases, the buffer capacity of the ocean and its ability to take up CO 2 from the atmosphere is reduced. Over the long term (millennial timescales), the ocean has the potential to take up approximately 85 percent of the anthropogenic CO 2 that is released to the atmosphere. As long as atmospheric CO 2 concentrations continue to rise, the oceans will continue to take up CO 2 . However, this reaction is reversible. If atmospheric CO 2 were to decrease in the future, the oceans will start releasing the accumulated anthropogenic CO 2 back out into the atmosphere. The ultimate storage place for anthropogenic CO 2 must be reactions that bind the CO 2 in a manner that is not easily reversed. Dissolution of calcium carbonate in the oceans, for example, is a long-term storage place for CO 2 . As the oceans continue to take up anthropogenic CO 2 , it will penetrate deeper into the water column, lowering the pH and making the waters more corrosive to calcium carbonate. The problem is that carbonate dissolution typically occurs in the deep ocean, well removed from the anthropogenic CO 2 taken up in the surface waters. In portions of the North Atlantic and North Pacific Oceans, however, anthropogenic CO 2 may have already penetrated deep enough to influence the dissolution of calcium carbonate in the water column. Sediment Burial. Burial of plant and animal material into the sediments can also provide long-term storage of anthropogenic CO 2 . Interestingly, almost no phytoplankton seem to grow faster in higher CO 2 environments, unlike many land plants. This is because phytoplankton growth in the oceans is generally limited by the availability of light and chemicals other than CO 2 , principally nitrogen and phosphorus but also smaller amounts of iron, zinc, and other micronutrients. One proposed approach for enhancing carbon removal from the atmosphere is to enhance phytoplankton growth by fertilizing specific regions of the ocean with a relatively inexpensive biologically limiting chemical like iron. The hypothesis is that the resulting bloom of oceanic plants would remove CO 2 from the atmosphere then transport that carbon into the deep ocean or sediments, effectively removing it from the short-term budget. The effectiveness of the “iron hypothesis” is being tested with several research efforts attempting to scale up iron fertilization experiments. Other carbon sequestration approaches, including direct injection of liquefied CO 2 into the deep ocean, are also being examined. Further research is necessary to determine whether any of these techniques will be effective or economically feasible. Implementation of these approaches may depend, in large part, on policy decisions made at national and international levels. Water Encyclopedia NOAA PMEL Air-sea gas exchange is a physio-chemical process, primarily controlled by the air-sea difference in gas concentrations and the exchange coefficient, which determines how quickly a molecule of gas can move across the ocean-atmosphere boundary. It takes about one year to equilibrate CO2 in the surface ocean with atmospheric CO2, so it is not unusual to observe large air-sea differences in CO2 concentrations. Most of the differences are caused by variability in the oceans due to biology and ocean circulation. The oceans contain a very large reservoir of carbon that can be exchanged with the atmosphere because the CO2 reacts with water to form carbonic acid and its dissociation products. As atmospheric CO2 increases, the interaction with the surface ocean will change the chemistry of the seawater resulting in ocean acidification. Evidence suggests that the past and current ocean uptake of human-derived (anthropogenic) CO2 is primarily a physical response to rising atmospheric CO2 concentrations. Whenever the partial pressure of a gas is increased in the atmosphere over a body of water, the gas will diffuse into that water until the partial pressures across the air-water interface are equilibrated. However, because the global carbon cycle is intimately embedded in the physical climate system there exist several feedback loops between the two systems. For example, increasing CO2 modifies the climate which in turn impacts ocean circulation and therefore ocean CO2 uptake. Changes in marine ecosystems resulting from rising CO2 and/or changing climate can also result in changes in air-sea CO2 exchange. These feedbacks can change the role of the oceans in taking up atmospheric CO2 making it very difficult to predict how the ocean carbon cycle will operate in the future. NOAA PMEL National Geographic Warming is speeding up. The top part of the ocean is warming up about 24 percent faster than it did a few decades ago, and that rate is likely to increase in the future. National Geographic New Scientist As the world’s oceans warm, their massive stores of dissolved carbon dioxide may be quick to bubble back out into the atmosphere and amplify the greenhouse effect, according to a new study. The oceans capture around 30 per cent of human carbon dioxide emissions and hide it in their depths. This slows the march of global warming somewhat. But climate records from the end of the last ice age show that as temperatures climb, the trend reverses and the oceans emit CO2, which exacerbates warming. Previous studies have suggested that it takes between 400 and 1300 years for this to happen. But now the most precise analysis to date has whittled that figure down. We now think the delay is more like 200 years, possibly even less, New Scientist RealClimate The oceans are presently taking up about 2 Gton C per year, a significant dent in our emissions of 7 Gton C per year. This could slow in the future, as overturning becomes inhibited by stratification, as the buffer loses its capacity due to acidification. Eventually, the fluxes could reverse as with a decrease in CO2 solubility due to ocean warming. The situation today is complicated somewhat by a carbon spike transient. Atmospheric CO2 is rising so quickly that the terrestrial biosphere and the ocean carbon reservoirs find themselves far out of equilibrium. In attempting to keep up, the other reservoirs are taking up massive amounts of CO2. If emissions were to stop today, it would take a few centuries for the atmosphere to equilibrate, and it would contain something like 25% of our emitted CO2. RealClimate RealClimate The ocean has a tendency to take up more carbon as the CO2 concentration in the air rises, because of Henry’s Law, which states that in equilibrium, more in the air means more dissolved in the water. Stratification of the waters in the ocean, due to warming at the surface for example, tends to oppose CO2 invasion, by slowing the rate of replenishing surface waters by deep waters which haven’t taken up fossil fuel CO2 yet. The Southern Ocean is an important avenue of carbon invasion into the ocean, because the deep ocean outcrops here. Le Quere et al. [2007] diagnosed the uptake of CO2 into the Southern Ocean using atmospheric CO2 concentration data from a dozen or so sites in the Southern hemisphere. They find that the Southern Ocean has begun to release carbon since about 1990, in contrast to the model predictions that Southern Ocean carbon uptake should be increasing because of the Henry’s Law thing. We have to keep in mind that it is a tricky business to invert the atmospheric CO2 concentration to get sources and sinks. The history of this type of study tells us to wait for independent replication before taking this result to the bank. Le Quere et al propose that the sluggish Southern Ocean CO2 uptake could be due to a windier Southern Ocean. Here the literature gets complicated. The deep ocean contains high concentrations of CO2, the product of organic carbon degradation (think exhaling fish). The effect of the winds is to open a ventilation channel between the atmosphere and the deep ocean. Stratification, especially some decades from now, would tend to shut down this ventilation channel. The ventilation channel could let the deep ocean carbon out, or it could let atmospheric carbon in, especially in a few decades as the CO2 concentration gets ever higher (Henry’s Law again). I guess it’s fair to say that models are not decisive in their assessment about which of these two factors should be dominating at present. The atmospheric inversion method, once it passes the test of independent replication, would trump model predictions of what ought to be happening, in my book. A decrease in ocean uptake is more clearly documented in the North Atlantic by Schuster and Watson [2007]. They show surface ocean CO2 measurements from ships of opportunity from the period 1994-1995, and from 2002-2005. Their surface ocean chemistry data is expressed in terms of partial pressure of CO2 that would be in equilibrium with the water. If the pCO2 of the air is higher than the calculated pCO2 of the water for example, then CO2 will be dissolving into the water. The pCO2 of the air rose by about 15 microatmospheres in that decade. The strongest Henry’s Law scenario would be for the ocean pCO2 to remain constant through that time, so that the air/sea difference would increase by the 15 microatmospheres of the atmospheric rise. Instead what happened is that the pCO2 of the water rose twice as fast as the atmosphere did, by about 30 microatmospheres. The air-sea difference in pCO2 collapsed to zero in the high latitudes, meaning no CO2 uptake at all in a place where the CO2 uptake might be expected to be strongest. One factor that might be changing the pressure of CO2 coming from the sea surface might be the warming surface waters, because CO2 becomes less soluble as the temperature rises. But that ain’t it, as it turns out. The surface ocean is warming in their data, except for the two most tropical regions, but the amount of warming can only explain a small fraction of the CO2 pressure change. The culprit is not in hand exactly, but is described as some change in ocean circulation, caused maybe by stratification or by the North Atlantic Oscillation, bringing a different crop of water to the surface. At any event, the decrease in ocean uptake in the North Atlantic is convincing. Canadell et al [2007] claim to see the recent sluggishness of natural CO2 uptake in the rate of atmospheric CO2 rise relative to the total rate of CO2 release (from fossil fuels plus land use changes). They construct records of the atmospheric fraction of the total carbon release, and find that it has increased from 0.4 back in about 1960, to 0.45 today. Carbon cycle models (13 of them, from the SRES A2 scenario) also predict that the atmospheric fraction should increase, but not yet. For the time period from 1960 to 2000, the models predict that we would find the opposite of what is observed: a slight decrease in the atmospheric fraction, driven by increasing carbon uptake into the natural world. Positive feedbacks in the real-world carbon cycle seem to be kicking in faster than anticipated, Canadell et al conclude. There is no real new information in the Canadell et al [2007] analysis on whether the sinking sink is in the ocean or on land. They use an ocean model to do this bookkeeping, but we have just seen how hard it is to model or even understand some of the observed changes in ocean uptake. In addition to the changing ocean sink, drought and heat wave conditions may change the uptake of carbon on land. The infamously hot summer of 2003 in Europe for example cut the rate of photosynthesis by 50%, dumping as much carbon into the air as had been taken up by that same area for the four previous years [Ciais et al., 2005]. The warming at the end of the last ice age was prompted by changes in Earth’s orbit around the sun, but it was greatly amplified by the rising CO2 concentration in the atmosphere. The orbits pushed on ice sheets, which pushed on climate. The climate changes triggered a strong positive carbon cycle feedback which is, yes, still poorly understood. Now industrial activity is pushing on atmospheric CO2 directly. The question is when and how strongly the carbon cycle will push back. RealClimate 20.6.1 Air-Sea Flux Calculation Woolf Abstract The presence of vertical temperature and salinity gradients in the upper ocean and the occur- rence of variations in temperature and salinity on time scales from hours to many years complicate the calculation of the ﬂux of carbon dioxide (CO 2 ) across the sea surface. Temperature and salinity affect the interfacial concentration of aqueous CO 2 primarily through their effect on solubility with lesser effects related to saturated vapor pressure and the relationship between fugacity and partial pressure. The effects of temperature and salinity proﬁles in the water column and changes in the aqueous concentration act primarily through the partitioning of the carbonate system. Climatological calculations of ﬂux require atten- tion to variability in the upper ocean and to the limited validity of assuming ‘‘constant chemistry’’ in trans- forming measurements to climatological values. Contrary to some recent analysis, it is shown that the effect on CO 2 ﬂuxes of a cool skin on the sea surface is large and ubiquitous. An opposing effect on calculated ﬂuxes is related to the occurrence of warm layers near the surface; this effect can be locally large but will usually coincide with periods of low exchange. A salty skin and salinity anomalies in the upper ocean also affect CO 2 ﬂux calculations, though these haline effects are generally weaker than the thermal effects. Woolf Memo The signiﬁcance of precise temperatures can be readily understood from two facts. First, atmospheric and upper ocean CO 2 concentrations are almost in balance globally, with a net inﬂux into the contemporary ocean of only approximately 2% of the diffusive exchange. Second, the efﬂux and inﬂux depend on the fugacity or partial pressure of CO 2 (pCO 2 ) in the upper ocean and atmosphere, respectively, and the sensitivity of the fugacity in seawater is estimated at more than 4% per degree Kelvin temperature change. There appears to be a serious risk that mishandling temperature even slightly (i.e., biases of 0.1 K and less) can lead to substantial errors in calculated net ﬂux. Thermal Skin Effect The cool skin [e.g., Donlon et al., 1999, 2002] is the phenomenon that the top millimeter or so of the upper ocean (the ‘‘thermal skin’’) is generally slightly cooler than the water below (the ‘‘mixed layer’’). There have been several attempts to estimate the error in the net global CO2 uptake if the thermal skin effect is neglected. Various studies reported an increased uptake of up to one third of the uncorrected uptake; for example, Robertson and Watson [1992] reported a correction of 0.6 PgC/yr ), while Van Scoy et al. [1995] estimated 0.4 PgC/yr. There are a large number of thermal and haline effects that can potentially alter the air-sea ﬂux of carbon dioxide (and other gases). In this paper, we provide a careful and detailed treatment of the thermal effects and also brieﬂy discuss the haline effects. Generally, these analogous haline effects are smaller than the thermal effects, but worth including in a thorough calculation. We have deliberately omitted another connection between temperature and gas ﬂuxes: the coupling of heat and gas ﬂuxes through irreversible thermodynamics. In principle that coupling also affects CO 2 ﬂuxes, but the effect is negligible for all practical purposes. We also assume that the gas at the interface will be in perfect equilibrium with the concentration in the lower atmosphere. That assumption requires neglect of vertical gradients in the marine atmospheric boundary layer and the ‘‘kinetic layer’’ immediately above the sea surface. Some effects of aqueous carbon chemistry are included, but we have assumed that hydration and dehydra- tion rates are too low to signiﬁcantly alter the transfer velocity of CO 2 Woolf (2017) On the calculation of air-sea fluxes of CO2 in the presence of temperature and salinity gradients (pdf) 20.6.2 Fungus fast track carbon Gartwaite New research focused on interactions among microbes in water suggests fungal microparasites play a bigger than expected role in aquatic food webs and the global carbon cycle. New research shows a crucial piece has been missing from the conventional explanation for what happens between this first “fixing” of CO2 into phytoplankton and its eventual release to the atmosphere or descent to depths where it no longer contributes to global warming. The missing piece? Fungus. “Basically, carbon moves up the food chain in aquatic environments differently than we commonly think it does,” said Anne Dekas, an assistant professor of Earth system science at Stanford University. Dekas is the senior author of a paper published June 1 in Proceedings of the National Academy of Sciences that quantifies how much carbon goes into parasitic fungi that attack microalgae. Researchers until now have predicted that most carbon fixed into colonies of hard-shelled, single-celled algae known as diatoms then funnels directly into bacteria – or dissolves like tea in the surrounding water, where it’s largely taken up by other bacteria. Conventional thinking assumes carbon escapes from this microbial loop mainly through larger organisms that graze on the bacteria or diatoms, or through the CO2 that returns to the atmosphere as the microbes breathe. This journey is important in the context of climate change. “For carbon sequestration to occur, carbon from CO2 needs to go up the food chain into big enough pieces of biomass that it can sink down into the bottom of the ocean,” Dekas said. “That’s how it’s really removed from the atmosphere. If it just cycles for long periods in the surface of the ocean, it can be released back to the air as CO2.” It turns out fungus creates an underappreciated express lane for carbon, “shunting” as much as 20 percent of the carbon fixed by diatoms out of the microbial loop and into the fungal parasite. “Instead of going through this merry-go-round, where the carbon could eventually go back to the atmosphere, you have a more direct route to the higher levels in the food web,” Dekas said. Garthwaite (2021) Fungus creates a fast track for carbon 20.6.3 Ocean Carbon Sink Gruber Abstract The ocean has absorbed 25 ± 2% of the total anthropogenic CO2 emissions from the early 1960s to the late 2010s, with rates more than tripling over this period and with a mean uptake of –2.7 ± 0.3 Pg C year–1 for the period 1990 through 2019. This growth of the ocean sink matches expectations based on the increase in atmospheric CO2, but research has shown that the sink is more variable than long assumed. The sink stagnated during the 1990s with rates hovering around –2 Pg C year–1, but strengthened again after approximately 2000, taking up around –3 Pg C year–1 for 2010–2019. The most conspicuous changes in uptake occurred in the high latitudes, especially the Southern Ocean. These variations are caused by changes in weather and climate, but a volcanic eruption-induced reduction in the atmospheric CO2 growth rate and the associated global cooling contributed as well Understanding the variability of the ocean carbon sink is crucial for policy making and projecting its future evolution, especially in the context of the UN Framework Convention on Climate Change stocktaking activities and the deployment of CO2 removal methods. This goal will require a global-level effort to sustain and expand the current observational networks and to better integrate these observations with models. Gruber Key Points The long-term trend in the ocean carbon sink since the early 1960s was primarily driven by the increasing uptake of anthropogenic CO2. Although the ocean is expected to have lost a few petagrams of natural CO2 to the atmosphere in response to ocean warming, this loss cannot be quantiied conclusively with observations. The oceanic uptake of anthropogenic CO2 scaled proportionally with the increase in atmospheric CO2 between the early 1960s and late 2010s, as expected given the quasi-exponential growth of atmospheric CO2 during this period. The average ocean uptake rate of –2.7±0.3PgCyear–1 for the period 1990 through 2019 is commensurate with asensitivity β of 1.4±0.1PgC per ppm atmospheric CO2, suggesting a trend in the uptake of –0.4±0.1PgCyear–1 per decade. The annual meanocean carbon sink varies by about ±20% around this trend, primarily caused by changes in the sources and sinks of natural CO2, with a lesser role for variations in atmospheric CO2 growth rates impacting the uptake of anthropogenic CO2. The net oceanic uptake rate of CO2 will likely decrease in the future owing to several converging trends: reduced emissions of CO2 leading to reduced atmospheric CO2 growth rates in response to climate policy; reduced storage capacity owing to continuing ocean acidiication; and enhanced outgassing of natural CO2 owing to ocean warming and changes in ocean circulation and biology. Gruber Summary The strength of the ocean carbon sink has tripled from the 1960s until the present. Thus, the ocean has maintained its key role as a sink for the CO2 emitted into the atmosphere as a consequence of human activities, removing about 25 ± 2% of the total emissions over six decades. The strengthening of the ocean sink has been largely driven by the increas-ing uptake of anthropogenic CO2 in response to the rise in atmospheric CO2, leading to a strong proportionality between the two. By contrast, the contribution from changes in the natural carbon cycle has been small so far, consistent with the assumption that the ocean circula-tion and biological pump was overall in steady state. However, new insights and observations publishedin the past decade challenge this assumption, especially on shorter timescales, suggesting an ocean that is more variable than previously recognized. New evidence also sug-gests over the past three decades a loss of natural CO2 to the atmosphere due to ocean warming and changes in ocean circulation. If confirmed, such a loss suggests an ocean carbon sink that is rather sensitive to climate change. An ocean sink that is more sensitive to climate change than currently assumed in coupled carbon-climate models52 would imply that the ocean will take up less CO2 from the atmosphere in the future than anticipated. This would leave a larger fraction of the emissions in the atmosphere, causing additional global warming and climate change. In other words, the ocean carbon-climate feedback could be more positive than suggested by current coupled carbon-climate models. Moreover, the finding of the ocean sink potentially being more sensitive to changes in atmospheric CO2 growth rates than previously recognized implies a stronger than anticipated decline of the ocean carbon sink in ambitious mitigation scenarios. The implications are large and far-reaching. Any reduction in ocean carbon uptake compared with current assumptions would require even stronger investments into decarbonization strategies, making the achievement of specific global warming targets harder. It also reduces the efficacy of the negative emission approaches that aim to curb climate change by removing CO2 from the atmosphere using land-based139,140 or ocean-based141 approaches. Gruber (2023) Trends and variability in the ocean carbon sink Mastodon Link DeVries Abstract This contribution to the RECCAP2 (REgional Carbon Cycle Assessment and Processes) assessment analyzes the processes that determine the global ocean carbon sink, and its trends and variability over the period 1985–2018, using a combination of models and observation-based products. The mean sea-air CO2 flux from 1985 to 2018 is −1.6 ± 0.2 PgC yr−1 based on an ensemble of reconstructions of the history of sea surface pCO2 (pCO2 products). Models indicate that the dominant component of this flux is the net oceanic uptake of anthropogenic CO2, which is estimated at −2.1 ± 0.3 PgC yr−1 by an ensemble of ocean biogeochemical models, and −2.4 ± 0.1 PgC yr−1 by two ocean circulation inverse models. The ocean also degasses about 0.65 ± 0.3 PgC yr−1 of terrestrially derived CO2, but this process is not fully resolved by any of the models used here. From 2001 to 2018, the pCO2 products reconstruct a trend in the ocean carbon sink of −0.61 ± 0.12 PgC yr−1 decade−1, while biogeochemical models and inverse models diagnose an anthropogenic CO2-driven trend of −0.34 ± 0.06 and −0.41 ± 0.03 PgC yr−1 decade−1, respectively. This implies a climate-forced acceleration of the ocean carbon sink in recent decades, but there are still large uncertainties on the magnitude and cause of this trend. The interannual to decadal variability of the global carbon sink is mainly driven by climate variability, with the climate-driven variability exceeding the CO2-forced variability by 2–3 times. These results suggest that anthropogenic CO2 dominates the ocean CO2 sink, while climate-driven variability is potentially large but highly uncertain and not consistently captured across different methods. Plain Language Summary The second REgional Carbon Cycle Assessment and Processes effort, or RECCAP2, provides a comprehensive assessment of global and regional greenhouse gas budgets. This paper focuses on the ocean carbon sink, and investigates the processes that control its magnitude, trends and variability. Observation-based techniques estimate that the net transfer of CO2 from the atmosphere to the ocean, averaged over 1985–2018, is 1.6 billion tonnes of carbon per year, and that oceanic CO2 uptake is increasing by 0.61 billion tonnes of carbon per year each decade. Models say that most of this CO2 entering the ocean, and its increase over time, is driven by anthropogenic CO2 emissions, which causes the ocean to take up 2.1–2.4 billion tonnes of carbon per year. There are some hints that climate change might be accelerating ocean carbon uptake, but the errors in our estimates are too large to know for sure right now. Our methods and observations will have to be improved in order to better detect the impact of climate change on the ocean carbon sink. X thread Observation-based techniques estimate that the net transfer of carbon dioxide, CO2, from the atmosphere to the ocean, averaged over 1985–2018, is 1.6 billion tonnes of carbon per year, and that oceanic CO2 uptake is increasing by 0.61 billion tonnes of carbon per year each decade. Models say that most of this CO2 entering the ocean, and its increase over time, is driven by anthropogenic CO 2 emissions, which causes the ocean to take up 2.1–2.4 billion tonnes of carbon per year. There are some hints that climate change might be accelerating ocean carbon uptake, but the errors in our estimates are too large to know for sure right now. DeVries (2023) Magnitude, Trends, and Variability of the Global Ocean Carbon Sink From 1985 to 2018 20.7 Sea Level Rise Spratt The paleoclimate record tells us that, in the long run, each one-degree of warming brings 10-20 meters (32- 66 feet) of sea level rise. Hunziker (2023) The Truth About IPCC Reports Hausfather Sea level rise (SLR) is one of the most severe impacts of climate change, with rising waters threatening to inundate small-island nations and coastal regions by the end of the century. At the same time, SLR is one of the impacts with the largest uncertainties, with different studies projecting widely different ranges over the 21st century. The Earth’s oceans have already risen by around 0.2m since the late 1800s, with the rate of SLR accelerating in recent decades. In its 2013 fifth assessment report (AR5), the Intergovernmental Panel on Climate Change (IPCC) estimated that SLR was “unlikely” to exceed 1m this century, even if emissions were very high. However, a number of studies published in the years since then suggest that the worst-case projections for SLR could be much higher – up to 2m or more this century. With this week’s release of the IPCC Special Report Ocean and Cryosphere in a Changing Climate (SROCC), it is useful to take a look at the current understanding of how sea level has changed in the past and may change in the future. In this explainer, Carbon Brief examines estimates of historical sea level rise and the evidence that rates are accelerating. It explores the drivers of historical and future sea level rise, including thermal expansion of water, melting glaciers and melting ice sheets. Finally, it compares the worst-case projections from the IPCC with other studies published before and after AR5 was released. Reconstructing past changes in global sea levels is far from a simple task. While high-quality satellite measurements with global coverage are available since the early 1990s, prior to that researchers have to rely on tide gauges scattered around the world. These tide gauges primarily cover coastal regions, leaving it up to researchers to figure out how best to fill the gaps. Tide gauges are also subject to factors that can complicate the interpretation of local sea level changes, namely subsidence (sinking land) or isostatic rebound (rising land due to melting glaciers). Sea levels have risen by between 0.18 and 0.2m (180 to 200mm) since 1900. Rates of change in global sea levels are shown as longer-term 20-year averages because individual years are sensitive to global surface temperatures; El Niño years where temperatures are a bit warmer tend to have more rapid SLR than cooler La Niña years. The current rate of sea level rise – as measured by accurate satellite altimeters – is around 50% faster than was experienced in the 1940s. Melting glaciers can affect the shape and gravitational field of the Earth, causing regional fluctuations in sea levels. Sediment compaction, plate tectonics and localised subsidence can all play a role in specific regions. Figure: Global mean sea level from 1992-2014 based on data collected from the TOPEX/Poseidon, Jason-1 and Jason-2 satellite altimeters. Figure from the NASA Scientific Visualization Studio. One of the major drivers of the SLR the world has experienced in recent decades is not from melting glaciers or ice sheets. Rather, it is driven by the thermal expansion of water. As the ocean warms, seawater becomes less dense and expands, raising sea levels. The rapid increase in ocean heat content has led to around 19mm of sea level rise just from thermal expansion between 1993 and 2010, around a third of the total increase of 54mm. While glacier melt and thermal expansion were responsible for the majority of historical SLR, this has been changing in recent years. There are now larger contributions to SLR coming from ice sheet melt and changes in land water storage – driven in part by groundwater depletion for irrigation. Since AR5 in 2013, a large number of new studies on future SLR have been published. Many of these have shown substantially higher worst-case SLR estimates by the end of the 21st century than those published in the AR5 – largely due to a reassessment of the potential losses from Antarctic and Greenland ice sheets. Since the publication of the IPCC report in 2013, we’ve seen the range of future SLR projections expand significantly, with some studies suggesting the possibility of up to 2.5m of global mean SLR by 2100. There are a number of factors driving the uncertainty in future SLR amounts and rates, but the behaviour of the Antarctic and Greenland ice sheets in a warming climate is, perhaps, one of the largest contributors to this uncertainty. In particular, as new studies have come out suggesting the possibility of larger contributions to sea level rise from the Antarctic ice sheet than previously thought, we’ve seen the upper bound of future SLR projections climb upwards. One study, published in Nature in 2016, suggested that a previously unconsidered process known as “marine ice-cliff instability” (MICI) meant the glaciers in the Antarctic were more unstable than scientists had thought. The paper concluded that “Antarctica has the potential to contribute more than a metre of SLR by 2100 and more than 15m by 2500” if future emissions are very high. The IPCC reports have tended to err on the side of providing intentionally cautious and conservative estimates of SLR, rather than focusing on less likely, extreme possibilities that would be of high consequence, should they occur. The IPCC Special Report Ocean and Cryosphere in a Changing Climate (SROCC) considered potential 21st century SLR estimates higher than those in the IPCC AR5. Figure: Projected change in global average sea level during the 21st century (metres), relative to the average for 1986-2005. Each panel shows projections from the current report (SROCC, coloured line and area) relative to the projections made in AR5 (black line and grey area). Left: The low emissions RCP2.6 scenario. Centre: The medium emissions RCP4.5 pathway. Right: The very high emissions RCP8.5 scenario. Source: IPCC SROCC figure 4.9. Even these new estimates may end up being conservative. For example, a recent study by Prof Jonathan Bamber at the University of Bristol and colleagues brought together a group of 22 experts to assess their views of the likelihood of different future SLR scenarios. They found that a global SLR exceeding 2m by 2100 “lies within the 90% uncertainty bounds for a high-emission scenario”. This is more than twice the upper value found in the IPCC AR5. Hausfather 2021 (Carbonbrief Explainer) IPCC In its most recent assessment, the Intergovernmental Panel on Climate Change said the sea level was unlikely to rise beyond 1.1 metre (3.6ft) by 2100. But climate researchers from the University of Copenhagen’s Niels Bohr Institute believe levels could rise as much as 1.35 metres by 2100, under a worst-case warming scenario. “The models used to base predictions of sea level rise on presently are not sensitive enough,” he said. “To put it plainly, they don’t hit the mark when we compare them to the rate of sea level rise we see when comparing future scenarios with observations going back in time.” Higher Sea Level Rise (Guardian) 20.7.1 Uncertainty Gavin Why is future sea level rise still so uncertain? Here’s a list of factors that will influence future regional sea level (in rough order of importance): ice mass loss from West Antarctica ice mass loss from Greenland ocean thermal expansion mountain glacier melt gravitational, rotational and deformational (GRD) effects changes in ocean circulation steric (freshwater/salinity) effects groundwater extraction reservoir construction and filling changes in atmospheric pressure and winds And on top of that, the risks of coastal flooding also depend on: tectonic/isostatic land motion local subsidence local hydrology storm surges tides If that wasn’t bad enough, it doesn’t even get into why some of the bigger terms here are so difficult to constrain. Note that the factors listed above involve the whole Earth system: the oceans, the cryosphere, the atmosphere, the solid earth and lithosphere, and a full range of scales, from the city block and shoreline, to ice dynamics that change over kilometers, to GRD footprints, to the whole global ocean. While each of these elements has a devoted scientific community, sea level rise cuts across all the disciplines. And similarly, while each of these elements has a specialized modeling capability, there is no single model that encompasses all of this (not even close – as yet). What this means is that estimates of future sea level rise are mixes of information from multiple sources, tied together in more or less sophisticated frameworks (this is the approach in the IPCC SCROCC report and the upcoming AR6) that attempt to build a full uncertainty range from all the disparate sources of information (coupled ocean-atmosphere models, hydrology models, ice sheet models, solid earth models etc.). To reiterate, there is no ‘climate model’ prediction of global sea level rise, though the climate models we often discuss here (the CMIP-class of models), do provide some of the inputs. This means that links and feedbacks between these different elements are not always coherent – e.g. the estimates of groundwater depletion (used for irrigation) or glacier melt might not impact the soils or the freshwater budget of the downstream rivers and ocean. RealClimate 20.7.2 TSLS Transient Sea Level Sensitivity By analyzing the mean rate of change in sea level (not sea level itself), we identify a nearly linear rela- tionship with global mean surface temperature (and there- fore accumulated carbon dioxide emissions) both in model projections and in observations on a century scale. This mo- tivates us to define the “transient sea level sensitivity” as the increase in the sea level rate associated with a given warm- ing in units of meters per century per kelvin. We find that future projections estimated on climate model responses fall below extrapolation based on recent observational records. This comparison suggests that the likely upper level of sea level projections in recent IPCC reports would be too low. Sea level projections as assessed in AR5 and SROCC systematically fall below what would be expected from extrapolating observations to warmer conditions, as well as below the expert elicitation. Error bars show estimated likely ranges (17 %–83 %). Grindsted (2021) Transient Sensitivity of Sea Level Rise (Ocean Science) (pdf) Verbeek From 1.1 meters to 1.35 In the first week of February this year, we learned that the rise in the sea level is likely to be faster and higher than previously thought, according to researchers who found that recent predictions are inconsistent with historical data. Until this research from the Niels Bohr Institute in Copenhagen, we relied on the (then) latest assessment of the IPCC that predicted that the sea level was unlikely to rise beyond 1.1 meters (that is 3.6 feet) by the end of this century. But in week five of this year, the latest research said that the worst-case warming scenario could raise sea levels to 1.35 meters by 2100. This finding was published in the Journal of Ocean Science by scientists who had used historical data on the sea-level rise to validate various models relied on by the IPCC to make its assessment. They found that the IPCC models were not sensitive enough and found a discrepancy of about 25cm; they added in their report that some experts assign a substantially higher likelihood of such a 1.35-meter future. From 1.35 meters to 2 meters Let’s move fast forward through the most recent history and move from week five of this year to week 32 when the IPCC released the first part of its Sixth Assessment Report. It summarizes the conclusions of 234 international scientists on the current climate research on how the Earth is changing as temperatures rise and what those changes will mean for the future. They conclude, for instance, that the evidence for accelerating ice sheet loss has become more evident; this factor is primarily responsible for the increase in the rate of sea-level rise since the 1990s. The other aspect is the expansion of ocean water when it gets warmer. A new finding is that under the most extreme IPCC emissions scenario, the scientists could not rule out rapid ice sheet loss leading to sea level rise approaching 2 meters (7 feet) by the end of this century. So in just the first eight months of this year, the extreme scenario for sea-level rise went up from 1.1 meters to 2 meters. A level above which it gets incredibly challenging to keep our feet dry in the Netherlands. Due to deep uncertainty in ice sheet processes, the IPCC report could not rule out a seal level of 5 m by 2150 under a very high greenhouse gas emissions scenario. Verbeek (2021) This year, the predictions for maximum sea-level rise nearly doubled 20.7.3 High-End Seal Level Rise Estimate Wal Abstract Sea level rise (SLR) is a long-lasting consequence of climate change because global anthropogenic warming takes centuries to millennia to equilibrate for the deep ocean and ice sheets. SLR projections based on climate models support policy analysis, risk assessment and adaptation planning today, despite their large uncertainties. The central range of the SLR distribution is estimated by process-based models. However, risk-averse practitioners often require information about plausible future conditions that lie in the tails of the SLR distribution, which are poorly defined by existing models. Here, a community effort combining scientists and practitioners builds on a framework of discussing physical evidence to quantify high- end global SLR for practitioners. The approach is complementary to the IPCC AR6 report and provides further physically plausible high-end scenarios. High-end estimates for the different SLR components are developed for two climate scenarios at two timescales. For global warming of +2°C in 2100 (RCP2.6/SSP1-2.6) relative to pre-industrial values our high-end global SLR estimates are up to 0.9 m in 2100 and 2.5 m in 2300. Similarly, for a (RCP8.5/SSP5-8.5), we estimate up to 1.6 m in 2100 and up to 10.4 m in 2300. The large and growing differences between the scenarios beyond 2100 emphasize the long-term benefits of mitigation. However, even a modest 2°C warming may cause multi-meter SLR on centennial time scales with profound consequences for coastal areas. Earlier high-end assessments focused on instability mechanisms in Antarctica, while here we emphasize the importance of the timing of ice shelf collapse around Antarctica. This is highly uncertain due to low understanding of the driving processes. Hence both process understanding and emission scenario control high-end SLR. Wal Memo Continuing gradual warming and expansion of ocean water (i.e., the steric effect), mass loss from glaciers and polar ice sheets continue long after emissions have slowed or stopped. Climate models simulating physical processes are used to reconstruct historical sea level change (excluding the ice sheet contribution), and consequently provide a method to project SLR given specific future anthropogenic CO2 emissions and associated warming of the Earth system. Such a process-based approach provides robust estimates of changes in the central part of the SLR distribution. Estimating the tails of the distribution, which includes the ice sheet contribution remains contentious as not all the relevant processes are sufficiently understood or represented in the models, leading to variations between projections and multiple views of how the upper tail of the SLR distribution will evolve in future. High-end SLR projections provide information about the upper tail of the probability distribution of SLR, and are especially important for assessing long-term risks and adaptation responses - defining a plausible “worst case” SLR to consider in an adaptation plan. High-end estimates provide insight on potential adaptation limits, tipping points and thresholds, and t he level of climate mitigation required to keep SLR adaptation manageable. High-end SLR information does not replace the quantification of the more likely central parts of the SLR distribution. A default adaptation plan may follow the median projection, with high-end estimates used to inform the development of contingency options that can be applied in the case that high-end SLR manifests. Such a planning approach is known as “adaptive planning” or “dynamic adaptive planning” in the literature - when there are long lead times for action and long operational lives, such as for storm surge barriers or nuclear power stations, or where there is significant path-dependency for decisions. We use expert judgment based on physical reasoning to arrive at estimates - (which cannot be constrained by deterministic modeling) - providing a transparent attribution of cause and effect. Practitioner needs depend less on precise estimates of likelihood and more on evidence that is sufficiently credible, salient, and legitimate to support adaptation planning, including financing. (“Salient” is used here in the context of relevance to practical needs.) Projections supported by multiple lines of evidence and eliciting broader confidence from the scientific community are of greater value as compared to projections further along the tail that feature fewer lines of evidence, and hence have lower confidence. Risk-averse practitioners need to consider low likelihood, high consequence SLR futures that poses challenges to adaptation. Practitioners may misuse the results, as they will expect/assume that IPCC SLR scenarios cover all major uncertainties (while they only cover central estimates not tails). For longer time scales and higher temperature scenarios, the Antarctic ice sheet contribution dominates the uncertainty in SLR. Assuming perfect correlation between all contributions, the total global high-end SLR estimate in 2100 amounts to 0.86 and 1.55 m for +2°C and +5°C, respectively. Focusing on 2300, these numbers increase considerably to 2.5 and 10.4 m, for +2°C and +8°C–10°C, respectively. Alternatively, assuming total independence of contributions, the high-end rise is 0.72 and 1.27 m for 2100 and 2.2 and 8.6 m in 2300, for +2°C and +8°C–10°C, respectively. A GMSL of 2 m in 2100 cannot be excluded. In 2300, the contribution of the Antarctic ice sheet is poorly constrained, so the high-end estimate is considerably higher than most previous estimates. The large uncertainties in projecting sea levels over multiple centuries which arises from: (a) the poorly constrained timing of the collapse of major ice shelves around Antarctica, and (b) the limited understanding of ice-dynamical and subglacial processes. An SLR of 10 m by 2300 would be extremely challenging and costly, suggesting the need for a near-universal retreat from the present coastline including the most developed and valuable areas, or alternatively, protection/advance on a scale that is hard to envisage, even where artificial protection is the norm today. The Antarctic contribution is likely to be controlled by the timing of the loss of major ice shelves around Antarctica. Improved use of climate models including a dynamical ice sheet component will fill knowl- edge gaps with respect to the quantification of feedbacks which are not yet included in the modeling frameworks, and an improved understanding of correlations between different components of the climate system that contribute to global SLR. In addition, growing observational time series will also constrain the physics of the slow processes controlling ice shelf and ice sheet evolution. A strong focus on the timing of thinning and breakup of the Antarctic ice shelves is a critical aspect. At the same time, we also acknowledge that most studies fail to convincingly address the paleo sea level record. Models that include MICI (Marine Ice Cliff Instability) in Antarctica, but limit calving rates to those observed on Greenland could be too conservative Uncertainties exist for basal processes controlling the rate of mass loss once buttressing ice shelves are lost, with a large simulated range in SLR from Antarctica in response to strong imposed forcing. The timing when Antarctic ice shelves might be lost remains a key unknown. Break-up of ice shelves has been observed in response to processes triggered by ocean warming, processes which are not yet well quantified and that are omitted from all major existing models. Most models are unable to capture the magnitude of SLR in previous warm periods in Earth history, suggesting that there are either processes missing or that the importance of the processes that are included are underestimated. Antarctica lost ice during these warm periods, but we do not know understand why. Wal (2023) A High-End Estimate of Sea Level Rise for Practitioners Meijers Our inability to confidently predict between an extremely challenging two metres and a civilisation-ending 10 metres of sea level rise is an exemplar of the problem facing Antarctic and Southern Ocean researchers. Without more data and more research, we cannot confidently say whether the Southern Ocean will continue to sweep our warming and CO2 emissions “under the carpet” in the deep ocean, whether we are severely underestimating the scale and speed of sea level rise, or how and when melt may influence the global ocean circulation, gradually or suddenly via a tipping point. Meijers (2023) Is the climate crisis finally catching up with Antarctica? 20.8 AMOC - Gulf Stream Weakest Gulf Stream in Millenium The Atlantic Meridional Overturning Circulation (AMOC)—one of Earth’s major ocean circulation systems—redistributes heat on our planet and has a major impact on climate. Here, we compare a variety of published proxy records to reconstruct the evolution of the AMOC since about ad 400. A fairly consistent picture of the AMOC emerges: after a long and relatively stable period, there was an initial weakening starting in the nineteenth century, followed by a second, more rapid, decline in the mid-twentieth century, leading to the weakest state of the AMOC occurring in recent decades. Caesar (2021) AMOC Millenium Weakest (Nature Geoscience) [paywall!] Rahmstorf - Twitter Thread The Guardian The Guardian (Commentary) Gulf Stream Collapse Guardian Climate scientists have detected warning signs of the collapse of the Gulf Stream, one of the planet’s main potential tipping points. The research found “an almost complete loss of stability over the last century” of the currents that researchers call the Atlantic meridional overturning circulation (AMOC). The currents are already at their slowest point in at least 1,600 years, but the new analysis shows they may be nearing a shutdown. Figure: North Atlantic Circulation. Blue - Cold Deep Water, Red - Warm Surface Water Guardian Thornally Abstract The Atlantic meridional overturning circulation (AMOC) is a system of ocean currents that has an essential role in Earth’s climate, redistributing heat and influencing the carbon cycle. The AMOC has been shown to be weakening in recent years; this decline may reflect decadal-scale variability in convection in the Labrador Sea, but short observational datasets preclude a longer-term perspective on the modern state and variability of Labrador Sea convection and the AMOC1. Here we provide several lines of palaeo-oceanographic evidence that Labrador Sea deep convection and the AMOC have been anomalously weak over the past 150 years or so (since the end of the Little Ice Age, LIA, approximately ad 1850) compared with the preceding 1,500 years. Our palaeoclimate reconstructions indicate that the transition occurred either as a predominantly abrupt shift towards the end of the LIA, or as a more gradual, continued decline over the past 150 years; this ambiguity probably arises from non-AMOC influences on the various proxies or from the different sensitivities of these proxies to individual components of the AMOC. We suggest that enhanced freshwater fluxes from the Arctic and Nordic seas towards the end of the LIA—sourced from melting glaciers and thickened sea ice that developed earlier in the LIA—weakened Labrador Sea convection and the AMOC. The lack of a subsequent recovery may have resulted from hysteresis or from twentieth-century melting of the Greenland Ice Sheet. Our results suggest that recent decadal variability in Labrador Sea convection and the AMOC has occurred during an atypical, weak background state. Future work should aim to constrain the roles of internal climate variability and early anthropogenic forcing in the AMOC weakening described here. Thornally (2018) Anomalously weak Labrador Sea convection and Atlantic overturning during the past 150 years (PayWall) Caesar Abstract The Atlantic meridional overturning circulation (AMOC)—a system of ocean currents in the North Atlantic—has a major impact on climate, yet its evolution during the industrial era is poorly known owing to a lack of direct current measurements. Here we provide evidence for a weakening of the AMOC by about 3 ± 1 sverdrups (around 15 per cent) since the mid-twentieth century. This weakening is revealed by a characteristic spatial and seasonal sea-surface temperature ‘fingerprint’—consisting of a pattern of cooling in the subpolar Atlantic Ocean and warming in the Gulf Stream region—and is calibrated through an ensemble of model simulations from the CMIP5 project. We find this fingerprint both in a high-resolution climate model in response to increasing atmospheric carbon dioxide concentrations, and in the temperature trends observed since the late nineteenth century. The pattern can be explained by a slowdown in the AMOC and reduced northward heat transport, as well as an associated northward shift of the Gulf Stream. Comparisons with recent direct measurements from the RAPID project and several other studies provide a consistent depiction of record-low AMOC values in recent years. Caesar (2018) Observed fingerprint of a weakening Atlantic Ocean overturning circulation (PayWall) SharedIt 20.8.1 The Rise and Fall of AMOC The AMO is simply an artifact of studies that misinterpret the time-varying pattern of human-caused climate change as a low-frequency oscillation At times I feel like I created a monster when I gave a name to this putative climate oscillation in 2000. The concept of the AMO has since been misapplied and misrepresented to explain away just about every climate trend under the sun, often based on flawed statistical methods that don’t properly distinguish a true climate oscillation from a time-varying trend: If you assume that all trends are a simple linear ramp, and call everything left-over an “oscillation”, then the simple fact that global warming flattened out from the 1950s through the 1970s driven by the ramp-up in cooling sulphate aerosol pollution masquerades as an apparent “oscillation” on top of a simple linear trend. We’ve published a number of articles over the years (see e.g. here, here, here, here, here, and here) demonstrating that studies that use such an approach to define the AMO end up mis-attributing to a natural “oscillation” what is actually human-caused climate change. Such analyses have been used by some to dismiss, among other things, the impact climate change is having on increasingly active and destructive Atlantic hurricane seasons, attributing the increase in recent decades to a supposed upturn in the AMO. RealClimate 20.8.2 Rethinking AMOC Chafik A weakened AMOC may have played a role in causing almost 600 years’ worth of frigid winters in Europe and North America. This period, called the Little Ice Age, lasted roughly from 1300 until 1870 and came on the heels of the Medieval Warm Period (circa 950–1250), when temperatures in the Northern Hemisphere were unusually warm. Figure: This simplified view (top) shows the surface flows (red arrows) and deep return flows (blue arrows) that make up the large-scale ocean circulation in the North Atlantic. Color bands on the ocean surface indicate average sea surface temperatures from 1900 to 2019 (data are from the Hadley Centre) and highlight the northward extent of warm waters to higher latitudes. The longitude-depth temperature distribution of the ocean (bottom; data are from the World Ocean Atlas 2018) across the Greenland-Scotland Ridge (GSR, white transect line in the top panel) is also shown. The exchange of waters across the GSR is driven by the rapid loss of heat to the atmosphere over the Nordic Seas. This heat loss causes the waters to sink and build a huge reservoir of cold, dense water that spills back into the deep North Atlantic across the GSR, completing the overturning process. Nearly half of the AMOC’s poleward flow of warm, salty waters enters the Nordic Seas—comprising the Greenland, Iceland, and Norwegian Seas. Here the water cools and pools north of the undersea Greenland-Scotland Ridge (GSR). A host of important questions remains about the dynamics of the ocean near the GSR and the effects of these dynamics on regulating climate. The AMOC has two pathways of overturning circulation. One is open ocean convection in the Irminger and Labrador Seas that produces the upper layer of North Atlantic Deep Water (NADW). The second involves progressive cooling of warm, salty water from the Atlantic in the Nordic Seas. This cooling results in dense water spilling over the GSR back into the North Atlantic—mainly through two passages, the Denmark Strait between Greenland and Iceland and the Faroe Bank Channel south of the Faroes—and forming a lower layer of NADW. Both regions depend upon heat loss to produce water of greater density, but it appears that huge heat losses from the Nordic Seas and the concomitant production and pooling of very dense water behind the GSR are fundamental to maintaining a mild climate in northern Europe. This heat loss produces a healthy supply of NADW that spills back into the global abyss and enables warm, salty water to feed the Nordic Seas. Evidence of strong variability in Nordic Seas inflow on multidecadal timescales. The volume of and heat transported in this poleward flow, as measured at the GSR, are strongly coupled to the Atlantic multidecadal variability (AMV), which describes natural patterns of sea surface temperature variability in the North Atlantic that influence climate globally The AMV affects Nordic Seas inflow because deep convection in the northeast Atlantic translates the surface temperature variations down into the upper layers of the ocean, and these variations shape the ocean’s dynamic height field. The inflow of warm water to the Nordic Seas has been quite stable over the past century since the start of modern oceanography. Nordic Seas overturning circulation has been stable over the past 100 years. This stability is surprising given the extraordinary warming presently underway in the Nordic Seas and Arctic Ocean. The continued stability of this vital ocean circulation system is not guaranteed in the future. It is also unclear how future change may manifest or which early-warning indicators should be relied upon to forecast change. The recent discovery of an unknown route by which cold water courses its way through the Norwegian Sea. We identified that this new route directs cold deep flows north of the Faroe Islands to the Norwegian slope before turning them south through the Faroe-Shetland Channel and into the deep North Atlantic. Which route water takes north of the GSR and how much is funneled each way depend on the prevailing winds. Under weak westerly wind conditions in the Nordic Seas, the densest water that feeds the Faroe Bank Channel comes primarily from north of Iceland. During strong westerly wind conditions, however, more water seems to originate from along the Jan Mayen Ridge, which is located farther north of Iceland and more in the middle of the Nordic Seas. This wind dependence is curious, considering the strong control that bathymetry can exert on the circulation. Deep rapid flow, or deep jet, called the Faroe-Shetland Channel Jet. Remarkably, this jet flows south along the eastern slope of the channel rather than along the western side as has long been assumed. The deep jet is found to be the main current branch in terms of transport that delivers the densest water to the North Atlantic Ocean via the Faroe Bank Channel. This surprising finding countered past observations and thinking. We do not yet have a firm grasp of the deep circulation of the Nordic Seas and how it varies over time. All available observational evidence so far indicates that there is no long-term trend in the Nordic Seas meridional overturning circulation to date. The degree to which fresh water from the Arctic and Greenland Sea can mix with and dilute warm, saline water from the Atlantic. Such dilution could suppress deep temperature- and density-driven convection, thus weakening or shutting down the overturning in the Nordic Seas and, by extension, the deepest component of the AMOC. However, most scientists no longer think such a shutdown scenario is likely because observations to date indicate that Arctic and Greenland waters tend to remain trapped around and south of Greenland rather than mixing and diluting the Atlantic water flowing north in the Nordic Seas Nonetheless, there is broad agreement that the climatic consequences of a potential shutdown of this vital ocean circulation are so enormous that they obligate us to improve our understanding of the Nordic Seas. Chafik (2021) Rethinking Oceanic Overturning in Nordic Seas Stefan (Referring to Caesar (above)) The Atlantic overturning circulation (sometimes popularly dubbed the Gulf Stream System) has weakened significantly since the late 19th Century, with most of the decline happening since the mid-20th Century. The prime observational finding, is a long-term cooling trend in the subpolar Atlantic – the only region in the world which has cooled while the rest of the planet has warmed. Figure: Observed temperature trends since the beginning of the 20th Century What explains this cold blob? If the ocean temperature in any region changes, this can only be due to a change in heat supply or loss. That can either be a change in heat flow via ocean currents or through the sea surface. Thus the subpolar Atlantic can either have cooled because the ocean currents are bringing less heat into this region, or alternatively because more heat is being lost to the atmosphere. Weather dominates the short-term fluctuations, but the ocean currents dominate the long-term development because of the longer response time scale and “memory” of the ocean. There is a significant correlation of the NAO with subpolar Atlantic surface temperatures. But on the longer time scales of interest to us (for 20-year smoothed data), changes in the sea surface temperature lead the NAO changes by three years. We conclude that changes in sea surface temperatures cause the changes in NAO and not vice versa. In summer, the effect of heat flow through the sea surface should dominate, in winter the effect of ocean currents. That is because the well-mixed surface layer of the ocean is thin, so only the uppermost part of the ocean heat transport gets to affect the surface temperature. But the thin surface layer still feels the full brunt of atmospheric changes, and even stronger than in winter, because the thermal inertia of the thin summer surface layer is small. The cooling in the “cold blob” is most pronounced in winter. That suggests the ‘cold blob’ is driven from the ocean and not the atmosphere. AMOC is the dominant mechanism of heat transport into the high-latitude Atlantic. Across the different models, differences in the amount of AMOC slowdown nearly completely explain the differences in subpolar Atlantic temperatures. We have the conclusion by Kanzow et al. from hydrographic sections that the AMOC has weakened by ~ 10% since the 1950s (see below). And the Nitrogen-15 data of Sherwood et al. indicating a water mass change that matches what is predicted by the CM2.6 model for an AMOC slowdown. And the subsurface Atlantic temperature proxy data published recently by Thornalley et al. Plus there is work suggesting a weakening open-ocean convection. And finally, our time evolution of the AMOC that we proposed based on our AMOC index, i.e. based on the temperatures in the cold blob region, for the past decades matches evidence from ocean reanalysis and the RAPID project. Some of these other data are shown together with our AMOC index below. Figure: Time evolution of the Atlantic overturning circulation reconstructed from different data types since 1700. The scales on the left and right indicate the units of the different data types. The lighter blue curve was shifted to the right by 12 years since Thornalley found the best correlation with temperature with this lag. Our index is the dark blue line starting in 1870. Graph: Levke Caesar. Measuring the AMOC at a particular latitude in principle requires measuring a cross-section across the entire Atlantic, from surface to bottom. There are only two data sets that aspire to measure AMOC changes in this way. First, the RAPID project which has deployed 226 moored measuring instruments at 26.5 ° North for that purpose since 2004. It shows a downward trend since then, which closely matches what we find with our temperature-based AMOC index. Second is the work by Kanzow et al. (2010) using results of five research expeditions across the Atlantic between 1957 and 2004, correcting an earlier paper by Bryden et al. for seasonal effects and finding a roughly 10% decline over this period (in terms of the linear trend of these five data points). Some other measurements cover parts of the overturning circulation, and generally for short periods only. For 1994-2013, Rossby et al. (2013) – at the Oleander line between 32° and 40° North – found a decrease in the upper 2000m transport of the Gulf Stream by 0.8 Sverdrup (a Sverdrup is a flow of a million cubic meters per second). It is important to realize that the AMOC is not the same as the Gulf Stream. The latter, as measured by Rossby, has a volume flow of ~90 Sverdrup, while the AMOC has a volume flow of only 15-20 Sverdrup. While the upper northward branch of the AMOC does flow via the Gulf Stream, it thus only contributes about one fifth to the Gulf Stream flow. Any change in Gulf Stream strength could thus be due to a change in the other 80% of Gulf Stream flow, which are wind-driven. The AMOC does however provide the major northward heat transport which affects the northern Atlantic climate, because its return flow is cold and deep. Most of the Gulf Stream flow, in contrast, returns toward the south near the sea surface at a similar temperature as it flowed north, thus leaving little heat behind in the north. One interesting question for further research is how the AMOC in the Atlantic is linked to the exchange with the Nordic Seas across a line between Greenland, Iceland and Scotland. In our 2015 paper we showed a model result suggesting an anti-correlation of these overflows with the AMOC, and our new paper suggests a similar thing: a warm anomaly off Norway coinciding with the cold anomaly in the subpolar Atlantic, both in the high-resolution CM2.6 model and the observations. Cold meltwater from Greenland flowing in? You can work that out from a simple heat budget calculation. The amount is far too small to matter for the large-scale sea surface temperature, but enough to matter for sea surface salinity. Stefan (2018) If you doubt that the AMOC has weakened, read this PIK Because ongoing direct AMOC measurements only started in 2004, the researchers applied an indirect approach, using so-called proxy data, to find out more about the long-term perspective of its decline. Proxy data, as witnesses of the past, consist of information gathered from natural environmental archives such as tree rings, ice cores, ocean sediments, and corals, as well as from historical data, for instance from ship logs. “We used a combination of three different types of data to obtain information about the ocean currents: temperature patterns in the Atlantic Ocean, subsurface water mass properties and deep-sea sediment grain sizes, dating back from 100 to ca. 1600 years. While the individual proxy data is imperfect in representing the AMOC evolution, the combination of them revealed a robust picture of the overturning circulation [](fig/PIK_Gulf_Stream.jpeg An AMOC slowdown has long been predicted by climate models as a response to global warming caused by greenhouse gases – according to a number of studies, this is likely the reason for the observed weakening. The Atlantic overturning is driven by what the scientists call deep convection, triggered by the differences in the density of the ocean water: Warm and salty water moves from the south to the north where it cools down and thus gets denser. When it is heavy enough the water sinks to deeper ocean layers and flows back to the south. Global warming disturbs this mechanism: Increased rainfall and enhanced melting of the Greenland Ice Sheet add fresh water to the surface ocean. This reduces the salinity and thus the density of the water, inhibiting the sinking and thus weakening the flow of the AMOC. Its weakening has also been linked to a unique substantial cooling of the northern Atlantic over the past hundred years. This so-called ‘cold blob’ was predicted by climate models as a result of a weakening AMOC, which transports less heat into this region. The northward surface flow of the AMOC leads to a deflection of water masses to the right, away from the US east coast. This is due to Earth’s rotation that diverts moving objects such as currents to the right in the northern hemisphere and to the left in the southern hemisphere. As the current slows down, this effect weakens and more water can pile up at the US east coast, leading to an enhanced sea level rise. In Europe, a further slowdown of the AMOC could imply more extreme weather events like a change of the winter storm track coming off the Atlantic, possibly intensifying them. Other studies found possible consequences being extreme heat waves or a decrease in summer rainfall. If we continue to drive global warming, the Gulf Stream System will weaken further – by 34 to 45 percent by 2100 according to the latest generation of climate models. This could bring us dangerously close to the tipping point at which the flow becomes unstable. PIK 20.8.3 AMOC Collapse EWS (Early Warning Signals) Ditlevsen [See also under ‘Statistics/Collapse’] Ditlevsen Abstract The Atlantic meridional overturning circulation (AMOC) is a major tipping element in the climate system and a future collapse would have severe impacts on the climate in the North Atlantic region. In recent years weakening in cir- culation has been reported, but assessments by the Intergovernmental Panel on Climate Change (IPCC), based on the Climate Model Intercomparison Project (CMIP) model simulations suggest that a full collapse is unlikely within the 21st century. Tipping to an undesired state in the climate is, however, a growing concern with increasing greenhouse gas concentrations. Predictions based on observations rely on detecting early-warning signals, primarily an increase in variance (loss of resilience) and increased autocorrelation (critical slowing down), which have recently been reported for the AMOC. Here we provide statistical signiﬁcance and data-driven estimators for the time of tip- ping. We estimate a collapse of the AMOC to occur around mid-century under the current scenario of future emissions. Ditlevsen (2023) Warning of a forthcoming collapse of the Atlantic meridional overturning circulation (pdf) 20.8.4 Gulf Stream weakening - measurements Piecuch Abstract The Gulf Stream is a vital limb of the North Atlantic circulation that influences regional climate, sea level, and hurricane activity. Given the Gulf Stream’s relevance to weather and climate, many studies have attempted to estimate trends in its volumetric transport from various data sets, but results have been inconclusive, and no consensus has emerged whether it is weakening with climate change. Here we use Bayesian analysis to jointly assimilate multiple observational data sets from the Florida Straits to quantify uncertainty and change in Gulf Stream volume transport since 1982. We find with virtual certainty (probability P &gt; 99%) that Gulf Stream volume transport through the Florida Straits declined by 1.2 ± 1.0 Sv in the past 40 years (95% credible interval). This significant trend has emerged from the data set only over the past ten years, the first unequivocal evidence for a recent multidecadal decline in this climate-relevant component of ocean circulation. Piecuch Summary The Gulf Stream is a major ocean current located off the East Coast of the United States. It carries a tremendous amount of seawater and along with it heat, carbon, and other ocean constituents. Because of this, the Gulf Stream plays an important role in weather and climate, influencing phenomena as seemingly unrelated as sea level along coastal Florida and temperature and precipitation over continental Europe. Given how important this ocean current is to science and society, scientists have tried to determine whether the Gulf Stream has undergone significant changes under global warming, but so far, they have not reached a firm conclusion. Here we report our effort to synthesize available Gulf Stream observations from the Florida Straits near Miami, and to assess whether and how the Gulf Stream transport there has changed since 1982. We conclude with a high degree of confidence that Gulf Stream transport has indeed slowed by about 4% in the past 40 years, the first conclusive, unambiguous observational evidence that this ocean current has undergone significant change in the recent past. Future studies should try to identify the cause of this change. Piecuch (2023) Robust Weakening of the Gulf Stream During the Past Four Decades Observed in the Florida Straits 20.9 Denmark Strait cataract Puiu The Denmark Strait’s underwater waterfall — known as the Denmark Strait cataract — plays a pivotal role in the intricate dance of the Atlantic’s thermohaline circulation, which influences our planet’s climate on a global scale. The journey begins in the Arctic, where surface water cools and gains density, causing it to sink and flow toward lower latitudes. Following the contours of the seafloor, this immense current accelerates as it encounters the submarine relief of the Denmark Strait, transforming into a breathtaking waterfall beneath the waves. Eventually, it converges with the great troughs of the northern Atlantic Ocean, leaving an indelible mark on the deep-sea ecosystems thriving in the area. While the scientific community has dedicated considerable efforts to studying the hydrodynamic properties of this underwater marvel, many aspects of its behavior remain shrouded in mystery. This is where the FAR-DWO oceanographic campaign, led by Professors David Amblàs and Anna Sanchez-Vidal from the University of Barcelona, comes in. From July 19 to August 12, 2023, the team boarded the oceanographic ship Sarmiento de Gamboa and embarked on an unprecedented journey. “To date, we have examined the hydrodynamic characteristics of this colossal underwater cataract. However, in the FAR-DWO expedition, our goal is to delve into unexplored realms,” explained David Amblàs and Anna Sanchez-Vidal from the University of Barcelona’s Department of Earth and Ocean Dynamics. “We will investigate its capacity to transport sediments, its role in shaping the seabed relief, and the influence of topography on its propagation.” During the campaign, the team analyzed the hydrographic and sedimentological variability of the waterfall by sampling and observing the water column, as well as studying the sediment and seafloor relief. Two lines equipped with instruments were deployed at great depths, continuously recording hydrological information until their recovery in September 2024. The results are still pending. The researchers in Barcelona have quite a bit of experience. Their groundbreaking 2008 study revealed the existence of dense water cascades in the Cap de Creus canyon, along the northern coast of Catalonia in the northwestern Mediterranean. They plan to combine observational data from both marine areas with a numerical hydrosedimentary model, providing a groundbreaking quantification of the underwater cascades’ transformative power. Puiu (2023) The world’s largest waterfall is actually underwater 20.10 Whale Mitigation Chami When it comes to saving the planet, one whale is worth thousands of trees. Many proposed solutions to global warming, such as capturing carbon directly from the air and burying it deep in the earth, are complex, untested, and expensive. What if there were a low-tech solution to this problem that not only is effective and economical, but also has a successful funding model? An example of such an opportunity comes from a surprisingly simple and essentially “no-tech” strategy to capture more carbon from the atmosphere: increase global whale populations. Marine biologists have recently discovered that whales—especially the great whales—play a significant role in capturing carbon from the atmosphere (Roman and others 2014). And international organizations have implemented programs such as Reducing Emissions from Degradation and Deforestation (REDD) that fund the preservation of carbon-capturing ecosystems. The carbon capture potential of whales is truly startling. Whales accumulate carbon in their bodies during their long lives. When they die, they sink to the bottom of the ocean; each great whale sequesters 33 tons of CO2 on average, taking that carbon out of the atmosphere for centuries. A tree, meanwhile, absorbs only up to 48 pounds of CO2 a year. Protecting whales could add significantly to carbon capture because the current population of the largest great whales is only a small fraction of what it once was. Sadly, after decades of industrialized whaling, biologists estimate that overall whale populations are now to less than one fourth what they once were. Some species, like the blue whales, have been reduced to only 3 percent of their previous abundance. Thus, the benefits from whales’ ecosystem services to us and to our survival are much less than they could be. Whale Pump Wherever whales, the largest living things on earth, are found, so are populations of some of the smallest, phytoplankton. These microscopic creatures not only contribute at least 50 percent of all oxygen to our atmosphere, they do so by capturing about 37 billion metric tons of CO2, an estimated 40 percent of all CO2 produced. To put things in perspective, we calculate that this is equivalent to the amount of CO2 captured by 1.70 trillion trees—four Amazon forests’ worth—or 70 times the amount absorbed by all the trees in the US Redwood National and State Parks each year. More phytoplankton means more carbon capture. In recent years, scientists have discovered that whales have a multiplier effect of increasing phytoplankton production wherever they go. How? It turns out that whales’ waste products contain exactly the substances—notably iron and nitrogen—phytoplankton need to grow. Whales bring minerals up to the ocean surface through their vertical movement, called the “whale pump,” and through their migration across oceans, called the “whale conveyor belt. Despite the fact that nutrients are carried into the ocean through dust storms, river sediments, and upwelling from wind and waves, nitrogen and phosphorus remain scarce and limit the amount of phytoplankton that can bloom in warmer parts of the oceans. In colder regions, such as in the Southern Ocean, the limiting mineral tends to be iron. If more of these missing minerals became available in parts of the ocean where they are scarce, more phytoplankton could grow, potentially absorbing much more carbon than otherwise possible. If whales were allowed to return to their pre-whaling number of 4 to 5 million—from slightly more than 1.3 million today—it could add significantly to the amount of phytoplankton in the oceans and to the carbon they capture each year. Despite the drastic reduction in commercial whaling, whales still face significant life-threatening hazards, including ship strikes, entanglement in fishing nets, waterborne plastic waste, and noise pollution. While some species of whales are recovering—slowly—many are not. Enhancing protection of whales from human-made dangers would deliver benefits to ourselves, the planet, and of course, the whales themselves. This “earth-tech” approach to carbon sequestration also avoids the risk of unanticipated harm from suggested untested high-tech fixes. Nature has had millions of years to perfect her whale-based carbon sink technology. All we need to do is let the whales live. Finance! International financial institutions, in partnership with other UN and multilateral organizations, are ideally suited to advise, monitor, and coordinate the actions of countries in protecting whales. Whales are commonly found in the waters around low-income and fragile states, countries that may be unable to deal with the needed mitigation measures. Support for these countries could come, for example, from the Global Environment Facility, which typically provides support to such countries to meet international environmental agreements. The IMF is also well placed to help governments integrate the macroeconomic benefit that whales provide in mitigating climate change, as well as the cost of measures to protect the whales, into their macro-fiscal frameworks. The World Bank has the expertise to design and implement specific programs to compensate private sector actors for their efforts to protect whales. Other UN and multilateral organizations can oversee compliance and collect data to measure the progress of these efforts. Coordinating the economics of whale protection must rise to the top of the global community’s climate agenda. Earth-Tech The “earth-tech” strategy of supporting whales’ return to their previous abundance in the oceans would significantly benefit not only life in the oceans but also life on land, including our own. Chami IMF (2019) Protect Whales - Limit Global Warming (pdf) Meynecke Whales have been titled climate savers in the media with their recovery welcomed as a potential carbon solution. However, only a few studies were performed to date providing data or model outputs to support the hypothesis. Following an outline of the primary mechanisms by which baleen whales remove carbon from the atmosphere for eventual sequestration at regional and global scales, we conclude that the amount of carbon whales are potentially sequestering might be too little to meaningfully alter the course of climate change. This is in contrast to media perpetuating whales as climate engineers. Creating false hope in the ability of charismatic species to be climate engineers may act to further delay the urgent behavioral change needed to avert catastrophic climate change impacts, which can in turn have indirect consequences for the recovery of whale populations. Nevertheless, whales are important components of marine ecosystems, and any further investigation on existing gaps in their ecology will contribute to clarifying their contribution to the ocean carbon cycle, a major driver of the world’s climate. While whales are vital to the healthy functioning of marine ecosystems, overstating their ability to prevent or counterbalance anthropogenically induced changes in global carbon budget may unintentionally redirect attention from known, well-established methods of reducing greenhouse gases. Large scale protection of marine environments including the habitats of whales will build resilience and assist with natural carbon capture. Figure: The nested cycles of marine organic carbon (Corg), including (1) net primary production and heterotrophic respiration in the surface ocean, (2) export production from the surface ocean and respiration in the deep sea followed by upwelling or mixing of the respired CO2 back to the surface ocean (the soft-tissue component of the biological pump); and (3) the burial of sedimentary organic carbon. Also shown are the indicative residence times (r). Note that carbon reservoirs shown refer solely to the fraction affected by organic carbon cycling; for instance, the deep-ocean value shown is of carbon dioxide produced by respiration, not the carbon released from CaCO3 dissolution. For whales to play a role in reducing atmospheric CO2 concentrations, they need to influence the biological pump such that there is an increase in (i) the export of organic carbon from the surface to the deep ocean and/or (ii) the amount removed from the ocean and entering the slower sediment circuit. Meynecke (2023) Do whales really increase the oceanic removal of atmospheric carbon? Nyhus Giganten tar med seg klimagassar i grava - Presset aukar på Noreg for å byggje opp att kvalbestanden. Men klimagevinsten til kvalane er omstridd. Kvalar som døyr naturleg og søkk til botn tek med seg store mengder karbon i grava og «fangar» ho for godt. Men kor mykje? Det internasjonale pengefondet (IMF) har taksert denne «karbonfangsten» til ein verdi av 2 milliardar dollar. Reknestykket legg til grunn at 1000 kvalar blir drepne kvart år. I 2022 tok Noreg livet av 581 vågekval. I ein ny forskingsartikkel går forfattarane i rette med forteljinga om kvalen som naturen sin eigen vaktmester og «klimaentreprenør». I artikkelen skriv dei at kvalen sin tiltrekkingskraft på mennesket skaper « » om at vegen til klimafrelse går gjennom den store skapningen. – Kva rolle kvalane speler med omsyn til klima er flittig diskutert i forskarmiljøa, seier Martin Biuw, som leier forskingsgruppa for sjøpattedyr ved Havforskingsinstituttet. Han legg til: – Det er langt frå klarlagt kor viktig denne rolla eigentleg er. For å klarleggje kvalen si rolle i karbonsyklusen er Havforskingsinstituttet med i eit internasjonalt partnarskap for å forstå krinsløpet betre. Å talfeste bidraget til kvalen i den store marine karbonpumpa er prega av stor uvisse, seier Joakim Hauge i Bellona. Han presiserer: – Når det er sagt, er det ikkje tvil om at å leggje til rette for store kvalpopulasjonar vil bidra til stor karbonlagring. Med utgangspunkt i at ingenting styrar åtferd meir enn lommeboka, har chilenske styresmakter oppretta ei prøveordning med «biokredittar» der båtførarar som forstyrrar kvalen må betale ei «kvalavgift». Meir naturleg å satse på kvalen enn regnskogen I 1972 vart kvalen eit symbol på FNs miljøvernerklæring, og har sidan skapt gnissingar mellom verdssamfunnet og Noreg. Noreg, Japan og Island er dei einaste landa i verda som framleis tillèt kvalfangst. Under den globale fangsttoppen rundt 1960 vart om lag 75.000 kval drepne kvart år. I dag reknar Den Internasjonale kvalfangstkommisjonen (IWC) med at det svømmer 1,5 millionar rundt i verdshava. For hundre år sidan var talet 4,5 millionar. Slik frakter hvalen næringsstoffer og mineraler Ekspander/minimer faktaboks Professor i bevaringsbiologi Anne Sverdrup-Thygeson skriver om «hvalfall» og hvalens bidrag til karbonsyklusen i boka På naturens skuldre (2020). Boka er anmeldt her. Et utdrag: «En sjelden gang kommer det noe skikkelig digert dalende ned fra oven. Et hvalfall. Bare ordet er nok til å få det til å krible i hjernevindingene mine. For mitt indre blikk ser jeg for meg hvordan et enormt berg av kjøtt og spekk og bein synker sakte, majestetisk, nedover i vannmassene. Tonnevis med karbon, nitrogen, kalsium, fosfor, i livets siste dykk. (…) Forskerne har sett på hvordan de store hvalene, som knølhval, spermhval og blåhval, bidrar til å pumpe næring til de delene av havet der det trengs mer. Disse hvalene dykker dypt i havet for å hente føde av ulike slag – fisk, blekksprut eller krill. Så svømmer de opp til overflaten for å puste. Her slippes også avføringen ut, og den flyter. Slik frakter hvalen næringsstoffer og mineraler (som nitrogen eller jern) opp til overflatevannet. I noen havområder, som i Sørishavet, begrenses planteplanktonets vekst nettopp av tilgangen på jern. Spermhval-avføring har en jernkonsentrasjon minst ti millioner ganger høyere enn vannet. Hvalens tilstedeværelse gir økt planteplankton-vekst, som igjen betyr mer fotosyntese og mer CO2 fanget fra atmosfæren – karbon som gjerne daler ned på havdypet som marin snø når det korte planktonlivet er over. Et forsiktig estimat fra Sørishavet antyder at spermhvalen der sender flere hundre tusen tonn karbon ut av systemet og ned til lagring på havets dyp, hvert år. I tillegg legger mange av de store hvalene ut på lange vandringer, blant de mest imponerende årlige migrasjoner vi kjenner til blant pattedyra. Knølhvalen, for eksempel, beiter i kaldt, næringsrikt vann på høye breddegrader, men forflytter seg til varmere, typisk 124 | på naturens skuldre mindre næringsrike havområder nærmere ekvator for å kalve. Som oftest spiser ikke hvalene mens de er i kalvingsområdene, de bare tærer på fettet. Men tisse må de, og urinen de slipper ut, er rik på nitrogen, som ofte er mangelvare i disse farvannene (og det monner når du er stor – en islandsk forsker anslår at en gjennomsnittlig finnhval tisser 974 liter i døgnet …). Slik blir hvalenes langturer en del av et transportbånd for næring, fra rike hav til næringsfattige havområder.» Nyhus (2023) Giganten tar med seg klimagassar i grava 20.11 Antarctica’s Role Climate change is rapidly pushing five critical, interconnected processes in the Antarctic Southern Ocean towards substantial changes. It warns that disrupting these processes may disproportionately exacerbate global climate change and have widespread impacts on marine and human life worldwide, due to the region’s central role in regulating our earth systems. Wilson Center 20.12 Failing phytoplankton, failing oxygen University of Lancaster Falling oxygen levels caused by global warming could be a greater threat to the survival of life on planet Earth than flooding, according to researchers from the University of Leicester. A study led by Sergei Petrovskii, Professor in Applied Mathematics from the University of Leicester’s Department of Mathematics, has shown that an increase in the water temperature of the world’s oceans of around six degrees Celsius – which some scientists predict could occur as soon as 2100 – could stop oxygen production by phytoplankton by disrupting the process of photosynthesis. Professor Petrovskii explained: “Global warming has been a focus of attention of science and politics for about two decades now. A lot has been said about its expected disastrous consequences; perhaps the most notorious is the global flooding that may result from melting of Antarctic ice if the warming exceeds a few degrees compared to the pre-industrial level. However, it now appears that this is probably not the biggest danger that the warming can cause to the humanity. “About two-thirds of the planet’s total atmospheric oxygen is produced by ocean phytoplankton – and therefore cessation would result in the depletion of atmospheric oxygen on a global scale. This would likely result in the mass mortality of animals and humans.” The team developed a new model of oxygen production in the ocean that takes into account basic interactions in the plankton community, such as oxygen production in photosynthesis, oxygen consumption because of plankton breathing and zooplankton feeding on phytoplankton. While mainstream research often focuses on the CO2 cycle, as carbon dioxide is the agent mainly responsible for global warming, few researchers have explored the effects of global warming on oxygen production. The 2015 United Nations Climate Change Conference will be held in Le Bourget, Paris, from November 30 to December 11. It will be the 21st yearly session of the Conference of the Parties to the 1992 United Nations Framework Convention on Climate Change (UNFCCC) and the 11th session of the Meeting of the Parties to the 1997 Kyoto Protocol. The conference objective is to achieve a legally binding and universal agreement on climate, from all the nations of the world. University of Lancaster (2015) Petrovski Abstract Ocean dynamics is known to have a strong effect on the global climate change and on the composition of the atmosphere. In particular, it is estimated that about 70 % of the atmospheric oxygen is produced in the oceans due to the photosynthetic activity of phytoplankton. However, the rate of oxygen production depends on water temperature and hence can be affected by the global warming. In this paper, we address this issue theoretically by considering a model of a coupled plankton–oxygen dynamics where the rate of oxygen production slowly changes with time to account for the ocean warming. We show that a sustainable oxygen production is only possible in an intermediate range of the production rate. If, in the course of time, the oxygen production rate becomes too low or too high, the system’s dynamics changes abruptly, resulting in the oxygen depletion and plankton extinction. Our results indicate that the depletion of atmospheric oxygen on global scale (which, if happens, obviously can kill most of life on Earth) is another possible catastrophic consequence of the global warming, a global ecological disaster that has been overlooked. Petrovski (2015) Mathematical Modelling of Plankton–Oxygen Dynamics Under the Climate Change (paywall) "],["permafrost.html", "21 Permafrost", " 21 Permafrost Turetsky Permafrost stores 2x the amount of carbon in the atmosphere yet is not considered by many climate models. Are we totally screwed??? Here I will explain what we know and why I promote #ClimateActionNow but not panic. 1/ The Arctic (and its permafrost soils) is not a missing black box in any climate model, which all include Arctic soils. Until we explicitly include permafrost in these models, it is difficult to know what climate feedbacks we are missing. Likely to be in the middle. 2/ I research abrupt permafrost thaw, known to be a large source of methane. NO large scale models address abrupt thaw, yet. Ouch. Still, some portion of abrupt thaw fluxes are included in current modeling. What’s the potential for overlap? More than zero, but we don’t know. 3/ Facts: 1) Rates of permafrost thaw are increasing with rapid Arctic warming. 2) Permafrost extent on our planet is shrinking. 3) Unlike in the past, permafrost that thaws today or in the near future is unlikely to reform. Also, Arctic fires are an amplifier. 4/ So why do I advocate no panic? 1) the best evidence shows that reducing human emissions will keep some permafrost frozen. 2) Permafrost has resisted past warm periods. It deserves our help and RESPECT. 3) Losing permafrost is not the same as losing permafrost carbon…. 5/ Permafrost thaw can stimulate plant growth and entirely offset permafrost carbon losses. In other places, this won’t happen. The Arctic long has been a climate champion, but we need to prepare for a state change and an Arctic that exerts its muscles on global climate. 6/ Worrying about a missing Arctic carbon bomb does not keep me awake at night. Rather, I worry that we don’t have the tools to monitor the Arctic increasing its climate muscles. Improved atmospheric monitoring, field networks, climate models. Let’s not panic, let’s get to work. 7/7 Turetsky (twitter thread) Some text on Permafrost "],["soil.html", "22 Soil 22.1 Soil Depth 22.2 Peatland 22.3 Land Use Change (LUC) 22.4 Fertilizers 22.5 Regenerative Agriculture 22.6 Rice Fields 22.7 Fungi", " 22 Soil Guardian The storage potential of one of the Earth’s biggest carbon sinks – soils – may have been overestimated, research shows. This could mean ecosystems on land soaking up less of humanity’s emissions than expected, and more rapid global heating. The study, based on over 100 experiments, found the opposite. When plant growth increases, soil carbon does not. The finding is significant because the amount of organic carbon stored in soils is about three times that in living plants and double that in the atmosphere. Soils can also store carbon for centuries, whereas plants and trees rot quickly after they die. When rising CO2 increases plant growth, there is a decrease in soil carbon storage. If soils do absorb less in future, “the speed of global warming could be higher” Soils, plants and trees are important for carbon levels, but ending the burning of fossil fuels is essential. To stop global warming, we need to stop emissions, because ecosystems only take up a fraction of all the CO2 emissions. The researchers found that in grasslands, elevated CO2 led to 9% plant growth – less than forests – but soil carbon rose by 8%. Terrier said there has been a lot of discussion about tree planting as a way to tackle the climate crisis. “What I found very concerning in that debate is that people were suggesting planting trees in natural grasslands, savannah, and tundra,” he said. “I think that would be a terrible mistake because, as our results imply, there is a very large potential to increase soil carbon storage in grasslands.” Given that the land absorbs 30% of the carbon emitted from fossil fuels and deforestation, understanding if that will change in the future matters. Change would be determined by the balance between rising CO2 boosting plant growth and the negative effects of climate change itself, including drought, heatwaves and fires. The evidence to date suggests the biggest change will be the negative effects of global heating on ecosystems Guardian 22.1 Soil Depth No-till farming was developed and promoted in the mid-20th century as an erosion control measure. Under conve ntional tillage, soil is broken up and mixed mechanically. In no-till farming, soil disturbance is minimized and crop residues are left on the soil surface. Reducing or eliminating tillage improves water infiltration r ates and protects against wind and water erosion. Reducing tillage also improves soil structure, allowing “ag gregates” (intact clumps of soil) to form when they otherwise would have been broken into smaller pieces. Agg regates are often carbon rich, and are thought to have a role in protecting organic matter from decay.Althoug h this suggests that eliminating or reducing tillage might be a way to increase the overall amount of carbon stored in soil, the relationship between tillage and soil carbon storage remains a heavily debated topic. No fewer than 11 synthesis papers published in the past five years have addressed the relationship between tilla ge and soil carbon storage. These papers each analyzed data from hundreds of individual studies. While the synthesis papers analyzed many of the same studies, they reached a range of conclusions. Some have concluded that tillage has no statistica lly detectable effect on overall soil carbon storage, while others have identified positive effects or indica ted that tillage effects depend on other factors such as climate and soil type Sampling depth is likely a key source of the disagreement. It has two main effects, which we call the “carbon redistribution effect” and “density change effect”. We’ll describe each in turn. CarbonPlan 22.2 Peatland Gallego-Sala Peatlands cover just 3% of the world’s land area, but store twice as much carbon as all the trees on Earth combined. The carbon held in these wetlands has been accumulating for millennia and may be “irrecoverable”. This means that, once released, the carbon in the soil would take centuries to re-establish – way beyond the timescales relevant for tackling climate change. But the world is losing huge quantities of carbon from peatlands each year. In fact, humans have already pushed the Earth’s peatlands from an overall “sink” of carbon to a “source”. This is mainly due to drainage of tropical peatlands to convert land for farming. It is now widely accepted that peatlands can play a key role in tackling climate change as one of many potential “nature-based solutions” – both through restoration efforts, but also through “avoided emissions” from protecting pristine peatlands. Peat is a wetland soil made of partially decomposed plant debris. The soil being saturated is key to its extraordinary stores of carbon. The water creates “anoxic” conditions in the soil. This lack of oxygen slows down how quickly microbes can break down the organic matter the soil contains. Decomposition without oxygen produces methane, which is why peatlands are natural methane emitters. However, the sluggish pace of decomposition means that peatlands take up carbon more quickly than it is emitted. Draining a peatland – taking the water table below a certain threshold – triggers a fundamental shift in this ecological balance. With oxygen now available, decomposition speeds up and carbon dioxide (CO2) emissions increase. This turns the peatland into a carbon source. Additionally, peat is a fuel and, once it dries, it becomes increasingly easy to ignite. Peat fires are now common in drained or drought-affected peatlands all over the world. For example, during El Niño years, dry conditions in Indonesia can contribute to widespread peatland fires, substantially increasing global land-use emissions. All of these extra emissions increase the account of CO2 in the atmosphere. Peatlands can be responsible for as much as 5-10% of global annual human-caused CO2 emissions. Restoring, or “rewetting”, peatlands is, therefore, an important route towards recovering the carbon sink function in these ecosystems. It has been shown to be efficient in terms of both land area – these are the most carbon dense ecosystems in the world – and financial cost. Gallego-Sala (2021) Peatlands cover just 3% of the world’s land area, but store twice as much carbon as all the trees on Earth combined. 22.3 Land Use Change (LUC) Independent A recent study in Nature Communications shows that global demands for commodities, especially in connection with agricultural development, are the main drivers of land use change in the global south. A land use change is defined as a permanent or long-term conversion in the type of cover of an area of land, for instance from forest to urban use, agricultural crops or savanna, or vice versa. The researchers used modern satellite technology, now able to detect changes such as deforestation in near real time, to evaluate global trends. They suggest global land use changes may be happening at a much higher rate than previously thought. The authors found that 17 per cent of the Earth’s land surface has undergone change at least once since 1960, which works out to an area the size of Germany every year. Over that period there was a net forest loss of 0.8 million km², while agricultural crops expanded by 1 million km² and rangelands and pastures by 0.9 million km². Independent Winkler we analyse the dynamics of global land use change at an unprecedented spatial resolution by combining multiple open data streams (remote sensing, reconstructions and statistics) to create the HIstoric Land Dynamics Assessment + (HILDA +). We estimate that land use change has affected almost a third (32%) of the global land area in just six decades (1960-2019) and, thus, is around four times greater in extent than previously estimated from long-term land change assessments. We also identify geographically diverging land use change processes, with afforestation and cropland abandonment in the Global North and deforestation and agricultural expansion in the South. Here, we show that observed phases of accelerating (~1960–2005) and decelerating (2006–2019) land use change can be explained by the effects of global trade on agricultural production. Temporal dynamics of global land use change and its relation to globalised markets. The rate of global land use change was not constant over time. In analysing the temporal dynamics, we identify two different phases: (1) an acceleration phase with an increasing rate of change from 1960 to 2004; and (2) a decreasing rate of change from 2005 to 2019. The transition from constant to rising rates of land use change has been discussed in the context of shifting global food regimes and coincides with a period when global food production changed from agro- technological intensification (driven by the Green Revolution in the 1960s) to the production for globalised markets and increasing trade, especially during the 1990s. We find this acceleration phase to be more distinct in regions of the Global South, as observed in South America, Africa and Southeast Asia, where production and export of commodity crops have increased, most strikingly since the 2000s. The growing influence of tele-connected markets is found to be a major driver of land use change, parti- cularly deforestation for commodity crops in the Global South. This offshoring of land use change from the Global North to the South is evident in the growing proportion of cropland in the countries of the Global South used for export and consumption outside of their territories. However, the data suggest a rather abrupt change to decreasing rates of land use change in the period from 2005, which is most evident in Africa and South America, regions of the Subtropics and Tropics. We hypothesise that the transition from accelerating to decelerating land use change is related to market developments in the context of the global economic and food crisis 2007–2009. Before the crisis, rising demand for food, animal feed and biofuels as well as increasing oil prices (reaching an all-time high in 2008 at $145.31 per barrel of Crude) stimulated global agricultural production, which enhanced global land use change. In particular, high oil prices made bioenergy crops more competitive and profitable compared to fossil fuels. Increasing demand, mostly in the developed countries of the Global North, spurred bioenergy crop expansion in the Global South (e.g. production of oil crops in Ghana, Argentina, Brazil and Indonesia). Biofuel policies, climatic extremes and export bans led to global food price spikes in 2007–2008 and in 2010, which raised concerns about food security in many import-dependent countries and rapidly growing economies (e.g. the EU, China or India). A wave of large-scale, transboundary land acquisitions and foreign investments in agriculture emerged, mostly targeting sub- Saharan Africa, Southeast Asia and South America 48,55,56 . This development is reflected in the sudden increase in the rate of land use change (during 2000–2005), ensuing fluctuations (during 2006–2010) and sharp decrease (after 2010) in countries of the Global South, e.g. Brazil, Argentina or Ethiopia. We find that the observed slowdown of global land use change after the economic crisis 2007–2009 is mainly caused by a decline in agricultural expansion in the countries of the Global South, particularly pronounced in Argentina, Ghana and Ethiopia. We postulate that the global deceleration of land use change is related to market mechanisms during the economic crisis. With the economic boom coming to an end during the Great Recession, the global demand for commodities dropped. Countries which focussed on the produc- tion of commodity crops for global markets prior to the crisis (e.g. Argentina, Brazil, Ghana or Indonesia), no longer found buyers for their goods, reduced agricultural production and, thus, the rate of agricultural land expansion. The observed sharp decline in the rate of land use change, especially in Africa, may be further caused by a decrease in the number and size of global land acquisitions after the financial crisis in 2007–2009. Since then, hedge funds in land became less common and concerns were raised about unsustainable practices related to transbound- ary land acquisitions (e.g. land/water degradation and displace- ment of rural labour). Resulting incentives from international organisations and exporting countries to limit land trade may have led to the recent decline in large-scale land acquisitions. Winkler (2021) Global land use changes are four times greater than previously estimated (pdf) 22.3.1 Climate effect of Land Use Change Kalnay Abstract The most important anthropogenic influences on climate are the emission of greenhouse gases1 and changes in land use, such as urbanization and agriculture. But it has been difficult to separate these two influences because both tend to increase the daily mean surface temperature. The impact of urbanization has been estimated by comparing observations in cities with those in surrounding rural areas, but the results differ significantly depending on whether population data or satellite measurements of night light are used to classify urban and rural areas. Here we use the difference between trends in observed surface temperatures in the continental United States and the corresponding trends in a reconstruction of surface temperatures determined from a reanalysis of global weather over the past 50 years, which is insensitive to surface observations, to estimate the impact of land-use changes on surface warming. Our results suggest that half of the observed decrease in diurnal temperature range is due to urban and other land-use changes. Moreover, our estimate of 0.27 °C mean surface warming per century due to land-use changes is at least twice as high as previous estimates based on urbanization alone. Kalnay (2003) Impact of urbanization and land-use change on climate(pdf) 22.4 Fertilizers Carbon Brief Fertilisers are helping to degrade [the soil] and not build fertile soils. The global production of fertilisers is responsible for around 1.4% of annual CO2 emissions, and fertiliser use is a major contributor of non-CO2 greenhouse gas emissions. Beyond CO2 and water, a plant needs three primary nutrients in large quantities in order to grow: nitrogen, phosphorus and potassium. These nutrients, which are sucked up from the soil by a plant’s root system, have several different roles to play. Among other things, nitrogen is a major component of chlorophyll, which is needed for photosynthesis, and amino acids, which are crucial for plant development. Phosphorus is heavily involved in the way plants produce energy. Potassium plays a key role in regulating how a plant transports and uses water. Although nitrogen is the most abundant element on Earth, it is primarily found as “unreactive” nitrogen gas in the atmosphere. Its inert nature means that plants are unable to incorporate this nitrogen into their cells. Rather, plants need a reactive, or “biologically available”, form of the element in order to build new biomass. In the absence of human intervention, plants maintain a careful balance of nutrients in the soil. Certain microbes live symbiotically with legumes and other plants, taking nitrogen gas from the air and “fixing” it into the forms that plants can use, such as ammonia. The diagram below shows the processes that transform nitrogen into different forms in the soil. While each of these three major nutrients is naturally found in soils, for thousands of years, humans have been adding more in the form of fertilisers to encourage plant growth and boost crop yields. Fertilisers can broadly be separated into two categories: organic fertilisers and mineral fertilisers, sometimes referred to as chemical or synthetic fertilisers. Together, nitrogen, phosphorus and potassium fertilisers are known as “NPK fertilisers”. Today, the world applies more than 100m tonnes of synthetic nitrogen fertiliser to its crops every year. Around half of this is used to boost the production of cereals – predominantly maize, wheat and rice. In addition, around 50m tonnes of phosphorus fertilisers and more than 40m tonnes of potassium are used annually. Six companies have market caps in the tens of billions of US dollars: Canada’s Nutrien, Australia’s Wesfarmers, US-based CF Industries, SABIC Agri-Nutrients Company (formerly the Saudi Arabian Fertilizer Company), the US-based Mosaic Company and the ICL Group, formerly Israel Chemicals Ltd. Synthetic fertiliser use is high in the US, Canada and western Europe, where large-scale, mechanised agriculture is the norm. Its use is also high in several large, fast-growing economies, including Brazil, China and India. By contrast, fertiliser use is low across most of Africa, with Egypt being a notable exception. Use varies widely around the world, depending on the types of crops grown, the soil quality and myriad other factors. Nearly half of fertiliser applied in the US is used on maize fields, while soya crops are responsible for 40% of Brazil’s fertiliser consumption. 83% of fertiliser used in Malaysia is applied to oil palm plantations, while just under 90% of New Zealand fertiliser use is for grasslands. These regional differences extend to the types of fertiliser applied as well. Since soya, as with other legumes, is capable of fixing its own nitrogen, these plantations require higher inputs of phosphorus and lower use of nitrogen fertiliser. Since 1960, the amount of fertiliser used annually has increased nearly 10-fold. Fertiliser usage have gone hand-in-hand with increasing food yields – global cereal production has grown three- or four-fold in that same period. Had we not been eating high-meat diets, the world could have clearly fed more people with less fertiliser. We wouldn’t have all those livestock emissions if we hadn’t had enough nitrogen to feed all those animals to increase our population. [Genetic engineering] was the engine of the Green Revolution – the high-yielding genetic varieties – but the fuel of the Green Revolution, to power the engine, was the fertilisers. The mass adoption of synthetic fertilisers has come at a significant cost to the environment. Because the Haber-Bosch process is carried out at high temperature and pressure, the greenhouse gas emissions associated with it are substantial. In fact, producing ammonia fertilisers is responsible for about 1% of all global energy use and 1.4% of CO2 emissions – almost equivalent to the emissions of Germany. About 40% of the fossil gas input into the process is burned to fuel the reaction, with the remaining 60% being used as the feedstock. Although discussions around the environmental impacts of fertilisers tend to focus on nitrogen, the limited quantity of phosphorus in the Earth means that that resource is actually a more pressing concern. The global cycle of nutrients is completely unbalanced. This is terrible concerning sustainability. Fertiliser contributes to climate change in several key ways. Energy-intensive extractive and manufacturing processes require the burning of significant amounts of fossil fuels to turn raw materials into usable fertilisers. Many types of fertiliser are transported across long distances, adding to their greenhouse footprints. As with food-related emissions, transportation makes up only a small fraction of fertilisers’ greenhouse gas emissions – just a few percent of the total, according to Vaneeckhaute. However, recent research has suggested that the transport emissions associated with the entire food system – including transporting fertilisers, machinery and animal feed – are significantly higher than previously estimated. When nitrogen-containing fertilisers are applied to a field, some of the reactive nitrogen is taken up by plants, but another portion is lost to the environment. This is leached out into the soils, washed into rivers and other bodies of water by rain or irrigation water or released from the field directly into the atmosphere as vapour. Nutrient runoff can feed algal blooms, releasing methane and leading to oxygen declines in watercourses that can kill fish. A third portion is lost to the atmosphere as nitrous oxide, a greenhouse gas nearly 300 times as powerful as CO2. Microbes in the soil can break down the nitrogen fertilisers applied to a field to produce nitrous oxide. Nitrous oxide is the third-most abundant greenhouse gas in the atmosphere, after CO2 and methane. Emissions of the gas are predominantly due to agriculture. In 2019, nitrous oxide emissions were about one-third higher than they were in 1990. Nitrogen applied to crops can also escape to the atmosphere as ammonia or NOx gases, which can form particulate matter, absorbing or reflecting sunlight and producing a cooling effect. The warming and cooling effects of nitrogen approximately cancel each other out. The short-term effects are net cooling, but the very long-term effect is a commitment to net warming, Overuse of fertilisers can decimate microbial communities in the soil and decrease soil health. And excess phosphorus in the soil can become fixed to organic material or salts, resulting in a form of phosphate that is unusable by plants. Carbon Brief (2022) What does the world’s reliance on fertilisers mean for climate change? 22.5 Regenerative Agriculture Grunwald What exactly is ’Climate-Smart Agriculture? agriculture and the deforestation that makes room for it generate one-fourth of all greenhouse gas emissions. To meet the Paris targets for 2050, the agriculture sector somehow needs to reduce those emissions by 75 percent while increasing food production by more than 50 percent. Agriculture accounts for only one-ninth of U.S. greenhouse emissions — partly because America’s other sectors emit so much, partly because most deforestation happens abroad, partly because U.S. agriculture is the most efficient on earth — but it’s still a major climate problem. And unlike electricity or transportation, it’s a climate problem we’ve barely even begun to try to solve. “Climate-smart agriculture” may have started out as a political catchphrase, but it’s about to become an extremely lucrative business. USDA is now preparing to announce the winners of that $1 billion grant program, perhaps as early as this week, and it has begun studying options for the new $20 billion, which it has significant flexibility to decide how to spend. Showering farmers with cash is an American political tradition, and one thing that’s certainly clear is that Biden plans to use carrots rather than sticks to promote his climate agenda in farm country. “Farmers get really, really nervous about climate policy when they think it’s top-down regulations, something being done to them,” said Robert Bonnie, USDA’s Under Secretary for Farm Production and Conservation. ​“But when it’s voluntary, collaborative, incentives-based, folks are interested. Making sure this stuff can pencil out for producers is just critical.” Of course, the atmosphere doesn’t notice whether climate policies pencil out economically for farmers; it’s only affected by whether they reduce heat-trapping emissions. And at times, the Biden team has seemed to equate ​“climate-smart agriculture” with ​“regenerative agriculture,” an increasingly popular but scientifically controversial approach that aims to sequester more carbon in soils by farming in greater harmony with nature. The president put in an unexpected plug for soil-protecting ​“cover crops” during his first address to Congress, and his administration has promoted ​“conservation tillage,” ​“rotational grazing” and other regenerative practices designed to rebuild soils and increase soil carbon as well. Globally, extraordinary momentum is building behind regenerative agriculture — including the United Nations–supported, celebrity-studded Save Soil movement; food conglomerates such as General Mills, Cargill and Danone; fledgling carbon markets that provide financial rewards for emissions-reducing practices; environmental groups disgusted by conventional farming; and even the new King of the United Kingdom. But although there’s solid evidence that regenerative practices can improve soil health and reduce erosion, there’s not yet much evidence they can reliably and permanently sequester carbon underground or mitigate climate change — while there’s plenty of evidence that other practices unrelated to soil carbon can reduce emissions. Only half the world’s nitrogen fertilizers (which are usually manufactured from fossil fuels) actually end up fertilizing crops. The rest escape into the environment, where they pollute rivers, aquifers and streams, create a dead zone the size of Rhode Island and Delaware combined in the Gulf of Mexico, and foul the air with nitrous oxide, a greenhouse gas 300 times more potent than carbon dioxide. Here’s a simple idea: Let’s not waste so much fertilizer! It’s expensive for farmers, especially lately, and it’s a disaster for the planet. we already have proven ways to get more nitrogen into plants and less into the environment. Some farmers apply ​“slow-release fertilizer,” which gives soils more time to absorb nutrients and helps reduce runoff. Many American farmers also have self-driving tractors that use GPS technology and machine learning to apply the optimal amount of fertilizer in the fields where it’s needed. Grunwald (2022) What exactly is ​‘climate-smart agriculture’? 22.6 Rice Fields Tooze No crop is as vulnerable to global warming as rice, say scientists at irri. A study in 2004 found that a 1°C increase in minimum temperatures leads to a 10% decline in yields. Rising sea levels, another result of warming, are already causing salt intrusion in low-lying areas of the Mekong delta, eroding rice yields there. Massive floods last year in Pakistan, the world’s fourth-biggest rice exporter, are estimated to have destroyed 15% of its harvest. Rice’s contribution to global warming represents an underappreciated feedback loop. Irrigating paddy fields starves the underlying soil of oxygen. This encourages methane-emitting bacteria to flourish. Consequently, rice production is responsible for 12% of total methane emissions—and 1.5% of total greenhouse-gas emissions, comparable to aviation. Vietnam’s paddy fields produce more carbon equivalent than the country’s transportation. Rice yields are stangating. If it is to meet 30% rise in rice demand by 2050 global agriculture needs a greener revolution. Tooze (2023) 22.7 Fungi Eurekalert Fungi stores a third of carbon from fossil fuel emissions and could be essential to reaching net zero, new study reveals Mycorrhizal fungi are responsible for holding up to 36 per cent of yearly global fossil fuel emissions below ground - more than China emits each year The fungi make up a vast underground network all over the planet underneath grasslands and forests, as well as roads, gardens, and houses on every continent on Earth It is not only crucial to storing carbon and keeping the planet cooler, but are also essential to global biodiversity Researchers are now calling for fungi to be considered more heavily in conservation and biodiversity policies, and are investigating whether we can increase how much carbon the soil underneath us can hold The vast underground network of fungi beneath our feet stores over 13 gigatons of carbon around the world, roughly equivalent to 36 per cent of yearly global fossil fuel emissions, according to new research. It is widely believed that mycorrhizal fungi could store carbon, as the fungi forms symbiotic relationships with almost all land plants and transports carbon, converted into sugars and fats by the plant, into soil, but until now the true extent of just how much carbon the fungi were storing wasn’t known. The discovery by a team of scientists, including researchers from the University of Sheffield, that fungi is storing over a third of the carbon created from fossil fuel emissions each year indicates that it could be crucial as nations seek to tackle climate change and reach net zero. Work is now being undertaken to see whether we could increase how much carbon the soil underneath us can store. Eurekalert (2023) Fungi stores a third of carbon from fossil fuel emissions and could be essential to reaching net zero "],["climate-controvercies.html", "23 Climate Controvercies", " 23 Climate Controvercies Gerlich (2007) Falsification Of The Atmospheric CO2 Greenhouse Effects Within The Frame Of Physics (pdf) Halpern on Gerlich Gerhard Gerlich and Ralf D. Tscheuschner claim to have falsified the existence of an atmospheric greenhouse effect.1 Here, we show that their methods, logic, and conclusions are in error. Their most significant errors include trying to apply the Clausius statement of the Second Law of Thermodynamics to only one side of a heat transfer process rather than the entire process, and systematically ignoring most non-radiative heat flows applicable to the Earth’s surface and atmosphere. They claim that radiative heat transfer from a colder atmosphere to a warmer surface is forbidden, ignoring the larger transfer in the other direction which makes the complete process allowed. Further, by ignoring heat capacity and non-radiative heat flows, they claim that radiative balance requires that the surface cool by 100 K or more at night, an obvious absurdity induced by an unphysical assumption. This comment concentrates on these two major points, while also taking note of some of Gerlich and Tscheuschner’s other errors and misunderstandings. Halpern on Gerlich (2010) (paywall) Gerlich Reply to Halpern (2010) (pdf) Skeptical Science The second law of thermodynamics has been stated in many ways. For us, Rudolf Clausius said it best: “Heat generally cannot flow spontaneously from a material at lower temperature to a material at higher temperature.” The skeptic tells us that, because the air, including the greenhouse gasses, is cooler than the surface of the Earth, it cannot warm the Earth. If it did, they say, that means heat would have to flow from cold to hot, in apparent violation of the second law of thermodynamics. The skeptic is ignoring the fact that the Earth is being warmed by the sun, which makes all the difference. o summarise: Heat from the sun warms the Earth, as heat from your body keeps you warm. The Earth loses heat to space, and your body loses heat to the environment. Greenhouse gases slow down the rate of heat-loss from the surface of the Earth, like a blanket that slows down the rate at which your body loses heat. The result is the same in both cases, the surface of the Earth, or of your body, gets warmer. So global warming does not violate the second law of thermodynamics. SkepticalScience on Gerlich SkepticalScience on Postma Endersbee Endersbee (2008) GCC has natural causes (pdf) Bellerby on Segalstad (2008) "],["about.html", "A About", " A About Dyre Haugen and Dyrehaugen are Webians for Jon Martin - self-owned Globian, Webian, Norwegian and Canarian with a background from industrial research policy, urban planning and economic development consulting on global, regional and urban scales. I am deeply concerned about the (insane) way humanity (i.e. capitalism) interfere with nature. In an effort to gain insights in how and why this happens stuff is collected from around the web and put together in a linked set of web-sites. The sites are operated as personal notebooks. However, these days things can be easily published to the benefit of others concerned with the same issues. But be aware - this is not polished for presentation or peer-reviewed for exactness. I offer you just to have a look at my ‘work-desk’ as it appears in the moment. Any comment or suggestion can be mailed to dyrehaugen@pm.me Currently migrating from twitter (@dyrehaugen) to Mastodon (@dyrehaugen@mastodon.online) Thanks for visiting! "],["history.html", "B History", " B History In Norwegian Allerede på 1950-tallet oppdaget en gruppe amerikanske forskere tegn på at menneskelig aktivitet kunne gjøre jorda varmere. Prinsippene bak global oppvarming hadde da vært kjent siden slutten av 1800-tallet. Det skulle likevel ta lang tid før temaet fikk stor oppmerksomhet her i landet. I 1959 dukket for første gang ordet «drivhuseffekt» opp i en norsk avis. Men vi skal langt inn på 1980-tallet før den norske offentligheten fikk et forhold til det som senere blir omtalt som klimaendringer eller global oppvarming. Klimaforskerne varslet ikke (Lars Sandved Dalen i Forskning.no) Replikk til Dalen "],["links.html", "C Links", " C Links Current Dyrehaugen Sites: rcap - On Capitalism (loc) rclm - On Climate Change (loc) recs - On Economics (loc) rfin - On Finance (loc) rngy - On Energy (loc) renv - On Environment (loc) rsts - On Statistics (loc) rurb - On Urbanization (loc) rvar - On Varia (loc) rwsd - On Wisdom (loc) Blogs: rde - Blog in English (loc) rdn - Blog in Norwegian (loc) Discontinued: jdt - Collection (Jekyll) (loc) hdt - Collection (Hugo) (loc) Not listed: (q:) dhe dhn jrw56 (z:) rcsa rpad rstart "],["news.html", "D NEWS D.1 231206 The 2023 Climate Boom D.2 231114 Antarctic Heat Flux Gates D.3 230908 Antarctica Polar Amplification D.4 230116 No US Green Monetary Policy - but EU? D.5 211104 Global CO2 emissions have been flat for a decade, new data reveals D.6 211104 Top climate scientists are sceptical that nations will rein in global warming D.7 210921 Microsoft CO2-removal D.8 210909 ORCA turned on - Iceland D.9 210715 Arctic Sea Ice at Record Low D.10 210526 Dutch Court against Shell D.11 210509 NDCs need 80% increase to 2°C D.12 210508 Young Legal Action D.13 210424 Earth’s Axis tilted by Melting Glaciers D.14 210410 CO2 and Methane surged in 2020 D.15 210404 Gas Sustainability D.16 210220 US SCC Update in Progress D.17 210215 Focus on Steel, Meat and Cement D.18 210127 10 New Insights in Climate Science 2020 D.19 210130 Adaptation Summit D.20 210118 Warming all anthropogenic D.21 21014 Globale Temperature 1880-2020 D.22 210104 Not so long lag? D.23 210102 Climate Finance Shadow Report 2020", " D NEWS D.1 231206 The 2023 Climate Boom Overall, the warming of 2023 seems too large to be explained entirely by any of the suspects. It’s somewhat reminiscent of “the pause” from the 2000s and early 2010s when global warming slowed down and scientists struggled to explain it. That turned out to be due to natural variability persisting over an extended period. The current situation will probably end up being similar. Our estimate of the impact of El Nino comes from linear regression, but our present situation may be unique: we just flipped from an unusually persistent triple-dip La Nina (2020-2022) into a strong El Nino. This may mean that El Nino is having a bigger impact this year than it would on average. What does 2023 mean for the future? Probably not a lot. If you want to know what the future of the climate is, your best bet is to look at the climate model predictions. Climate models have done a great job predicting global average surface temperature, so the predictions deserve a significant amount of deference. They are predicting an acceleration of the warming as greenhouse gas emissions continue and aerosols decline, but not a continuation of the extreme warming of 2023. Dressler (2023) WTF is going on with the climate? D.2 231114 Antarctic Heat Flux Gates There are five ‘eddy heat flux gates’, or hot spots, identified around the Antarctic Circle and they’re acting as a gateway for the heat to go south, The Antarctic Circumpolar Current surrounds Antarctica like a force field, keeping out warmer waters, but scientists are worried about breaches. They are concerned eddies spinning off from the current act as gateways to let warmer water reach the icy continent, speeding up melting. The researchers will embark on the RV Investigator on Wednesday and deploy high-tech monitoring devices in the Southern Ocean to better understand the problem. It is the planet’s strongest flow of water and behaves like a climatic force field in the Southern Ocean. The Antarctic Circumpolar Current flows around the icy continent from west to east and acts as our safety belt so that the warm water doesn’t reach the Antarctic and melt the ice. But scientists are concerned that eddies spinning off from the current are acting as a “gateway” for warmer waters to enter the frigid zones. ABC.net.au D.3 230908 Antarctica Polar Amplification Antarctica is likely warming at almost twice the rate of the rest of the world and faster than climate change models are predicting, with potentially far-reaching implications for global sea level rise. Scientists analysed 78 Antarctic ice cores to recreate temperatures going back 1,000 years and found the warming across the continent was outside what could be expected from natural swings. In West Antarctica, a region considered particularly vulnerable to warming with an ice sheet that could push up global sea levels by several metres if it collapsed, the study found warming at twice the rate suggested by climate models. Climate scientists have long expected that polar regions would warm faster than the rest of the planet – a phenomenon known as polar amplification – and this has been seen in the Arctic. Antarctica was warming at a rate of between 0.22C and 0.32C per decade, compared to 0.18C per decade predicted by climate models. Part of the warming in Antarctica is likely being masked by a change in a pattern of winds – also thought to be linked to global heating and the loss of ozone over the continent – that has tended to reduce temperatures. Guardian (2023) Antarctica warming much faster than models predicted in ‘deeply concerning’ sign for sea levels D.4 230116 No US Green Monetary Policy - but EU? Jay Powell has said the Federal Reserve will not become a “climate policymaker”, as he mounted a full-throated defence of the US central bank’s independence from political influence. In a speech delivered on Tuesday, the Fed chair said the central bank must steer clear of issues outside its congressionally mandated purview and instead maintain a narrow focus on keeping consumer prices stable, fostering a healthy labour market and ensuring the safety of the country’s banking system. “It is essential that we stick to our statutory goals and authorities, and that we resist the temptation to broaden our scope to address other important social issues of the day,” he said at a conference hosted by Sweden’s central bank. “Without explicit congressional legislation, it would be inappropriate for us to use our monetary policy or supervisory tools to promote a greener economy or to achieve other climate-based goals.” He added: “We are not, and will not be, a ‘climate policymaker’.” At the same event, Isabel Schnabel, a member of the six-person executive board of the European Central Bank, advocated greater action to address climate change. The German economist pledged to “ensure that all of the ECB’s policies are aligned with the objectives of the Paris Agreement to limit global warming to well below 2C”. The ECB’s position is clear. It worries that high interest rates to control inflation will undermine the green transition by raising the cost of investing in wind, solar, hydrogen and other clean energies necessary for moving to a net zero carbon world. But ECB and Fed are aligned on two important issues: First, that the primary role of green intervention lies not with independent central banks but with governments. Powell said that “in a well-functioning democracy, important public policy decisions should be made, in almost all cases, by the elected branches of government”. Schnabel concurred, saying, “governments must remain in the lead in accelerating the green transition”. Second, they agree central banks have a role when supervising the banking system in ensuring commercial banks understand and manage financial risks from global warming. These include weather-related risks to infrastructure that banks have financed or fossil fuel assets that might become near-worthless in future. ESG on a Sunday D.5 211104 Global CO2 emissions have been flat for a decade, new data reveals Global carbon dioxide (CO2) emissions from fossil fuels and cement have rebounded by 4.9% this year, new estimates suggest, following a Covid-related dip of 5.4% in 2020. The Global Carbon Project (GCP) projects that fossil emissions in 2021 will reach 36.4bn tonnes of CO2 (GtCO2), only 0.8% below their pre-pandemic high of 36.7GtCO2 in 2019. The researchers say they “were expecting some sort of rebound in 2021” as the global economy bounced back from Covid-19, but that it was “bigger than expected”. While fossil emissions are expected to return to near-record levels, the study also reassesses historical emissions from land-use change, revealing that global CO2 output overall may have been effectively flat over the past decade. The 2021 GCP almost halves the estimate of net emissions from land-use change over the past two years – and by an average of 25% over the past decade. These changes come from an update to underlying land-use datasets that lower estimates of cropland expansion, particularly in tropical regions. Emissions from land-use change in the new GCP dataset have been decreasing by around 4% per year over the past decade, compared to an increase of 1.8% per year in the prior version. However, the GCP authors caution that uncertainties in land-use change emissions remain large and “this trend remains to be confirmed”. CarbonBrief D.6 211104 Top climate scientists are sceptical that nations will rein in global warming Nature conducted an anonymous survey of the 233 living IPCC authors last month and received responses from 92 scientists — about 40% of the group. Their answers suggest strong scepticism that governments will markedly slow the pace of global warming, despite political promises made by international leaders as part of the 2015 Paris climate agreement. Six in ten of the respondents said that they expect the world to warm by at least 3 °C by the end of the century, compared with what conditions were like before the Industrial Revolution. That is far beyond the Paris agreement’s goal to limit warming to 1.5–2 °C. Most of the survey’s respondents — 88% — said they think global warming constitutes a ‘crisis’, and nearly as many said they expect to see catastrophic impacts of climate change in their lifetimes. Nature D.7 210921 Microsoft CO2-removal In January this year, Microsoft made a major announcement: it had paid for the removal of 1.3 million tonnes of carbon dioxide from the atmosphere. Among its purchases were projects to expand forests in Peru, Nicaragua and the United States, as well as initiatives to regenerate soil across US farms. Microsoft will pay the Swiss firm Climeworks to operate a machine in Iceland that pulls CO2 from the air and injects it into the ground, where it mineralizes and turns to stone. The amount of CO2 to be removed is equivalent to about 11% of the annual emissions from Microsoft’s value chain; of this, the company will count less than half as being certified to officially compensate for its emissions. It is the largest corporate procurement of carbon removal so far. Microsoft did this as part of its 2020 commitment to slash its greenhouse-gas emissions to ‘net zero’ — as one of more than 120 nations and 1,500 companies to set such goals1. By 2030, the company will reduce its emissions by half or more, and will have 100% of its electricity consumption matched by zero-carbon energy purchases. It will electrify its vehicle fleet, stop using diesel for backup energy and reduce emissions across its value chain. Emissions that are harder to abate, including historical emissions, will be compensated for by withdrawing carbon from the atmosphere. The firm is levying an internal carbon tax across all types of greenhouse-gas emission. It has set up a US$1-billion fund to invest in carbon reduction and removal technologies, and partnerships to provide social and environmental benefits. The aim is that, by 2030, the company will be carbon negative. By 2050, it will have removed all of its emissions since it was founded in 1975. Here we summarize the lessons learnt from Microsoft’s carbon-removal efforts, along with those from another early corporate procurement — the $9-million purchases of carbon removal in 2020 and 2021 by the US–Irish financial-infrastructure company Stripe. Although these are just two companies’ efforts, they are the first significant open solicitations focused exclusively on carbon removal. We write as a team composed of Microsoft staff working on the company’s carbon-negative programme and research scientists who analyse carbon reduction and removal strategies. We highlight three ‘bugs’ in the current system: inconsistent definitions of net zero, poor measurement and accounting of carbon, and an immature market in CO2 removal and offsets. These challenges need to be overcome if the world is to reach net zero by mid-century. Nature D.8 210909 ORCA turned on - Iceland The world’s largest plant designed to suck carbon dioxide out of the air and turn it into rock has started running, the companies behind the project said on Wednesday. The plant, named Orca after the Icelandic word “orka” meaning “energy”, consists of four units, each made up of two metal boxes that look like shipping containers. Constructed by Switzerland’s Climeworks and Iceland’s Carbfix, when operating at capacity the plant will draw 4,000 tonnes of carbon dioxide out of the air every year, according to the companies. The climate crisis requires a new culture and politics, not just new tech Peter Sutoris Read more According to the US Environmental Protection Agency, that equates to the emissions from about 870 cars. The plant cost between US$10 and 15m to build, Bloomberg reported. To collect the carbon dioxide, the plant uses fans to draw air into a collector, which has a filter material inside. Once the filter material is filled with CO2, the collector is closed and the temperature is raised to release the CO2 from the material, after which the highly concentrated gas can be collected. The CO2 is then mixed with the water before being injected at a depth of 1,000 metres into the nearby basalt rock where it is mineralised. Guardian D.9 210715 Arctic Sea Ice at Record Low ARCTIC SEA ICE AT RECORD LOW for this time of year. This is an enormous source of amplifying feedback. Losing the remaining Arctic sea ice and its reflection of solar energy back to space would be equivalent to another one trillion tons of CO2. Peter Carter (twitter) D.10 210526 Dutch Court against Shell This is a real ruling: it includes Scope 3 emissions. Rechtspraak De rechtbank Den Haag beveelt Royal Dutch Shell (RDS) om via het concernbeleid van de Shell-groep de CO2-uitstoot eind 2030 terug te brengen tot netto 45% ten opzichte van het niveau van 2019. Rechtsspraak (Dutch) English Translation D.11 210509 NDCs need 80% increase to 2°C On current trends, the probability of staying below 2 °C of warming is only 5% Liu (2021) Nature (pdf) D.12 210508 Young Legal Action The young people taking their countries to court over climate inaction Children and young adults around the world are demanding action from governments on global heating and the ecological crisis, Guardian D.13 210424 Earth’s Axis tilted by Melting Glaciers Since the 1990s, the loss of hundreds of billions of tonnes of ice a year into the oceans resulting from the climate crisis has caused the poles to move in new directions. The direction of polar drift shifted from southward to eastward in 1995 and that the average speed of drift from 1995 to 2020 was 17 times faster than from 1981 to 1995. Since 1980, the position of the poles has moved about 4 metres in distance. The accelerated decline [in water stored on land] resulting from glacial ice melting is the main driver of the rapid polar drift after the 1990s. Guardian D.14 210410 CO2 and Methane surged in 2020 Levels of the two most important anthropogenic greenhouse gases, carbon dioxide and methane, continued their unrelenting rise in 2020 despite the economic slowdown caused by the coronavirus pandemic response. CO2 The global surface average for carbon dioxide (CO2), calculated from measurements collected at NOAA’s remote sampling locations, was 412.5 parts per million (ppm) in 2020, rising by 2.6 ppm during the year. The global rate of increase was the fifth-highest in NOAA’s 63-year record, following 1987, 1998, 2015 and 2016. The annual mean at NOAA’s Mauna Loa Observatory in Hawaii was 414.4 ppm during 2020. The economic recession was estimated to have reduced carbon emissions by about 7 percent during 2020. Without the economic slowdown, the 2020 increase would have been the highest on record, according to Pieter Tans, senior scientist at NOAA’s Global Monitoring Laboratory. Since 2000, the global CO2 average has grown by 43.5 ppm, an increase of 12 percent. The atmospheric burden of CO2 is now comparable to where it was during the Mid-Pliocene Warm Period around 3.6 million years ago, when concentrations of carbon dioxide ranged from about 380 to 450 parts per million. During that time sea level was about 78 feet higher than today, the average temperature was 7 degrees Fahrenheit higher than in pre-industrial times, and studies indicate large forests occupied areas of the Arctic that are now tundra. Methane Analysis of samples from 2020 also showed a significant jump in the atmospheric burden of methane, which is far less abundant but 28 times more potent than CO2 at trapping heat over a 100-year time frame. NOAA’s preliminary analysis showed the annual increase in atmospheric methane for 2020 was 14.7 parts per billion (ppb), which is the largest annual increase recorded since systematic measurements began in 1983. The global average burden of methane for December 2020, the last month for which data has been analyzed, was 1892.3 ppb. That would represent an increase of about 119 ppb, or 6 percent, since 2000. NOAA D.15 210404 Gas Sustainability **Scientifically Sustainable* The European Commission is attempting to finish its sustainable finance taxonomy, a landmark regulation that from next year will define what can be labelled as a sustainable investment in the EU. A leaked proposal for the rules, shared with EU states last week, would label as sustainable some gas plants that generate power and also provide heating or cooling. That came after the Commission’s original proposal – which denied natural gas-fuelled power plants a green label, following the recommendation of the bloc’s expert advisers – faced resistance from some EU countries. Nine members of the expert group advising the European Union on its sustainable finance rules have threatened to step down if Brussels pushes ahead with plans that they say would discredit its efforts to fight climate change. EU countries disagree on what role natural gas should play in meeting climate goals. Gas emits roughly half the CO2 of coal when burned in power plants, but gas infrastructure is associated with leaks of methane, a potent greenhouse gas. “The concept of what is scientifically sustainable, that’s really not for politicians to decide,” said Andreas Hoepner, a professor at University College Dublin who signed the letter. Reuters D.16 210220 US SCC Update in Progress In its 2013 revision of the SCC, the Obama IWG arrived at a central value of around US$50 per tonne of CO2 emitted in 2020 (all values expressed in today’s dollars). It also established a range for the SCC ($15–75) and presented an estimate at the 95th percentile ($150). The time is ripe for this update, That IWG did a careful job, but devastating storms and wildfires are now more common, and costs are mounting. Advances in attribution science mean that researchers can now link many more extreme weather events directly to climate change, and new econometric techniques help to quantify the dollar impacts. The monetary losses exceed the predictions of early models. The same goes for sea-level rise and many other types of damage. Plenty of scientific and economic judgements need to be made. These include how to deal with endemic uncertainties, including sudden and irreversible ‘tipping points’, such as ice-sheet collapses. Ethical questions must be considered, including the consequences for vulnerable communities and future generations. Revising the SCC will take extensive research. A 2017 study by the US National Academies of Sciences, Engineering, and Medicine proposed building a new climate-economy model based on modules — separate components that handle climate change, socio-economic projections, damages, valuation and discounting Other nations use widely different SCC values or overall approaches2. Germany’s 2020 guidance presented two values: €195 (US$235) and €680 ($820). Some countries instead establish a goal for emissions reductions (such as the United Kingdom’s 68% reduction by 2030 compared to 1990 levels) and then focus on minimizing the costs of achieving it, estimated at $20–100 per tonne of CO2. This is called a target-consistent approach. Wagner (Nature) D.17 210215 Focus on Steel, Meat and Cement Bill Gates has written about Climate Change. His assessment is that there is not the time, money or political will to reconfigure the energy sector in 10 years, and encouraging an impossible goal dooms the world to short-term measures that prove insufficient. Crucially, people need to radically change how they produce the worst climate offenders: steel, meat and cement. Making steel and cement accounts for roughly 10% of all global emissions, and beef alone 4%. Bill Gates D.18 210127 10 New Insights in Climate Science 2020 Someof which are: ● Earth’s temperature response to doubling the levels of carbon dioxide in the atmosphere is now better understood. While previous IPCC assessments have used an estimated range of 1.5–4.5°C, recent research now suggests a narrower range of 2.3–4.5°C. ● Emissions of greenhouse gases from permafrost will be larger than earlier projections because of abrupt thaw processes, which are not yet included in global climate models. ● Global plant biomass uptake of carbon due to CO 2 fertilization may be limited in the future by nitrogen and phosphorus. ● Rights-based litigation is emerging as a tool to address climate change. Moving forward, the latest research calls for innovative, imaginative, and transformative approaches to building sustainable and resilient human societies. For instance, by strengthening global cooperative frameworks and building new governance arrangements that can include bottom-up community initiatives. In the short term, we have a one-off opportunity to get on the right path by directing post-pandemic recovery spending to green investments. If the focus is instead on economic growth, with sustainability as an afterthought, it would jeopardize our ability to deliver on the Paris Agreement. Alarmingly, governments do not yet seem to be seizing the opportunity to shift towards low-carbon, healthier, and more resilient societies. futureearth (pdf) D.19 210130 Adaptation Summit Climate change adaptation seems to be a fairly new concept to many leaders. It were sometimes mix-ups with mitigation during the high-level talks. Mitigation and adaptation are both important and sometimes they overlap, so mix-ups are understandable. Climate adaptation involves many communities and disciplines (e.g. weather forecasting, climate services, regional climate modelling, “distillation“, disaster risk reduction). Financing is clearly needed for climate change adaptation. To ensure progress and avoid lofty visions without results on the ground, there may also be a need for tangible results and to show examples and demonstrations. One specific type discussed at the summit was “Early warning systems” which play an important role. But early warning systems, the way I understand them, don’t provide information about climate risks on longer timescales. Weather and climate – short and long timescales – are of course connected but nevertheless different Rasmus (2021) Adaptation Summit D.20 210118 Warming all anthropogenic Parties to the Paris Agreement agreed to holding global average temperature increases “well below 2 °C above pre-industrial levels and pursuing efforts to limit the temperature increase to 1.5 °C above pre-industrial levels”. Monitoring the contributions of human-induced climate forcings to warming so far is key to understanding progress towards these goals. Here we use climate model simulations from the Detection and Attribution Model Intercomparison Project, as well as regularized optimal fingerprinting, to show that anthropogenic forcings caused 0.9 to 1.3 °C of warming in global mean near-surface air temperature in 2010–2019 relative to 1850–1900, compared with an observed warming of 1.1 °C. Greenhouse gases and aerosols contributed changes of 1.2 to 1.9 °C and −0.7 to −0.1 °C, respectively, and natural forcings contributed negligibly. These results demonstrate the substantial human influence on climate so far and the urgency of action needed to meet the Paris Agreement goals. Nature (paywall) D.21 21014 Globale Temperature 1880-2020 The rate of global warming has accelerated in the past several years. The 2020 global temperature was +1.3°C (~2.3°F) warmer than in the 1880-1920 base period; global temperature in that base period is a reasonable estimate of ‘pre-industrial’ temperature. The six warmest years in the GISS record all occur in the past six years, and the 10 warmest years are all in the 21st century. Growth rates of the greenhouse gases driving global warming are increasing, not declining. [GISSTEMP 2020 Update] (https://mailchi.mp/caa/global-temperature-in-2020?e=96d59a909f) D.22 210104 Not so long lag? Until recently, Mann explained in The Guardian, scientists believed the climate system—a catch-all term for the interaction among the Earth’s atmosphere, oceans, and other parts of the biosphere—carried a long lag effect. This lag effect was mainly a function of carbon dioxide remaining in the atmosphere and trapping heat for many decades after being emitted. So, even if humanity halted all CO2 emissions overnight, average global temperatures would continue to rise for 25 to 30 years, while also driving more intense heat waves, droughts, and other climate impacts. Halting emissions will take at least twenty years, under the best of circumstances, and so humanity was likely locked in to at least 50 more years of rising temperatures and impacts. Research over the past ten years, however, has revised this vision of the climate system. Scientists used to “treat carbon dioxide in the atmosphere as if it was a simple control knob that you turn up” and temperatures climb accordingly, “but in the real world we now know that’s not what happens,” Mann said. Instead, if humans “stop emitting carbon right now … the oceans start to take up carbon more rapidly.” The actual lag effect between halting CO2 emissions and halting temperature rise, then, is not 25 to 30 years but, per Mann, “more like three to five years.” (October 2020) Guardian article Covering Climate Now article D.23 210102 Climate Finance Shadow Report 2020 Oxfam has released this report with subtitle Asessing progress towards the $100 billion commitment Progress is NOT in line with need or pledges. Climate change could undo decades of progress in development and dramatically increase global inequalities. There is an urgent need for climate finance to help countries cope and adapt. Over a decade ago, developed countries committed to mobilize $100bn per year by 2020 to support developing countries to adapt and reduce their emissions. The goal is a critical part of the Paris Agreement. As 2020 draws to a close, Oxfam’s Climate Finance Shadow Report 2020 offers an assessment of progress towards the $100bn goal. Based on 2017–18 reported numbers, developed countries are likely to claim they are on track to meet the $100bn goal. And on their own terms, they may be. But how the goal is met is as important as whether it is met. The dubious veracity of reported numbers, the extent to which climate finance is increasing developing country indebtedness, and the enduring gap in support for adaptation, LDCs and SIDS, are grave concerns. Meeting the $100bn goal on these terms would be cause for concern, not celebration. Oxfam Report (pdf) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
